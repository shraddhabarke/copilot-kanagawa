import data.counter
import data.memory
import numeric.int.operator
import sync.atomic
import sync.lock
import type.coerce
import type.stdtype

//| Basic FIFO.
template
    < typename T                  //< Type for each entry of the FIFO.
    , auto Size                   //< Maximum number of entries that can be stored.
    , bool EnqueueBlocking = true //< Block on enqueue if the FIFO is full until an entry
                                  // frees up. By default this is true. Otherwise,
                                  // the caller must ensure that the FIFO is not full.
    , bool DequeueBlocking = true //< Block on dequeue if the FIFO is empty until an entry
                                  // arrives. By default, this is true. Otherwise,
                                  // the caller must ensure that the FIFO is not empty.
    >
class FIFO
{
public:
    //| `Size` must be a power of 2.
    static assert(0 == (Size & (Size - 1)));

private:
    using pointer_t = index_t<Size>;

    // Memory that holds the raw data
    memory<T, Size> _dataMem;

    // Used to block reads while fifo is empty
    semaphore<Size, 0, DequeueBlocking> _readSemaphore;

    // Used to block writes while the fifo is full
    semaphore<Size, Size, EnqueueBlocking> _writeSemaphore;

count_t<Size> enqueue(T value, bool releaseDeferredDequeues)
    {
        // Block until the FIFO is no longer full
        _writeSemaphore.wait();

        // Get the value of the write pointer then increment the write pointer
        auto producer_index = first(atomically<pointer_t>(increment));

        // Store the value into the memory
        _dataMem[producer_index] = value;

        count_t<Size> snappedDeferredDequeueCount;
        atomic
        {
            if (releaseDeferredDequeues)
            {
                // Add one to the deferred dequeue count for the value being enqueued now.
                snappedDeferredDequeueCount = _deferredDequeueCount + 1;
                _deferredDequeueCount = 0;
            }
            else
            {
                // Ensure that the increment of _deferredDequeueCount below won't overflow.
                sim_assert(_deferredDequeueCount < (1 << bitsizeof(count_t<Size>)) - 1);

                snappedDeferredDequeueCount = 0;
                _deferredDequeueCount++;
            }
        }

        // Allow 0 or more threads to to get a value out
        _readSemaphore.post_multiple(snappedDeferredDequeueCount);

        return snappedDeferredDequeueCount;
    }
}
