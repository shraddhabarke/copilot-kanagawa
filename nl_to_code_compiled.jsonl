{"file": "data\\vector.pd", "nl": "Construct a vector from an array.", "code": "template <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\ntemplate <typename T, auto N>\ninline vector<T, N> from_array(T[N] a)\n{\n    return {a, N};\n}\n"}
{"file": "data\\vector.pd", "nl": "Construct a vector with capacity 1 from an optional. If the optional is invalid then return an empty vector otherwise return a singleton vector.", "code": "template <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename T>\ninline vector<T, 1> from_optional(optional<T> o)\n{\n    return {{o.value}, o.is_valid ? 1 : 0};\n}\n"}
{"file": "data\\vector.pd", "nl": "Construct a vector by replicating a value `length` times.", "code": "template <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <auto N, typename T>\ninline vector<T, N> replicate(T x, count_t<N> length)\n{\n    sim_assert(length <= N);\n    vector<T, N> result;\n    static for(const auto i : N)\n        if (i < length)\n            result.data[i] = x;\n    return resize(result, length);\n}\n"}
{"file": "data\\vector.pd", "nl": "Access element `i`. Equivalent to `v.data[i]`. If `i` is greater than or equal to `v.size` then a `sim_assert` is triggered.", "code": "template <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename T, auto N>\ninline T at(vector<T, N> v, index_t<N> i)\n{\n    sim_assert(i < v.size);\n    return v.data[i];\n}\n"}
{"file": "data\\vector.pd", "nl": "Return the first element in the vector. Equivalent to `v.data[0]`. If the vector is empty then a `sim_assert` is triggered.", "code": "template <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename T, auto N>\ninline T front(vector<T, N> v)\n{\n    sim_assert(v.size > 0);\n    return at(v, 0);\n}\n"}
{"file": "data\\vector.pd", "nl": "Return the last element in the vector. Equivalent to `v.data[v.size - 1]`.", "code": "template <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename T, auto N>\ninline T back(vector<T, N> v)\n{\n    sim_assert(v.size > 0);\n    return at(v, v.size - 1);\n}\n"}
{"file": "data\\vector.pd", "nl": "Return the number of elements. Equivalent to `v.size`.", "code": "template <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename T, auto N>\ninline count_t<N> size(vector<T, N> v)\n{\n    return v.size;\n}\n"}
{"file": "data\\vector.pd", "nl": "Check whether the vector is empty. Equivalent to `v.size == 0`.", "code": "template <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename T, auto N>\ninline bool empty(vector<T, N> v)\n{\n    return v.size == 0;\n}\n"}
{"file": "data\\vector.pd", "nl": "Return the maximum number of elements.", "code": "template <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename T, auto N>\ninline count_t<N> capacity(vector<T, N> v)\n{\n    return N;\n}\n"}
{"file": "data\\vector.pd", "nl": "Resize the vector to contain `length` elements. Equivalent to `v.size = length;`. If `length > v.size` then new elements are undefined. If `length` is greater than `N` then a `sim_assert` is triggered", "code": "template <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename T, auto N>\ninline vector<T, N> resize(vector<T, N> v, count_t<N> length)\n{\n    sim_assert(length <= N);\n    v.size = length;\n    return v;\n}\n"}
{"file": "data\\vector.pd", "nl": "Clear the contents. Equivalent to `v.size = 0;`.", "code": "template <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename T, auto N>\ninline vector<T, N> clear(vector<T, N> v)\n{\n    return resize(v, 0);\n}"}
{"file": "data\\vector.pd", "nl": "Insert `value` before position `pos` in vector `v`. If `pos > v.size` or `v.size >= N` then a `sim_assert` is triggered.", "code": "template <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename T, auto N>\ninline vector<T, N> insert(vector<T, N> v, index_t<N> pos, T value)\n{\n    sim_assert(pos <= v.size && v.size < N);\n    v.data = A::copy_array(v.data, pos, v.data, pos + 1, v.size - pos);\n    v.data[pos] = value;\n    v.size++;\n    return v;\n}"}
{"file": "data\\vector.pd", "nl": "Erase element at position `pos` from vector `v`. If `pos >= v.size` or the vector is empty then a `sim_assert` is triggered.", "code": "template <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename T, auto N>\ninline vector<T, N> erase(vector<T, N> v, index_t<N> pos)\n{\n    sim_assert(pos < v.size && v.size > 0);\n    v.data = A::copy_array(v.data, pos + 1, v.data, pos, v.size - pos - 1);\n    v.size--;\n    return v;\n}"}
{"file": "data\\vector.pd", "nl": "Append element `x` to the end of vector `v`. If `v.size >= N` then a `sim_assert` is triggered.", "code": "template <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename T, auto N>\ninline vector<T, N> push_back(T x, vector<T, N> v)\n{\n    sim_assert(v.size < N);\n    v.data[v.size] = x;\n    v.size++;\n    return v;\n}"}
{"file": "data\\vector.pd", "nl": "Remove the last element of the vector. If the vector is empty then a `sim_assert` is triggered.", "code": "template <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename T, auto N>\ninline vector<T, N> pop_back(vector<T, N> v)\n{\n    sim_assert(v.size > 0);\n    v.size--;\n    return v;\n}"}
{"file": "data\\vector.pd", "nl": "Append vectors. If the sum of the vector sizes is greater than `N` then a `sim_assert` is triggered.", "code": "template <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename T, auto N>\ninline vector<T, N> append(vector<T, N> x, vector<T, N> y)\n{\n    sim_assert(x.size + y.size <= N);\n    x.data = A::copy_array(y.data, 0, x.data, x.size, y.size);\n    return resize(x, x.size + y.size);\n}"}
{"file": "data\\vector.pd", "nl": "Map vector of input values to result values.", "code": "template <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename T, auto N>\ninline auto map((T) -> auto f, vector<T, N> x)\n{\n    using result_t = decltype(f(x.data[0]));\n    result_t[N] r;\n    static for(const auto i : N)\n        if (i < x.size)\n            r[i] = f(x.data[i]);\n    return resize(from_array(r), x.size);\n}"}
{"file": "data\\vector.pd", "nl": "Reserve `M` number of elements. If `M` is less than `v.size` then a `sim_assert` is triggered. Reserving the same capacity as the input vector returns the orginal vector.", "code": "template <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <auto M, typename T, auto N>\ninline vector<T, M> reserve(vector<T, N> v)\n{\n    sim_assert(v.size <= M);\n    const auto Bound = M < N ? M : N;\n    vector<T, M> new;\n    new.size = v.size;\n    static for(const auto i : Bound)\n        new.data[i] = v.data[i];\n    return new;\n}"}
{"file": "data\\vector.pd", "nl": "De-duplicate vector elements with user-supplied equality predicate.  For each element e, check the previous elements for duplicates. If there are any duplicates, mark element e as invalid. Return a vector of optionals where all valid elements are unique.", "code": "import data.vector as V\nimport .options as opt\nimport data.array as A\nimport data.function\nimport data.optional as Opt\nimport data.order as Ord\nimport data.tuple as P\nimport sync.atomic\nimport numeric.int.operator\nimport numeric.int.operator.unsigned as unsigned\nimport type.stdtype\n\ntemplate <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename T, auto N>\ninline vector<optional<T>, N> unique_by((T, T) -> bool equality_fn, vector<T, N> v) {\n    auto es = A::zip_with_indices( [v](index_t<N> i, T x) { return make_optional(i < v.size, x);}, v.data);\n    auto xs = A::unique_by( [equality_fn](optional<T> x, optional<T> y)\n    {\n        return Opt::equal_by(equality_fn, x, y);\n    }, es);\n    return {A::map(Opt::join<T>, xs), v.size};\n}\n"}
{"file": "data\\vector.pd", "nl": "Implement a binary reducer tree using a function to reduce a pair of inputs", "code": "template <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename T, auto N>\ninline T reduce((T, T) -> T f, vector<T, N> v)\n{\n    optional<T>[N] values;\n    static for(const auto i : N)\n        values[i] = make_optional(i < v.size, v.data[i]);\n\n    optional<T> result = A::reduce\n                     ( [f](optional<T> l, optional<T> r)\n                       {\n                           sim_assert(!r.is_valid || l.is_valid);\n                           if (l.is_valid && r.is_valid)\n                               l = make_optional(true, f(l.value, r.value));\n                           return l;\n                       }\n                     , values\n                     );\n    T uninit;\n    return Opt::from_optional(uninit, result);\n}"}
{"file": "data\\vector.pd", "nl": "//| De-duplicate vector elements. Similar to `unique_by` but uses the `==` operator. For each element e, check the previous elements for duplicates. If there are any duplicates, mark element e as invalid. Return a vector of optionals where all valid elements are unique.", "code": "template <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename T, auto N>\ninline vector<optional<T>, N> unique(vector<T, N> v)\n{\n    return unique_by(Ord::equal, v);\n}"}
{"file": "data\\vector.pd", "nl": "Implements map-reduce. Inputs are first mapped into the appropriate result type `R` and then reduced to a single output using a binary reduction tree.", "code": "template <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename R, typename T, auto N>\ninline R map_reduce((T) -> R map_fn, (R, R) -> R reduce_fn, vector<T, N> v)\n{\n    return reduce(reduce_fn, map(map_fn, v));\n}"}
{"file": "data\\vector.pd", "nl": "Return true if any of the elements are true. Return false if the vector is empty.", "code": "template <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <auto N>\ninline bool or(vector<bool, N> v)\n{\n    return empty(v) ? false : reduce([](bool x, bool y){ return x || y; }, v);\n}"}
{"file": "data\\vector.pd", "nl": "Return true if all of the elements are true. Return true if the vector is empty.", "code": "template <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <auto N>\ninline bool and(vector<bool, N> v)\n{\n    return empty(v) ? true : reduce([](bool x, bool y){ return x && y; }, v);\n}"}
{"file": "data\\vector.pd", "nl": "Return true if any of the elements satisfy the predicate. Return false if the vector is empty.", "code": "template <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename T, auto N>\ninline bool any((T) -> bool predicate, vector<T, N> v)\n{\n    return or(map(predicate, v));\n}"}
{"file": "data\\vector.pd", "nl": "Return true if all of the elements satisfy the predicate. Return true if the vector is empty.", "code": "template <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename T, auto N>\ninline bool all((T) -> bool predicate, vector<T, N> v)\n{\n    return and(map(predicate, v));\n}"}
{"file": "data\\vector.pd", "nl": "Return the minimum element from a vector of integers. Return undefined if the vector is empty.", "code": "template <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename T, auto N>\ninline T minimum(vector<T, N> v)\n{\n    return reduce(selecting(Ord::less_than), v);\n}"}
{"file": "data\\vector.pd", "nl": "Return the maximum element from a vector of integers. Return undefined if the vector is empty.", "code": "template <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename T, auto N>\ninline T maximum(vector<T, N> v)\n{\n    return reduce(selecting(Ord::greater_than), v);\n}"}
{"file": "data\\vector.pd", "nl": "Sum of the vector elements. Return undefined if the vector is empty.", "code": "import .options as opt\nimport data.array as A\nimport data.function\nimport data.optional as Opt\nimport data.order as Ord\nimport data.tuple as P\nimport sync.atomic\nimport numeric.int.operator\nimport numeric.int.operator.unsigned as unsigned\nimport type.stdtype\nimport data.vector as V\n\ntemplate <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename R, typename T, auto N>\ninline R sum(vector<T, N> v)\n{\n    return map_reduce(static_cast<R>, add<R, R>, v);\n}\n"}
{"file": "data\\vector.pd", "nl": "Given a vector of `optional<T>`, return the first (lowest vector index) valid element. If there are no valid elements or the vector is empty then return invalid.", "code": "import data.vector as V\nimport .options as opt\nimport data.array as A\nimport data.function\nimport data.optional as Opt\nimport data.order as Ord\nimport data.tuple as P\nimport sync.atomic\nimport numeric.int.operator\nimport numeric.int.operator.unsigned as unsigned\nimport type.stdtype\n\ntemplate <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename T, auto N>\ninline optional<T> first_valid(vector<optional<T>, N> v)\n{\n    return reduce(selecting(on1st(Opt::is_valid<T>)), v);\n}\n"}
{"file": "data\\vector.pd", "nl": "Given a vector of `optional<T>`, return the last (highest vector index) valid element. If there are no valid elements or the vector is empty then return invalid.", "code": "import .options as opt\nimport data.array as A\nimport data.function\nimport data.optional as Opt\nimport data.order as Ord\nimport data.tuple as P\nimport sync.atomic\nimport numeric.int.operator\nimport numeric.int.operator.unsigned as unsigned\nimport type.stdtype\nimport data.vector as V\ntemplate <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename T, auto N>\ninline optional<T> last_valid(vector<optional<T>, N> v)\n{\n    return reduce(selecting(on2nd(not(Opt::is_valid<T>))), v);\n}\n"}
{"file": "data\\vector.pd", "nl": "Return a vector containing only valid mapped elements.", "code": "template <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename R, typename T, auto N>\ninline vector<R, N> map_optional((T) -> optional<R> f, vector<T, N> v)\n{\n    auto opts   = map(f, v);\n    auto elems  = A::map([](optional<R> x){ return x.value; }, opts.data);\n    auto valids = A::zip_with_indices( [opts](index_t<N> i, optional<R> x)\n                                       {\n                                           return i < opts.size && x.is_valid;\n                                       }\n                                     , opts.data\n                                     );\n    auto p = A::gather(valids, elems);\n    return {p.first, p.second};\n}"}
{"file": "data\\vector.pd", "nl": "Return a vector containing only valid input elements..", "code": "import data.vector as V\nimport .options as opt\nimport data.array as A\nimport data.function\nimport data.optional as Opt\nimport data.order as Ord\nimport data.tuple as P\nimport sync.atomic\nimport numeric.int.operator\nimport numeric.int.operator.unsigned as unsigned\nimport type.stdtype\n\ntemplate <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename R, typename T, auto N>\ninline vector<R, N> map_optional((T) -> optional<R> f, vector<T, N> v)\n{\n    auto opts   = map(f, v);\n    auto elems  = A::map([](optional<R> x){ return x.value; }, opts.data);\n    auto valids = A::zip_with_indices( [opts](index_t<N> i, optional<R> x)\n                                       {\n                                           return i < opts.size && x.is_valid;\n                                       }\n                                     , opts.data\n                                     );\n    return gather(valids, elems);\n}\n\ntemplate <typename T, auto N>\ninline vector<T, N> cat_optionals(vector<optional<T>, N> v)\n{\n    return map_optional<T>(id, v);\n}\n"}
{"file": "data\\vector.pd", "nl": "Combine elements of two vectors using specified function. Any remaining elements of the longer vector are dropped. The capacity of the zipped vector is the minimum of `N` and `M`.", "code": "template <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename S, auto N, typename T, auto M>\ninline auto zip_with((S, T) -> auto f, vector<S, N> s, vector<T, M> t)\n{\n    using result_t = decltype(f(s.data[0], t.data[0]));\n    const auto Min = N < M ? N : M;\n    result_t[Min] rs;\n    auto min_size = Ord::min(s.size, t.size);\n    static for(const auto i : Min)\n        if (i < min_size)\n            rs[i] = f(s.data[i], t.data[i]);\n    return resize(from_array(rs), min_size);\n}"}
{"file": "data\\vector.pd", "nl": "Combine two vectors into a vector of pairs. Any remaining elements of the longer vector are dropped. The maximum size of the zipped vector is the minimum of `N` and `M`.", "code": "\nimport .options as opt\nimport data.array as A\nimport data.function\nimport data.optional as Opt\nimport data.order as Ord\nimport data.tuple as P\nimport sync.atomic\nimport numeric.int.operator\nimport numeric.int.operator.unsigned as unsigned\nimport type.stdtype\nimport data.vector as V\n\ntemplate <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename S, auto N, typename T, auto M>\ninline auto zip(vector<S, N> s, vector<T, M> t)\n{\n    return zip_with(P::make_pair<S, T>, s, t);\n}\n"}
{"file": "data\\vector.pd", "nl": "Transform a vector `v` into a pair of vectors using a projection `f`.", "code": "\nimport .options as opt\nimport data.array as A\nimport data.function\nimport data.optional as Opt\nimport data.order as Ord\nimport data.tuple as P\nimport sync.atomic\nimport numeric.int.operator\nimport numeric.int.operator.unsigned as unsigned\nimport type.stdtype\nimport data.vector as V\n\ntemplate <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename L, typename R, typename T, auto N>\ninline pair<vector<L, N>, vector<R, N>> unzip_with\n    ( (T) -> P::tuple2<L, R> f\n    , vector<T, N> v\n    )\n{\n    pair<vector<L, N>, vector<R, N>> result;\n    static for(const auto i : N)\n        if (i < v.size)\n        {\n            auto p = f(v.data[i]);\n            result.first.data[i]  = p.first;\n            result.second.data[i] = p.second;\n        }\n    result.first  = resize(result.first,  v.size);\n    result.second = resize(result.second, v.size);\n    return result;\n}\n"}
{"file": "data\\vector.pd", "nl": "Transform a vector of pairs into a pair of vectors.", "code": "import .options as opt\nimport data.array as A\nimport data.function\nimport data.optional as Opt\nimport data.order as Ord\nimport data.tuple as P\nimport sync.atomic\nimport numeric.int.operator\nimport numeric.int.operator.unsigned as unsigned\nimport type.stdtype\n\ntemplate <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename L, typename R, typename T, auto N>\ninline pair<vector<L, N>, vector<R, N>> unzip_with\n    ( (T) -> P::tuple2<L, R> f\n    , vector<T, N> v\n    )\n{\n    pair<vector<L, N>, vector<R, N>> result;\n    static for(const auto i : N)\n        if (i < v.size)\n        {\n            auto p = f(v.data[i]);\n            result.first.data[i]  = p.first;\n            result.second.data[i] = p.second;\n        }\n    result.first  = resize(result.first,  v.size);\n    result.second = resize(result.second, v.size);\n    return result;\n}\n\ntemplate <typename L, typename R, auto N>\ninline pair<vector<L, N>, vector<R, N>> unzip(vector<pair<L, R>, N> v)\n{\n    return unzip_with<L, R>(id, v);\n}\n"}
{"file": "data\\vector.pd", "nl": "Perform an inclusive scan on the given vector.", "code": "template <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename R, typename T, auto N>\ninline vector<R, N> inclusive_scan(vector<T, N> input, (R, R) -> R AssociativeFn)\n{\n    R[2][N] results;\n    static for (const auto i : N)\n    {\n        results[0][i] = cast<R>(input.data[i]);\n    }\n    static for (const auto j : clog2(N))\n    {\n        const uint1 prev_index = j % 2;\n        const uint1 next_index = (j + 1) % 2;\n        static for (const auto i : N)\n            if (i < input.size)\n            {\n                const auto shifted_by_j = 1 << j;\n                if (i < shifted_by_j)\n                    results[next_index][i] = results[prev_index][i];\n                else\n                {\n                    const auto idx = i - shifted_by_j;\n                    results[next_index][i] = AssociativeFn(results[prev_index][i], results[prev_index][idx]);\n                }\n            }\n    }\n    return {results[clog2(N) % 2], input.size};\n}"}
{"file": "data\\vector.pd", "nl": "Compute the prefix sum of the given vector.", "code": "import .options as opt\nimport data.array as A\nimport data.function\nimport data.optional as Opt\nimport data.order as Ord\nimport data.tuple as P\nimport sync.atomic\nimport numeric.int.operator\nimport numeric.int.operator.unsigned as unsigned\nimport type.stdtype\n\ntemplate <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename T, auto N>\ninline vector<T, N> make_vector\n    ( T[N] a        // Data to store in the vector.\n    , count_t<N> s  // Number of valid elements in the vector.\n    )\n{\n    sim_assert(s <= N);\n\n    return {a, s};\n}\n\ntemplate <typename R, typename T, auto N>\ninline vector<R, N> inclusive_scan(vector<T, N> input, (R, R) -> R AssociativeFn)\n{\n    // Two sets of results are kept - one set from the previous iteration and the other\n    // set is the values to use on the next iteration.  Each pass through the outer for\n    // loop below switches back and forth between which set is for the next versus\n    // previous iteration.  This avoids copying between two arrays after each iteration.\n    R[2][N] results;\n\n    static for (const auto i : N)\n    {\n        results[0][i] = cast<R>(input.data[i]);\n    }\n\n    static for (const auto j : clog2(N))\n    {\n        const uint1 prev_index = j % 2;\n        const uint1 next_index = (j + 1) % 2;\n\n        static for (const auto i : N)\n            if (i < input.size)\n            {\n                const auto shifted_by_j = 1 << j;\n                if (i < shifted_by_j)\n                    results[next_index][i] = results[prev_index][i];\n                else\n                {\n                    const auto idx = i - shifted_by_j;\n                    results[next_index][i] = AssociativeFn(results[prev_index][i], results[prev_index][idx]);\n                }\n            }\n    }\n\n    return make_vector(results[clog2(N) % 2], input.size);\n}\n\ntemplate <typename R, typename T, auto N>\ninline vector<R, N> prefix_sum(vector<T, N> v)\n{\n    return inclusive_scan(v, add<R, R>);\n}\n"}
{"file": "data\\vector.pd", "nl": "Element-wise equality comparison of vectors using specified function. Return false if the vectors differ in size.", "code": "template <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename T, auto N, auto M>\ninline bool equal_by((T, T) -> bool equality_fn, vector<T, N> x, vector<T, M> y)\n{\n    return x.size == y.size && and(zip_with(equality_fn, x, y));\n}"}
{"file": "data\\vector.pd", "nl": "Element-wise comparison of vectors for equality using `==`. Return false if the vectors differ in size.", "code": "template <typename T, auto N /*< Maximum size.*/>\nstruct vector\n{\n    T[N] data;\n    count_t<N> size;\n}\n\ntemplate <typename T, auto N, auto M>\ninline bool equal(vector<T, N> x, vector<T, M> y)\n{\n    return equal_by(Ord::equal, x, y);\n}"}
{"file": "data\\tuple.pd", "nl": "For improved type inference, consume `tuple2` and produce `pair`.", "code": "template <typename T1, typename T2>\nstruct tuple2\n{\n    T1 first;\n    T2 second;\n}\n\ntemplate <typename T1, typename T2>\nusing pair = tuple2<T1, T2>;"}
{"file": "data\\tuple.pd", "nl": "Create a pair of values.", "code": "template <typename T1, typename T2>\nstruct tuple2\n{\n    T1 first;\n    T2 second;\n}\n\ntemplate <typename T1, typename T2, typename T3>\nstruct tuple3\n{\n    T1 first;\n    T2 second;\n    T3 third;\n}\n\ntemplate <typename T1, typename T2, typename T3, typename T4>\nstruct tuple4\n{\n    T1 first;\n    T2 second;\n    T3 third;\n    T4 fourth;\n}\n\n//| For improved type inference, consume `tuple2` and produce `pair`.\n// For example, the compiler is able to infer the template of `first` in\n// `first(make_pair(1, 2))`\n\ntemplate <typename T1, typename T2>\ninline pair<T1, T2> make_pair(T1 a, T2 b)\n{\n    return {a, b};\n}\n"}
{"file": "data\\tuple.pd", "nl": "Return the first value of a pair.", "code": "template <typename T1, typename T2>\nstruct tuple2\n{\n    T1 first;\n    T2 second;\n}\n\ntemplate <typename T1, typename T2>\ninline T1 first(tuple2<T1, T2> a)\n{\n    return a.first;\n}\n"}
{"file": "data\\tuple.pd", "nl": "Return the second value of a pair.", "code": "template <typename T1, typename T2>\nstruct tuple2\n{\n    T1 first;\n    T2 second;\n}\n\ntemplate <typename T1, typename T2>\ninline T2 second(tuple2<T1, T2> a)\n{\n    return a.second;\n}\n"}
{"file": "data\\tuple.pd", "nl": "Swap the components of a pair.", "code": "template <typename T1, typename T2>\nstruct tuple2\n{\n    T1 first;\n    T2 second;\n}\n\ntemplate <typename T1, typename T2>\ninline pair<T2, T1> swap(tuple2<T1, T2> p)\n{\n    return {p.second, p.first};\n}"}
{"file": "data\\tuple.pd", "nl": "Compare pairs for equality.", "code": "template <typename T1, typename T2>\nstruct tuple2\n{\n    T1 first;\n    T2 second;\n}\n\ntemplate <typename T1, typename T2>\ninline bool equal(tuple2<T1, T2> x, tuple2<T1, T2> y)\n{\n    return x.first == y.first && x.second == y.second;\n}"}
{"file": "data\\tuple.pd", "nl": "Define a structure for a tuple with two elements.", "code": "template <typename T1, typename T2>\nstruct tuple2\n{\n    T1 first;\n    T2 second;\n}"}
{"file": "data\\tuple.pd", "nl": "Define a structure for a tuple with three elements.", "code": "template <typename T1, typename T2, typename T3>\nstruct tuple3\n{\n    T1 first;\n    T2 second;\n    T3 third;\n}"}
{"file": "data\\tuple.pd", "nl": "Define a structure for a tuple with four elements.", "code": "template <typename T1, typename T2, typename T3, typename T4>\nstruct tuple4\n{\n    T1 first;\n    T2 second;\n    T3 third;\n    T4 fourth;\n}"}
{"file": "data\\order.pd", "nl": "Return the smaller of two values.", "code": "inline auto min(auto a, auto b)\n{\n    return (a < b) ? a : b;\n}"}
{"file": "data\\order.pd", "nl": "Return the larger of two values.", "code": "inline auto max(auto a, auto b)\n{\n    return (a > b) ? a : b;\n}"}
{"file": "data\\order.pd", "nl": "Return true if the first argument is less than the second.", "code": "inline bool less_than(auto x, auto y)\n{\n    return x < y;\n}"}
{"file": "data\\order.pd", "nl": "Return true if the first argument is greater than the second.", "code": "inline bool greater_than(auto x, auto y)\n{\n    return x > y;\n}"}
{"file": "data\\order.pd", "nl": "Return equality of inputs.", "code": "inline bool equal(auto x, auto y)\n{\n    return x == y;\n}"}
{"file": "tutorials\\complete\\control_flow.pd", "nl": "Compute the sum of elements in _input_data using a do/while loop.", "code": "import data.array\nconst auto Depth = 512;\n\nmemory<uint32, Depth> _input_data;\nuint32 _result;\n\n// An integer wide enough to represent an index into _input_data\nusing element_index_t = index_t<Depth>;\n\nuint32 sum_do_while()\n{\n    uint32 result = 0;\n    count_t<Depth> i = 0;\n    do\n    {\n        result += _input_data[i];\n        i++;\n    } while (i < Depth);\n    return result;\n}\n"}
{"file": "tutorials\\complete\\control_flow.pd", "nl": "Compute the sum of elements in _input_data using a for loop.", "code": "import data.array\nconst auto Depth = 512;\nmemory<uint32, Depth> _input_data;\n\nuint32 _result;\n\n// An integer wide enough to represent an index into _input_data\nusing element_index_t = index_t<Depth>;\n\nuint32 sum_for()\n{\n    uint32 result = 0;\n    for (const auto i : Depth)\n    {\n        result += _input_data[i];\n    }\n    return result;\n}\n"}
{"file": "tutorials\\complete\\control_flow.pd", "nl": "Compute the sum of elements in _input_data using pipelined_for to parallelize execution.", "code": "import data.array\nconst auto Depth = 512;\nmemory<uint32, Depth> _input_data;\nuint32 _result;\n\n// An integer wide enough to represent an index into _input_data\nusing element_index_t = index_t<Depth>;\n\nuint32 sum_pipelined_for()\n{\n    _result = 0;\n    pipelined_for(Depth, [](element_index_t i)\n    {\n        const uint32 input = _input_data[i];\n        atomic\n        {\n            _result += input;\n        }\n    });\n    return _result;\n}\n"}
{"file": "tutorials\\complete\\control_flow.pd", "nl": "Compute the sum of elements in _input_data using pipelined_last to reduce synchronization overhead.", "code": "import data.array\nconst auto Depth = 512;\nmemory<uint32, Depth> _input_data;\nuint32 _result;\n\n// An integer wide enough to represent an index into _input_data\nusing element_index_t = index_t<Depth>;\nuint32 sum_pipelined_last()\n{\n    uint32 result = 0;\n    result = pipelined_last(Depth, [](element_index_t i)\n    {\n        const uint32 input = _input_data[i];\n        uint32 result;\n        atomic\n        {\n            static uint32 _sum = 0;\n            _sum += input;\n            result = _sum;\n        }\n        return result;\n    });\n    return result;\n}\n"}
{"file": "tutorials\\complete\\control_flow.pd", "nl": "Compute the sum of elements in _input_data using pipelined_last with loop unrolling for N additions per cycle.", "code": "import data.array\nconst auto Depth = 512;\n\n// An integer wide enough to represent an index into _input_data\nusing element_index_t = index_t<Depth>;\ntemplate<auto N>\nuint32 sum_unrolled()\n{\n    static_assert(0 == (Depth % N));\n    uint32 result = 0;\n    result = pipelined_last(Depth / N, [](element_index_t i)\n    {\n        uint32[N] input;\n        static for (const auto j : N)\n        {\n            input[j] = _input_data[i * N + j];\n        }\n        uint32 local_sum = sum<uint32>(input);\n        uint32 result;\n        atomic\n        {\n            static uint32 _sum = 0;\n            _sum += local_sum;\n            result = _sum;\n        }\n        return result;\n    });\n    return result;\n}\n"}
{"file": "data\\bitarray.pd", "nl": "Get the value of a single bit from the bitarray.", "code": "import data.array\nimport numeric.int.operator\n\ntemplate\n    < auto Size                                             //< Number of bits in the bit vector.\n    , auto WordWidth                                        //< Number of bits in each word.\n    , template <typename, auto> typename Memory = memory    //< Memory implementation.\n    >\nclass bitarray\n{\nprivate:\n    //| Size must be a multiple of word width\n    static_assert(0 == (Size % WordWidth));\n\n    const auto WordCount = Size / WordWidth;\n\npublic:\n    //| Represents the address of a single bit.\n    using bit_addr_t = index_t<Size>;\n\n    //| Represents the address of a single word.\n    using word_addr_t = index_t<WordCount>;\n\n    //| A single word which can be read or written.\n    using word_t = uint<WordWidth>;\n\n    //| Get the value of a single bit from the bitarray.\n    inline bool read_bit\n        ( bit_addr_t addr   //< Address of bit to read.\n        )\n    {\n        sim_assert(addr < Size);\n\n        auto decomposed_addr = div_mod(addr, WordWidth);\n\n        bool[WordWidth] word = cast<bool[WordWidth]>(_mem[decomposed_addr.first]);\n\n        return word[decomposed_addr.second];\n    }\n}\n"}
{"file": "data\\bitarray.pd", "nl": "Set the value of a single bit in the bitarray. Note that this is implemented with a read-modify write. If `Memory` is `memory_norep` then concurrent reads and writes of the bitarray are not allowed. If `Memory` is `memory`, then each call site of `read_bit`, `write_bit`, and `read_word` add another replica.", "code": "import data.array\nimport numeric.int.operator\n\n//| A fixed sized array of bits, stored internally as a memory of words.\n// Provides methods to read or write at bit and word granularity.\ntemplate\n    < auto Size                                             //< Number of bits in the bit vector.\n    , auto WordWidth                                        //< Number of bits in each word.\n    , template <typename, auto> typename Memory = memory    //< Memory implementation.\n    >\nclass bitarray\n{\nprivate:\n    //| Size must be a multiple of word width\n    static_assert(0 == (Size % WordWidth));\n\n    const auto WordCount = Size / WordWidth;\n\npublic:\n    //| Represents the address of a single bit.\n    using bit_addr_t = index_t<Size>;\n\n    //| Represents the address of a single word.\n    using word_addr_t = index_t<WordCount>;\n\n    //| A single word which can be read or written.\n    using word_t = uint<WordWidth>;\n\n    //| Set the value of a single bit in the bitarray.\n    // Note that this is implemented with a read-modify write.\n    // If `Memory` is `memory_norep` then concurrent reads and writes of the bitarray\n    // are not allowed.\n    // If `Memory` is `memory`,\n    // then each call site of `read_bit`, `write_bit`, and `read_word` add another replica.\n    inline void write_bit\n        ( bit_addr_t addr   //< Address of the bit to write.\n        , bool val          //< Value to write.\n        )\n    {\n        sim_assert(addr < Size);\n\n        auto decomposed_addr = div_mod(addr, WordWidth);\n\n        // The read-modify-write is implemented with word-width bitwise and followed by bitwise or\n        // The bitwise and is used to clear bits\n        // the bitwise or is used to set bits\n        bool[WordWidth] and_mask = repeat(true);\n        bool[WordWidth] or_mask = repeat(false);\n\n        and_mask[decomposed_addr.second] = val;\n        or_mask[decomposed_addr.second] = val;\n\n        atomic\n        {\n            word_t prev = _mem[decomposed_addr.first];\n\n            _mem[decomposed_addr.first] = (prev & cast<word_t>(and_mask)) | cast<word_t>(or_mask);\n        }\n    }\n}\n"}
{"file": "data\\bitarray.pd", "nl": "Get the value of a word.", "code": "import data.array\nimport numeric.int.operator\n\ntemplate\n    < auto Size                                             //< Number of bits in the bit vector.\n    , auto WordWidth                                        //< Number of bits in each word.\n    , template <typename, auto> typename Memory = memory    //< Memory implementation.\n    >\n\nclass bitarray\n{\nprivate:\n    //| Size must be a multiple of word width\n    static_assert(0 == (Size % WordWidth));\n\n    const auto WordCount = Size / WordWidth;\n\npublic:\n    //| Represents the address of a single bit.\n    using bit_addr_t = index_t<Size>;\n\n    //| Represents the address of a single word.\n    using word_addr_t = index_t<WordCount>;\n\n    //| A single word which can be read or written.\n    using word_t = uint<WordWidth>;\n\n    inline word_t read_word(word_addr_t addr) {\n\tsim_assert(addr < WordCount);\n\treturn _mem[addr];\n    }\n}\n"}
{"file": "data\\bitarray.pd", "nl": "Set the value of a word.", "code": "template\n    < auto Size                                             //< Number of bits in the bit vector.\n    , auto WordWidth                                        //< Number of bits in each word.\n    , template <typename, auto> typename Memory = memory    //< Memory implementation.\n    >\nclass bitarray\n{\nprivate:\n    //| Size must be a multiple of word width\n    static_assert(0 == (Size % WordWidth));\n\n    const auto WordCount = Size / WordWidth;\n\npublic:\n    //| Represents the address of a single bit.\n    using bit_addr_t = index_t<Size>;\n\n    //| Represents the address of a single word.\n    using word_addr_t = index_t<WordCount>;\n\n    //| A single word which can be read or written.\n    using word_t = uint<WordWidth>;\n\n    inline void write_word(word_addr_t addr, word_t word)\n{\n    sim_assert(addr < WordCount);\n   _mem[addr] = word;\n}\n}\n"}
{"file": "data\\optional.pd", "nl": "Create optional with `is_valid` set to true.", "code": "import data.order as O\nimport data.tuple as P\n\ntemplate <typename T>\nstruct optional\n{\n    bool is_valid;\n    T value;\n}\n\ntemplate <typename T>\ninline bool is_valid(optional<T> x)\n{\n    return x.is_valid;\n}\n\ntemplate <typename T>\ninline myoptional<T> make_optional(bool is_valid, T value)\n{\n    return {is_valid, value};\n}\n\n//| Create optional with `is_valid` set to true.\ninline auto just(auto value)\n{\n    return make_optional(true, value);\n}\n"}
{"file": "data\\optional.pd", "nl": "Compare optionals for equality. Return true when both arguments are invalid or both arguments are valid and have equal values.", "code": "import data.order as O\n\ntemplate <typename T>\nstruct optional\n{\n    bool is_valid;\n    T value;\n}\n\n//\n// #### __Examples__\n//\n//     >>> equal({false, 0x0}, {false, 0x1});\n//     true\n//\n//     >>> equal({true, 0x4}, {false, 0x4});\n//     false\n//\n//     >>> equal({true, 0x4}, {true, 0x4});\n//     true\n\ntemplate <typename T> inline bool equal(optional<T> x, optional<T> y) { return equal_by(O::equal, x, y); }\n"}
{"file": "data\\optional.pd", "nl": "Convert from `optional<T>` to `pair<bool, T>`.", "code": "import data.order as O\nimport data.tuple as P\n\ntemplate <typename T>\nstruct optional\n{\n    bool is_valid;\n    T value;\n}\n\ntemplate <typename T>\ninline bool is_valid(optional<T> x)\n{\n    return x.is_valid;\n}\n\ntemplate <typename T> inline P::pair<bool, T> optional_to_pair(optional<T> x) { return P::make_pair(x.is_valid, x.value); }\n"}
{"file": "data\\optional.pd", "nl": "Convert from `optional<T>` to `T`, using a default value if necessary.", "code": "import data.order as O\nimport data.tuple as P\n\ntemplate <typename T>\nstruct optional\n{\n    bool is_valid;\n    T value;\n}\n\n//| Convert from `optional<T>` to `T`, using a default value if necessary.\n//\n// #### __Examples__\n//\n//     >>> from_optional(0x7, {false, 0x2});\n//     0x7\n//\n//     >>> from_optional(0x7, {true, 0x2});\n//     0x2\n\ntemplate <typename T> \ninline T from_optional(T default_value, optional<T> x) { return x.is_valid ? x.value : default_value; }\n"}
{"file": "data\\optional.pd", "nl": "Remove one layer of `optional`, projecting `T` into the outer layer.", "code": "import data.order as O\nimport data.tuple as P\n\ntemplate <typename T>\nstruct optional\n{\n    bool is_valid;\n    T value;\n}\n\ntemplate <typename T>\ninline bool is_valid(optional<T> x)\n{\n    return x.is_valid;\n}\ninline optional<T> join(optional<optional<T>> x) { return make_optional(x.is_valid && x.value.is_valid, x.value.value); }\n"}
{"file": "data\\optional.pd", "nl": "Equality comparison of optionals using the specified function.", "code": "import data.order as O\nimport data.tuple as P\n\ntemplate <typename T>\nstruct optional\n{\n    bool is_valid;\n    T value;\n}\n\ntemplate <typename T>\ninline bool is_valid(optional<T> x)\n{\n    return x.is_valid;\n}\n\ntemplate <typename T> inline bool equal_by((T, T) -> bool equality_fn, optional<T> x, optional<T> y) { return (!x.is_valid && !y.is_valid) || (x.is_valid && y.is_valid && equality_fn(x.value, y.value)); }\n"}
{"file": "data\\optional.pd", "nl": "Returns a function with the signature: `(optional<A>)->optional<decltype(fn(A))>`. The result is valid if and only if the input is valid.// `fn` is called to compute the resulting value. // If the result is invalid, then `fn` is not called, and the result value is undefined.", "code": "\ninline auto lift_optional((auto) -> auto fn)\n{\n    return [fn](auto x)\n    {\n        optional<decltype(fn(x))> result = {};\n        if (x.is_valid)\n        {\n            result = make_optional(true, fn(x.value));\n        }\n\n        return result;\n    };\n}\n"}
{"file": "data\\optional.pd", "nl": "Returns a function with the signature: `(optional<A>, optional<B>)->optional<decltype(fn(A, B))>`. The result is valid if and only if both inputs are valid. `fn` is called to compute the resulting value. If the result is invalid, then `fn` is not called, and the result value is undefined.", "code": "inline auto lift2_optional((auto, auto) -> auto fn) {\n    return [fn](auto x, auto y)\n    {\n        optional<decltype(fn(x, y))> result = {};\n        if (x.is_valid && y.is_valid)\n        {\n            result = make_optional(true, fn(x.value, y.value));\n        }\n        return result;\n    };\n}\n"}
{"file": "data\\bits.pd", "nl": "Rotate the specified value left by the specified amount.", "code": "import data.array\nimport data.optional\nimport type.coerce\nimport type.stdtype\n\ntemplate <typename T> inline T rotl(T value, bitindex_t<T> amount) { const auto Width = bitsizeof(T); sim_assert(amount <= Width);  return cast<T>(value << amount) | cast<T>(value >> (Width - amount)); }\n"}
{"file": "data\\bits.pd", "nl": "Rotate the specified value right by the specified amount.", "code": "template <typename T> inline T rotr(T value, bitindex_t<T> amount) { const auto Width = bitsizeof(T); sim_assert(amount <= Width);  return cast<T>(value >> amount) | cast<T>(value << (Width - amount)); }"}
{"file": "data\\bits.pd", "nl": "Find the index of the highest 1 bit in the value. The result is an `optional<bitindex_t<T>>` with the `is_valid` field indicating if there are any 1 bits in the value. When `is_valid` is true then `value` is the index of the highest 1 bit.", "code": "import data.array\nimport data.optional\nimport type.coerce\nimport type.stdtype\n\ntemplate <typename T> inline optional<bitindex_t<T>> highest_one(T value) { \n\tconst auto Width = bitsizeof(T); \n\tuint1[Width] value_as_bits = cast<uint1[Width]>(value);  \n\toptional<bitindex_t<T>>[Width] in; \n\tstatic for (const auto i : Width) { \n\t    in[i].is_valid = value_as_bits[i] == 1; \n\t    in[i].value = i; } \n\treturn last_valid<bitindex_t<T>, Width>(in);\n}\n"}
{"file": "data\\bits.pd", "nl": "Find the index of the lowest 1 bit in the value. The result is an `optional<bitindex_t<T>>` with the `is_valid` field indicating if there are any 1 bits in the value. When `is_valid` is true then `value` is the index of the lowest 1 bit.", "code": "import data.array\nimport data.optional\nimport type.coerce\nimport type.stdtype\n\ntemplate <typename T> inline optional<bitindex_t<T>> lowest_one(T value) { const auto Width = bitsizeof(T); uint1[Width] value_as_bits = cast<uint1[Width]>(value);  optional<bitindex_t<T>>[Width] in; static for (const auto i : Width) { in[i].is_valid = value_as_bits[i] == 1; in[i].value = i; } return first_valid<bitindex_t<T>, Width>(in);}\n"}
{"file": "data\\bits.pd", "nl": "Return a count of the number of bits set in the value.", "code": "import data.array\nimport data.optional\nimport type.coerce\nimport type.stdtype\n\ntemplate <typename T> \ninline bitcount_t<T> pop_count(T value) { \n\t// Reduction tree to improve area of synthesized structure\n    const auto Width = bitsizeof(T); \n    bitcount_t<T>[Width] cts;  \n    uint1[Width] value_as_bits = cast<uint1[Width]>(value);  // Populate cts array from initial bit vector\n    static for (const auto i : Width) { \n    cts[i] = value_as_bits[i]; }\n    return sum<bitcount_t<T>>(cts);}\n"}
{"file": "data\\bits.pd", "nl": "Divide dividend by divisor and round the result up. Divisor must be an unsigned power of 2, known at compile time. Calling with (x, 32) returns the equivalent of (x + 31) / 32.", "code": "template<typename DividendType, typename DivisorType>\ninline DividendType divide_and_roundup(DividendType dividend, const DivisorType divisor) { return (dividend + (divisor - 1)) / divisor; }"}
{"file": "data\\bits.pd", "nl": "Round up a value to the next larger power of two. For example, all values from 33 through 64 (inclusive) round up to 64. OutputType must be at least one bit larger than InputType.", "code": "import data.array\nimport data.optional\nimport type.coerce\nimport type.stdtype\n\n\n//| Round up a value to the next larger power of two. For example,\n// all values from 33 through 64 (inclusive) round up to 64.\n// OutputType must be at least one bit larger than InputType.\n//\n// #### __Examples__\n//\n//     >>> roundup_to_pow2<uint15, uint16>(0);\n//     {0x0, 0x0}\n//\n//     >>> roundup_to_pow2<int7, int8>(0x1f);\n//     {0x1, 0x20}\n//\n//     >>> roundup_to_pow2<uint7, uint8>(0x20);\n//     {0x1, 0x20}\n//\n//     >>> roundup_to_pow2<uint15, uint16>(0x21);\n//     {0x1, 0x40}\n\ntemplate<typename InputType, typename OutputType>\ninline optional<OutputType> roundup_to_pow2(InputType input)\n{\n    sim_assert(bitsizeof(OutputType) > bitsizeof(InputType));\n    optional<OutputType> result;\n    if (pop_count(input) == 1)\n    {\n        // Exactly 1 bit is set -> input is already a power of 2.\n        result = make_optional<OutputType>(true, input);\n    }\n    else\n    {\n        auto highest = highest_one<OutputType>(input);\n        if (highest.is_valid)\n        {\n            result = make_optional<OutputType>(true, 1 << (highest.value + 1));\n        }\n        else\n        {\n            // No bits set, input must have been 0.  Rounding up 0\n            // is nonsensical and is treated as an error.\n            result = make_optional<OutputType>(false, 0);\n        }\n    }\n    return result;\n}\n"}
{"file": "data\\bits.pd", "nl": "Reverse all bits and return the same input data type.", "code": "import data.array\nimport data.optional\nimport type.coerce\nimport type.stdtype\n\ntemplate<typename T>\ninline T reverse(T data) { \n    uint1[bitsizeof(T)] result; \n    uint1[bitsizeof(T)] tmpData = cast<uint1[bitsizeof(T)]>(data); \n    static for(const auto i: bitsizeof(T)) { result[i] = tmpData[static(bitsizeof(T) - i - 1)]; }\n}\n"}
{"file": "data\\bits.pd", "nl": "Reverse input byte-by-byte and return as the same data type.", "code": "import data.array\nimport data.optional\nimport type.coerce\nimport type.stdtype\n\ntemplate<typename T>\ninline T reverse_bytes(T data) { const auto bytesize = bytesizeof(T); using bytes_t = uint8[bytesize];  bytes_t data_bytes = cast<bytes_t>(data); bytes_t result; static for (const auto i : bytesize) { result[i] = data_bytes[bytesize - 1 - i]; }\nreturn cast<T>(result); }\n"}
{"file": "data\\bits.pd", "nl": "Return array `bool[N]` with element at i the result of i >= arg.", "code": "template <auto N, typename T> inline bool[N] mask_greater_equal(T arg) { sim_assert(arg <= N); return reinterpret_cast<bool[N]>(static((1 << N) - 1) << arg); }"}
{"file": "data\\bits.pd", "nl": "Return array `bool[N]` with element at i the result of i < arg.", "code": "//| Return array `bool[N]` with element at i the result of i < arg.\n//\n// #### __Example__\n//\n//     >>> mask_less_than<4>(2);\n//     {0x1, 0x1, 0x0, 0x0}\n\ntemplate <auto N, typename T>\ninline bool[N] mask_greater_equal(T arg)\n{\n    sim_assert(arg <= N);\n    return reinterpret_cast<bool[N]>(static((1 << N) - 1) << arg);\n}\n\ntemplate <auto N, typename T> \ninline bool[N] mask_less_than(T arg) { \n    sim_assert(arg <= N); \n    auto ret = mask_greater_equal<N>(arg); \n    static for(const auto i : N) \n\tret[i] = !ret[i]; \n\treturn ret; }\n"}
{"file": "data\\bits.pd", "nl": "Return array `bool[N]` with element at i the result of i > arg.", "code": "template <auto N, typename T> inline bool[N] mask_greater_than(T arg) { sim_assert(arg <= N); return reinterpret_cast<bool[N]>(static((1 << N) - 2) << arg); }"}
{"file": "data\\bits.pd", "nl": "Return array `bool[N]` with element at i the result of i <= arg.", "code": "import data.array\nimport data.optional\nimport type.coerce\nimport type.stdtype\n\ntemplate <auto N, typename T>\ninline bool[N] mask_greater_than(T arg)\n{\n    sim_assert(arg <= N);\n    return reinterpret_cast<bool[N]>(static((1 << N) - 2) << arg);\n}\n\ntemplate <auto N, typename T>\ninline bool[N] mask_less_equal(T arg)\n{\n    sim_assert(arg <= N);\n    auto ret = mask_greater_than<N>(arg);\n    static for(const auto i : N)\n        ret[i] = !ret[i];\n    return ret;\n}\n\n\n\n\n"}
{"file": "data\\bits.pd", "nl": "Casts the specified scalar type to an array of booleans and applies the reduction operator to it", "code": "inline bool reduction((bool, bool) -> bool f, T x) { return reduce(f, cast<bool[bitsizeof(T)]>(x)); }"}
{"file": "data\\bits.pd", "nl": "Verilog style AND reduction operator", "code": "template<typename T>\ninline bool reduction_and(T x) { return reduction([](bool a, bool b){ return a && b; }, x); }\n"}
{"file": "data\\bits.pd", "nl": "Verilog style OR reduction operator", "code": "\ntemplate<typename T>\ninline bool reduction_or(T x) { return reduction([](bool a, bool b){ return a || b; }, x); }\n"}
{"file": "data\\bits.pd", "nl": "Verilog style XOR reduction operator", "code": "template<typename T>\ninline bool reduction_xor(T x) { return reduction([](bool a, bool b){ return a ^^ b; }, x); }\n"}
{"file": "data\\bits.pd", "nl": "Verilog style XNOR reduction operator", "code": "template<typename T>\ninline bool reduction_xnor(T x) { return !reduction_xor(x); }\n"}
{"file": "data\\bits.pd", "nl": "Verilog style NAND reduction operator", "code": "\ntemplate<typename T>\ninline bool reduction_nand(T x) { return !reduction_and(x); }\n"}
{"file": "data\\bits.pd", "nl": "Verilog style NOR reduction operator", "code": "template<typename T>\ninline bool reduction_nor(T x) { return !reduction_or(x); }\n"}
{"file": "data\\bits.pd", "nl": "AND operator applied to the bits of an arbitrary type.", "code": "template<typename T>\ninline T bitwise_and(T x, T y) { return binary_op([](auto a, auto b){return a & b; }, x, y); }\n"}
{"file": "data\\bits.pd", "nl": "OR operator applied to the bits of an arbitrary type.", "code": "template<typename T>\ninline T bitwise_or(T x, T y) { return binary_op([](auto a, auto b){return a | b; }, x, y); }\n"}
{"file": "data\\bits.pd", "nl": "XOR operator applied to the bits of an arbitrary type.", "code": "template<typename T>\ninline T bitwise_xor(T x, T y) { return binary_op([](auto a, auto b){return a ^ b; }, x, y); }\n"}
{"file": "data\\bits.pd", "nl": "NAND operator applied to the bits of an arbitrary type.", "code": "template<typename T>\ninline T bitwise_nand(T x, T y) { return binary_op([](auto a, auto b){return ~(a & b); }, x, y); }\n"}
{"file": "data\\bits.pd", "nl": "NOR operator applied to the bits of an arbitrary type.", "code": "template<typename T>\ninline T bitwise_nor(T x, T y) { return binary_op([](auto a, auto b){return ~(a | b); }, x, y); }\n"}
{"file": "data\\bits.pd", "nl": "XNOR operator applied to the bits of an arbitrary type.", "code": "template<typename T>\ninline T bitwise_xnor(T x, T y) { return binary_op([](auto a, auto b){return ~(a ^ b); }, x, y); }\n"}
{"file": "data\\array.pd", "nl": "Perform an inclusive scan on the given array.", "code": "template <typename R, typename T, auto N>\ninline R[N] inclusive_scan(T[N] input, (R, R) -> R AssociativeFn)\n{\n    // Two sets of results are kept - one set from the previous iteration and the other\n    // set is the values to use on the next iteration.  Each pass through the outer for\n    // loop below switches back and forth between which set is for the next versus\n    // previous iteration.  This avoids copying between two arrays after each iteration.\n    R[2][N] results;\n    static for (const auto i : N)\n    {\n        results[0][i] = cast<R>(input[i]);\n    }\n    static for (const auto j : clog2(N))\n    {\n        const uint1 prev_index = j % 2;\n        const uint1 next_index = (j + 1) % 2;\n        static for (const auto i : N)\n        {\n            const auto shifted_by_j = 1 << j;\n            if (i < shifted_by_j)\n            {\n                results[next_index][i] = results[prev_index][i];\n            }\n            else\n            {\n                const auto idx = i - shifted_by_j;\n                results[next_index][i] = AssociativeFn(results[prev_index][i], results[prev_index][idx]);\n            }\n        }\n    }\n    return results[clog2(N) % 2];\n}\n"}
{"file": "data\\array.pd", "nl": "Compute the prefix sum of the given array.", "code": "template <typename R, typename T, auto N>\ninline R[N] inclusive_scan(T[N] input, (R, R) -> R AssociativeFn)\n{\n    // Two sets of results are kept - one set from the previous iteration and the other\n    // set is the values to use on the next iteration.  Each pass through the outer for\n    // loop below switches back and forth between which set is for the next versus\n    // previous iteration.  This avoids copying between two arrays after each iteration.\n    R[2][N] results;\n\n    static for (const auto i : N)\n    {\n        results[0][i] = cast<R>(input[i]);\n    }\n\n    static for (const auto j : clog2(N))\n    {\n        const uint1 prev_index = j % 2;\n        const uint1 next_index = (j + 1) % 2;\n\n        static for (const auto i : N)\n        {\n            const auto shifted_by_j = 1 << j;\n            if (i < shifted_by_j)\n            {\n                results[next_index][i] = results[prev_index][i];\n            }\n            else\n            {\n                const auto idx = i - shifted_by_j;\n                results[next_index][i] = AssociativeFn(results[prev_index][i], results[prev_index][idx]);\n            }\n        }\n    }\n\n    return results[clog2(N) % 2];\n}\n\ntemplate <typename R, typename T, auto N> \ninline R[N] prefix_sum(T[N] input) { \n    return inclusive_scan(input, add<R, R>); \n}\n"}
{"file": "data\\array.pd", "nl": "An inline function that returns the smallest N elements seen in a sequence of elements so far, provided one at a time over multiple calls. Internally, this is achieved by using a pipeline of N atomic stages each of which accepts an element, compares it with its current smallest, and swaps the two if the provided lambda returns true. The remaining element is then passed onto the next stage, or discarded if no stage follows. This iterative nature is suitable for use inside a `[[pipelined]]` function which would supply one piece of data per cycle (for example, extracted from a memory).", "code": "template\n    < auto N     //< Maximum number of elements to be extracted.\n    , typename T //< Type of each element.\n    >\ninline optional<T>[N] partial_sort\n    ( T x\n    , (T, T) -> bool cmp //< Binary function that returns true when the lhs\n                         //  should be swapped and stored.\n    , bool is_last       //< Indicates a call with the last element in the\n                         //  sequence so that state can be reset for the next\n                         //  call.\n    )\n{\n    optional<T>[N] snappedResult;\n\n    optional<T> lhs = {true, x};\n    static for(const auto i : N)\n    {\n        atomic\n        {\n            static optional<T> result = {};\n\n            auto rhs = result;\n            if (lhs.is_valid && (!rhs.is_valid || cmp(lhs.value, rhs.value)))\n            {\n                result = lhs;\n                lhs = rhs;\n            }\n\n            snappedResult[i] = result;\n\n            if (is_last)\n                result.is_valid = false;\n        }\n    }\n\n    return snappedResult;\n}\n\n"}
{"file": "data\\array.pd", "nl": "Bitonic sorting network. Sorts the passed array such that", "code": "import data.function\nimport data.optional as Opt\nimport data.order    as Ord\nimport data.tuple    as P\nimport numeric.int.operator\nimport type.coerce\nimport type.stdtype\n\ntemplate <typename T, auto N>\nusing array = T[N];\n\ntemplate <auto N, typename T>\ninline T[N] bitonic_comparator(T[N] x, (T, T)->bool cmp)\n{\n    sim_assert(N % 2 == 0);\n    const auto half_N = N / 2;\n    T[N] y;\n  static for (const auto i : half_N)\n    {\n        bool cmp_flag = cmp(x[i], x[i + half_N]);\n        y[i] = cmp_flag ? x[i] : x[i + half_N];\n        y[i + half_N] = cmp_flag ? x[i + half_N] : x[i];\n    }\n    return y;\n}"}
{"file": "data\\array.pd", "nl": "Given an array of `optional<T>`, return the last (highest array index) item with `is_valid` true. If there are no items with `is_valid` true, then the returned `optional<T>` has `is_valid` set to false.", "code": "// #### __Examples__\n//\n//     >>> last_valid<uint8>({{false, 0xAB}, {false, 0x22}});\n//     {false, 0xAB}\n//\n//     >>> last_valid<uint8>({{true, 0xCD}, {true, 0xFF}});\n//     {true, 0xFF}\nimport data.function\nimport data.optional as Opt\nimport data.order    as Ord\nimport data.tuple    as P\nimport numeric.int.operator\nimport type.coerce\nimport type.stdtype\n\ntemplate <typename T, auto N> \ninline optional<T> last_valid(optional<T>[N] x) { \n    return reduce(selecting(on2nd(not(Opt::is_valid<T>))), x); \n}"}
{"file": "data\\array.pd", "nl": "Gather entries in data that are marked as valid to the front of an array,", "code": "template <typename T, auto N>\ninline P::pair<T[N],count_t<N>> gather(bool[N] valids, T[N] data)\n{\n    // Prefix sum to number each valid entry\n    auto valids_prefix_sum = prefix_sum<count_t<N>>(cast<uint1[N]>(valids));\n    // Gather into results array\n    T[N] result;\n    static for (const auto i : N)\n    {\n        // Mark data entries that could be the i-th valid\n        optional<T>[N] finds;\n        static for (const auto j : N)\n        {\n            // Only consider entries that are after i since the (i-1)th\n            // entry of a prefix_sum of a uint1 array cannot exceed i\n            if (j >= i)\n            {\n                // Examine valids_prefix_sum[j-1] for efficiency, with\n                // exception for j == 0\n                if (j == 0)\n                    finds[j] = Opt::make_optional(0 == i, data[j]);\n                else\n                    finds[j] = Opt::make_optional(valids_prefix_sum[j-1] == i, data[j]);\n            }\n        }\n        // Select the last one, since this entry (position i-1) is the one\n        // that causes the next entry (position i) to increment\n        auto find = last_valid<T>(finds);\n        result[i] = find.value;\n    }\n    return P::make_pair(result, valids_prefix_sum[N-1]);\n}"}
{"file": "data\\array.pd", "nl": "Transpose rows and columns in a 2-dimensional array.", "code": "template <typename T, auto I, auto J> inline T[J][I] transpose(T[I][J] src) { T[J][I] result;  static for (const auto i : I) { static for (const auto j : J) { result[j][i] = src[i][j]; } }  return result; }"}
{"file": "data\\array.pd", "nl": "Scatter the entries in data into the entries marked as true in the valid", "code": "template <typename T, auto N>\ninline P::pair<T[N],count_t<N>> scatter(bool[N] valids, T[N] data)\n{\n    // Prefix sum to number valid entries in result\n    auto valids_prefix_sum = prefix_sum<count_t<N>>(cast<uint1[N]>(valids));\n    // Scatter into results array\n    T[N] result;\n    static for (const auto i : N)\n    {\n        if (valids[i])\n        {\n            if (i == 0)\n                result[i] = data[0];\n            else\n                result[i] = data[valids_prefix_sum[i-1]];\n        }\n    }\n    return P::make_pair(result, valids_prefix_sum[N-1]);\n}"}
{"file": "data\\array.pd", "nl": "Shift the elements of an arbitrary-typed array right by the given number", "code": "inline T[M] shift_array_right(T[N] data, U amount) { // Require U be unsigned\n static assert(cast<U>(-1) > 0);  T[M] out; const auto Size = 1 << bitsizeof(U); static for(const auto i : M) { T[Size] data_i; static for(const auto j : Size) if (i + j < N) data_i[j] = data[i + j]; out[i] = data_i[amount]; } return out;}"}
{"file": "data\\array.pd", "nl": "Shift the elements of an arbitrary-typed array left by the given number of positions, with the possibility of returning a different number of elements as the input array.", "code": "inline T[M] shift_array_left(T[N] data, U amount) { // Require U be unsigned\n static assert(cast<U>(-1) > 0);  T[M] out; const auto Size = 1 << bitsizeof(U); static for(const auto i : M) { T[Size] data_i; static for(const auto j : Size) { const auto i_minus_j = i - j; if (i_minus_j >= 0 && i_minus_j < N) data_i[j] = data[i_minus_j]; } out[i] = data_i[amount]; } return out; }"}
{"file": "data\\array.pd", "nl": "// Function: rotate_array. Common code for rotate_array_right and rotate_array_left. This helper function applies the Narrow/rotate arrays optimization from effective-sandpiper.md to reduce area. RotateRight - rotate right if true. rotate left if false.", "code": "template <auto M, typename T, auto N, typename U, bool RotateRight>\ninline T[M] rotate_array(T[N] data, U amount)\n{\n    static if (N > 1)\n    {\n        static assert(bitsizeof(U) <= clog2(N));\n        // Require U be unsigned\n        static assert(cast<U>(-1) > 0);\n        // Workaround bug 13575\n        const auto N_min_2 = (N >= 2) ? N : 2;\n        // Convert U to an array of uint2\n        const auto U_Width_2 = (bitsizeof(U) + 1) / 2;\n        uint2[U_Width_2] U_uint2 = reinterpret_cast<uint2[U_Width_2]>(concat(0_u1, amount));\n        static assert(bitsizeof(U_uint2) == bitsizeof(amount) || bitsizeof(U_uint2) == bitsizeof(amount) + 1);\n        // Each iteration, use 2 bits of U to shift\n        static for (const auto i : U_Width_2)\n        {\n            // Constant shifts of last round by 0, 1 << i, 2 << i, and 3 << i.\n            T[4][N] rotated_data;\n            static for (const auto j : 4)\n            {\n                const auto Shift = j << (2 * i);\n                if (RotateRight)\n                {\n                    static for (const auto k : N)\n                    {\n                        rotated_data[j][k] = data[static((k + Shift) % N_min_2)];\n                    }\n                }\n                else\n                {\n                    // Bias is Shift round up to the nearest multiple N - used to ensure that array index cannot be negative\n                    const auto Bias = ((Shift + N) / N) * N;\n                    const auto Offset = cast<index_t<N>>((Bias - Shift) % N_min_2);\n                    static for (const auto k : N)\n                    {\n                        rotated_data[j][k] = data[static((k + Offset) % N_min_2)];\n                    }\n                }\n            }\n            // Select between possible rotations depending on actual value of U\n            static for (const auto k : N)\n            {\n                data[k] = mux(U_uint2[i], rotated_data[0][k], rotated_data[1][k], rotated_data[2][k], rotated_data[3][k]);\n            }\n        }\n    }\n    // Construct output\n    T[M] out;\n    static for (const auto i : M)\n    {\n        out[i] = data[i];\n    }\n    return out;\n}"}
{"file": "data\\array.pd", "nl": "Rotate the elements of an arbitrary-typed array right by the given number of positions, with the possibility of returning a different number of elements as the input array.", "code": "inline T[M] rotate_array_right(T[N] data, U amount) { // Workaround bug 30568 // sim_assert(amount < N);  return rotate_array<M, T, N, U, true>(data, amount); }"}
{"file": "data\\array.pd", "nl": "Rotate the elements of an arbitrary-typed array left by the given number", "code": "inline T[M] rotate_array_left(T[N] data, U amount) { sim_assert(amount < N);  return rotate_array<M, T, N, U, false>(data, amount); }"}
{"file": "data\\array.pd", "nl": "Map array of input values to result values.", "code": "template <typename T, auto N> inline auto map((T) -> auto f, T[N] x) { using result_t = decltype(f(x[0]));  result_t[N] r;  static for(const auto i : N) { r[i] = f(x[i]); }     return r; }"}
{"file": "data\\array.pd", "nl": "Map array of indices to result values.", "code": "template <auto N> inline auto map_indices((index_t<N>) -> auto f) { return map(f, template indices<N>()); }"}
{"file": "data\\array.pd", "nl": "Implement a binary reducer tree using a function to reduce a pair of inputs.", "code": "template <typename T, auto N>\ninline T reduce((T, T) -> T f, T[N] x)\n{\n    static if (N == 1)\n    {\n        return x[0];\n    }\n    else\n    {\n        // Combine adjacent elements in x\n        const auto NewN = (N + 1) / 2;\n        T[NewN] new_array;\n        static for(const auto i : N/2)\n        {\n            new_array[i] = f(x[2*i], x[2*i + 1]);\n        }\n        // carry odd case\n        static if ((N % 2) == 1)\n        {\n            new_array[NewN - 1] = x[N - 1];\n        }\n        return reduce(f, new_array);\n    }\n}"}
{"file": "data\\array.pd", "nl": "Implements map-reduce. Inputs are first mapped into the appropriate result type, and then reduced to a single output using a binary reduction tree.", "code": "template <typename T, auto N, typename R> inline R map_reduce((T) -> R map_fn, (R, R) -> R reduce_fn, T[N] x) { return reduce(reduce_fn, map(map_fn, x)); }"}
{"file": "data\\array.pd", "nl": "Returns true if any of the elements are true.", "code": "template <auto N> inline bool or(bool[N] x) { return reduce( [](bool x, bool y) { return x || y; }, x); }"}
{"file": "data\\array.pd", "nl": "Returns true if all of the elements are true.", "code": "template <auto N> inline bool and(bool[N] x) { return reduce( [](bool x, bool y) { return x && y; }, x); }"}
{"file": "data\\array.pd", "nl": "Returns true if any of the elements of array satisfies the predicate.", "code": "template <typename T, auto N> inline bool any((T) -> bool predicate, T[N] x) { return or(map(predicate, x)); }"}
{"file": "data\\array.pd", "nl": "Returns true if all elements of the array satisfy the predicate.", "code": "template <typename T, auto N> inline bool all((T) -> bool predicate, T[N] x) { return and(map(predicate, x)); }"}
{"file": "data\\array.pd", "nl": "Combines elements of two arrays using specified function.", "code": "template <typename S, typename T, auto N> inline auto zip_with((S, T) -> auto f, S[N] x, T[N] y) { using result_t = decltype(f(x[0], y[0]));  result_t[N] r;  static for(const auto i : N) { r[i] = f(x[i], y[i]); }     return r;}"}
{"file": "data\\array.pd", "nl": "Map array of input values and their indices to result values.", "code": "template <typename T, auto N> inline auto zip_with_indices((index_t<N>, T) -> auto f, T[N] x) { return zip_with(f, template indices<N>(), x); }"}
{"file": "data\\array.pd", "nl": "Combines two arrays into an array of pairs.", "code": "template <typename T1, typename T2, auto N> inline P::pair<T1, T2>[N] zip(T1[N] x, T2[N] y) { return zip_with(P::make_pair<T1, T2>, x, y); }"}
{"file": "data\\array.pd", "nl": "Returns array with each element value equal to its index.", "code": "template <auto N /*< Array length*/, typename T = index_t<N> /*< Element type*/> inline T[N] indices() { T[N] x;  static for(const auto i : N) { x[i] = i; } return x;}"}
{"file": "data\\array.pd", "nl": "Returns minimum element from an array of integers.", "code": "template <typename T, auto N> inline T minimum(T[N] x) { return reduce(selecting(Ord::less_than), x); }"}
{"file": "data\\array.pd", "nl": "Returns maximum value in the array of integers.", "code": "template <typename T, auto N> inline T maximum(T[N] x) { return reduce(selecting(Ord::greater_than), x); }"}
{"file": "data\\array.pd", "nl": "Sum elements in an array.", "code": "template <typename R, typename T, auto N> inline R sum(T[N] x) { return map_reduce(static_cast<R>, add<R, R>, x); }"}
{"file": "data\\array.pd", "nl": "Given an array of `optional<T>`, return the first (lowest array index) item", "code": "template <typename T, auto N> inline optional<T> first_valid(optional<T>[N] x) { return reduce(selecting(on1st(Opt::is_valid<T>)), x); }"}
{"file": "data\\array.pd", "nl": "Copies an array or creates a subset of an array.", "code": "template < typename T, auto N     //< Source array length\n, auto M     //< Destination array length.\n>\ninline T[M] copy_array\n    ( T[N] source\n    , index_t<N> s_first          //< The index of the first element of the\n                                  //  source array to copy to the destination\n                                  //  array.\n    , T[M] destination\n    , index_t<M> d_first          //< The index in the destination array to\n                                  //  copy the first element to.\n    , count_t<N> elements_to_copy //< The number of array elements to copy\n                                  //  from source to destination.\n    )\n{\n    // Array boundary checks:\n    sim_assert(elements_to_copy + s_first <= N);\n    sim_assert(elements_to_copy + d_first <= M);\n    auto src_dest_offset = s_first - d_first;\n    static for (const auto i : M)\n    {\n        if (i >= d_first && i < (d_first + elements_to_copy))\n        {\n            destination[i] = source[i + src_dest_offset];\n        }\n    }\n    return destination;\n}"}
{"file": "data\\array.pd", "nl": "De-duplicate array elements with user-supplied equality predicate.", "code": "template <typename T, auto N>\ninline optional<T>[N] unique_by\n    ( (T, T) -> bool equality_fn //< Equality predicate.\n    , T[N] xs\n    )\n{\n    template <auto I>\n    inline optional<T>[N] remove_dups((T, T) -> bool eq_fn, optional<T>[N] ys)\n    {\n        static assert(I < N);\n        static if (I != 0)\n        {\n            bool[I] dups;\n            static for(const auto j : I)\n                dups[j] = eq_fn(ys[j].value, ys[I].value);\n            ys[I].is_valid = !or(dups);\n            return remove_dups<I - 1>(eq_fn, ys);\n        }\n        else\n        {\n            return ys;\n        }\n    }\n    return remove_dups<N - 1>(equality_fn, map(Opt::just, xs)); }"}
{"file": "data\\array.pd", "nl": "De-duplicate array elements. Similar to `unique_by` but uses the `==` operator. For each element e, check the previous elements for duplicates. If there are any duplicates, mark element e as invalid. Returns an array of optionals where all valid elements are unique.", "code": "template <typename T, auto N> inline optional<T>[N] unique(T[N] xs) { return unique_by(Ord::equal, xs); }"}
{"file": "data\\array.pd", "nl": "Element-wise equality comparison of arrays using specified function.", "code": "template <typename T, auto N> inline bool equal_by((T, T) -> bool equality_fn, T[N] xs, T[N] ys) { return and(zip_with(equality_fn, xs, ys)); }"}
{"file": "data\\array.pd", "nl": "Element-wise comparison of arrays for equality using `==`.", "code": "template <typename T, auto N> inline bool equal(T[N] xs, T[N] ys) { return equal_by(Ord::equal, xs, ys); }"}
{"file": "data\\array.pd", "nl": "Transform an array into a pair of arrays using a projection.", "code": "template\n    < typename L //< Type of first projection of T.\n    , typename R //< Type of second projection of T.\n    , typename T //< Input array element type.\n    , auto N     //< Array length.\n    >\ninline P::pair<L[N], R[N]> unzip_with\n    ( (T) -> P::tuple2<L, R> f  //< Mapping from input array element to pair of\n                             //  result elements.\n    , T[N] xs\n    )\n{\n    P::pair<L[N], R[N]> result;\n    static for(const auto i : N)\n    {\n        auto p = f(xs[i]);\n        result.first[i] = p.first;\n        result.second[i] = p.second;\n    }\n    return result;\n}"}
{"file": "data\\array.pd", "nl": "Transform an array of pairs into a pair of arrays.", "code": "template <typename L, typename R, auto N> inline P::pair<L[N], R[N]> unzip(P::tuple2<L, R>[N] xs) { return unzip_with<L, R>(id, xs); }"}
{"file": "data\\array.pd", "nl": "Construct an array with all elements equal to the same value", "code": "template <auto N, typename T> inline T[N] replicate(T value) { T[N] result;  static for (const auto i : N) { result[i] = value; } return result;}"}
{"file": "data\\array.pd", "nl": "Return an array of repeated applications of `f` to `x`.", "code": "template <auto N, typename T> inline T[N] iterate((T) -> T f, T x) { static assert(N > 0); T[N] result; result[0] = x; static for(const auto i : N - 1) result[i+1] = f(result[i]); return result; }"}
{"file": "data\\array.pd", "nl": "Access element `i`. Equivalent to `x[i]`. If `i` is greater than or", "code": "template <typename T, auto N> inline T at(T[N] x, index_t<N> i) { sim_assert(i < N); return x[i]; }"}
{"file": "data\\array.pd", "nl": "Return the first element in the array. Equivalent to `x[0]`.", "code": "template <typename T, auto N> inline T front(T[N] x) { return x[0]; }"}
{"file": "data\\array.pd", "nl": "Return the last element in the vector. Equivalent to `x[N - 1]`.", "code": "template <typename T, auto N> inline T back(T[N] x) { return x[N - 1]; }"}
{"file": "data\\function.pd", "nl": "Identity function.", "code": "inline auto id(auto x) { return x; }"}
{"file": "data\\function.pd", "nl": "Return a generic closure which ignores its argument and always returns `x`", "code": "inline auto constant(auto x) { using return_t = decltype(x);  return [x](auto y) -> return_t { return x; }; }"}
{"file": "data\\function.pd", "nl": "Function composition", "code": "inline auto compose((auto) -> auto f, (auto) -> auto g) { return [f, g](auto x) { return f(g(x)); }; }"}
{"file": "data\\function.pd", "nl": "Composition with a binary function", "code": "inline auto compose2((auto) -> auto f, (auto, auto) -> auto g) { return [f, g](auto x, auto y) { return f(g(x, y)); }; }"}
{"file": "data\\function.pd", "nl": "Apply one argument to a curried function", "code": "inline auto apply((auto) -> auto f, auto x) { return f(x); }"}
{"file": "data\\function.pd", "nl": "Curry a binary function", "code": "inline auto curry((auto, auto) -> auto f) { return [f](auto x) { return [f, x](auto y) { return f(x, y); }; }; }"}
{"file": "data\\function.pd", "nl": "Convert a curried function into uncurried unary function", "code": "inline auto uncurry1((auto) -> auto f) { return [f](auto x) { auto g = f(x); return g(); }; }"}
{"file": "data\\function.pd", "nl": "Convert a curried function into uncurried binary function", "code": "inline auto uncurry((auto) -> auto f) { return [f](auto x, auto y) { auto g = f(x); return g(y); }; }"}
{"file": "data\\function.pd", "nl": "Convert a curried function into uncurried three parameter function", "code": "inline auto uncurry3((auto) -> auto f) { return [f](auto x, auto y, auto z) { auto g = f(x); auto h = g(y); return h(z); }; }"}
{"file": "data\\function.pd", "nl": "Bind a value to the function argument", "code": "inline auto bind((auto) -> auto f, auto x) { return [f, x]() { return f(x); }; }"}
{"file": "data\\function.pd", "nl": "Bind a value to the first argument of a function", "code": "inline auto bind1st((auto, auto) -> auto f, auto x) { return apply(curry(f), x); }"}
{"file": "data\\function.pd", "nl": "Apply a function to the first argument", "code": "inline auto on1st((auto) -> auto f) { return [f](auto x, auto y) { return f(x); }; }"}
{"file": "data\\function.pd", "nl": "Bind a value to the second argument of a function", "code": "inline auto bind2nd((auto, auto) -> auto f, auto y) { return apply(curry(flip(f)), y); }"}
{"file": "data\\function.pd", "nl": "Apply a function to the second argument", "code": "inline auto on2nd((auto) -> auto f) { return [f](auto x, auto y) { return f(y); }; }"}
{"file": "data\\function.pd", "nl": "Return true if the unary predicate is false", "code": "inline auto not((auto) -> bool f) { return compose(operator_not, f); }"}
{"file": "data\\function.pd", "nl": "Return true if the binary predicate is false", "code": "inline auto not2((auto, auto) -> bool f) { return compose2(operator_not, f); }"}
{"file": "data\\function.pd", "nl": "Select one of two arguments using the binary predicate", "code": "inline auto selecting((auto, auto) -> bool f) { return [f](auto x, auto y) { return f(x, y) ? x : y; }; }"}
{"file": "data\\function.pd", "nl": "Flip function parameters", "code": "inline auto flip((auto, auto) -> auto f) { return [f](auto x, auto y) { return f(y, x); }; }"}
{"file": "data\\function.pd", "nl": "Compose the function `N` times.", "code": "template <auto N> inline auto compose_endo((auto) -> auto f) { static assert(N > 0); static if (N == 1) return f; else return compose(f, compose_endo<N - 1>(f)); }"}
{"file": "data\\representation.pd", "nl": "Generate a onehot of the specified width.  A onehot is an array of booleans with a single value set to true.  Calling with `OutputWidth` 8 and `index` 1 returns an array of 8 bools with only bool 1 set to true.  Or in binary, 00000010.", "code": "template<auto OutputWidth, typename T>\ninline bool[OutputWidth] binary_to_one_hot(T index)\n{\n    // Make sure x isn't too large for the output array.\n    // For example, it's not possible to set the 5th boolean in a 3 element array.\n    sim_assert(index < OutputWidth);\n    bool[OutputWidth] result = {};\n    result[index] = true;\n    return result;\n}"}
{"file": "data\\representation.pd", "nl": "Change a value from big endian to little endian, or vice versa. // The input type must be of a size that's a multiple of 8 bits.", "code": "template<typename T>\ninline T endian_change(T input)\n{\n    uint8[bytesizeof(T)] inputAsArray = cast<uint8[bytesizeof(T)]>(input);\n    uint8[bytesizeof(T)] result;\n    static for (const auto i : bytesizeof(T))\n    {\n        result[i] = inputAsArray[static(bytesizeof(T) - i - 1)];\n    }\n    return cast<T>(result);\n}"}
{"file": "data\\representation.pd", "nl": "Similar to `mux`, but takes a `onehot` rather than an index as the first parameter. Also takes an array rather than a variable number of arguments for the selection list. The least significant bit in the onehot corresponds to index 0 in the data array.", "code": "template<typename T, auto Count>\ninline T onehot_mux(uint<Count> onehot, T[Count] data)\n{\n    uint<bitsizeof(T)>[Count] map;\n    bool[Count] bool_onehot = cast<bool[Count]>(onehot);\n    uint<bitsizeof(T)> bitwise_or(uint<bitsizeof(T)> x, uint<bitsizeof(T)> y)\n    {\n        return x | y;\n    }\n    // Can't use map here because that doesn't pass the index to the map function.\n    static for(const auto i : Count)\n    {\n        if (bool_onehot[i])\n        {\n            map[i] = cast<uint<bitsizeof(T)>>(data[i]);\n        }\n    }\n    uint<bitsizeof(T)> result = reduce(bitwise_or, map);\n    return cast<T>(result);\n}"}
{"nl": "Return true if the input is even.", "code": "inline bool even(auto a) {    return a % 2 == 0;}"}
{"nl": "Return true if the input is odd.", "code": "inline bool odd(auto a){    return !even(a);}"}
{"file": "data\\counter.pd", "nl": "Return the current count.", "code": "import numeric.int.operator.modular as modular\ninline ctr_t count() {\n    ctr_t result;\n    atomic\n    {\n        result = modular::sub(_first, _second);\n    }\n    return result; }"}
{"file": "data\\counter.pd", "nl": "Add one to the counter.", "code": "inline void increment() {    add(1); }"}
{"file": "data\\counter.pd", "nl": "Add amount to the counter.", "code": "inline void add(ctr_t amount) {\n    atomic\n    {\n        _first = modular::add(_first, amount);\n    }\n}"}
{"file": "data\\counter.pd", "nl": "Subtract one from the counter.", "code": "inline void decrement() {  subtract(1);}"}
{"file": "data\\counter.pd", "nl": "Subtract amount from the counter.", "code": "inline void subtract(ctr_t amount) {\n    atomic\n    {\n        _second = modular::add(_second, amount);\n    }\n}"}
{"file": "numeric\\float32.pd", "nl": "Check `x` is not a number.", "code": "inline bool isnan(float32 x)\n{\n    const auto flags = getSpecialCases<Denorm::On>(cast<float32PackedFormat>(x));\n    return flags.nan;\n}"}
{"file": "numeric\\float32.pd", "nl": "Check `x` is positive or negative infinity.", "code": "inline bool isinf(float32 x)\n{\n    const auto flags = getSpecialCases<Denorm::On>(cast<float32PackedFormat>(x));\n    return flags.inf;\n}"}
{"file": "numeric\\float32.pd", "nl": "Return sign of `x`.", "code": "inline bool signbit(float32 x)\n{\n    const auto s = cast<float32PackedFormat>(x);\n    return s.sign == 1;\n}"}
{"file": "numeric\\float32.pd", "nl": "Addition of two float values.", "code": "inline float32 add(float32 in1, float32 in2)\n{\n    float32 result;\n    if (denorm_mode == Denorm::On)\n    {\n        result = float32_add(in1, in2);\n    }\n    else\n    {\n        result = float32_add_denormoff(in1, in2);\n    }\n    return result;\n}"}
{"file": "numeric\\float32.pd", "nl": "Multiplication of two float values.", "code": "inline float32 mul(float32 in1, float32 in2)\n{\n    float32 result;\n    if (denorm_mode == Denorm::On)\n    {\n        result = float32_mul(in1, in2);\n    }\n    else\n    {\n        result = float32_mul_denormoff(in1, in2);\n    }\n    return result;\n}"}
{"file": "numeric\\float32.pd", "nl": "Compare two float32 values for equality.", "code": "inline bool eq(float32 in1, float32 in2)\n{\n    // Unpack input\n    float32PackedFormat a;\n    float32PackedFormat b;\n    a = cast<float32PackedFormat>(in1);\n    b = cast<float32PackedFormat>(in2);\n\n    // Get zero, nan, or inf\n    specialCaseFlags a_flags = getSpecialCases<denorm_mode>(a);\n    specialCaseFlags b_flags = getSpecialCases<denorm_mode>(b);\n\n    bool result;\n    // Negative and positive zero are equal\n    if (a_flags.zero && b_flags.zero)\n    {\n        result = true;\n    }\n    // NaNs are not equal\n    else if (a_flags.nan || b_flags.nan)\n    {\n        result = false;\n    }\n    else\n    {\n        result = cast<uint32>(in1) == cast<uint32>(in2);\n    }\n\n    return result;\n}"}
{"file": "numeric\\float32.pd", "nl": "Check `in1` less than `in2`.", "code": "inline bool lt(float32 in1, float32 in2)\n{\n    // Unpack input\n    float32PackedFormat a;\n    float32PackedFormat b;\n    a = cast<float32PackedFormat>(in1);\n    b = cast<float32PackedFormat>(in2);\n\n    // Get zero, nan, or inf\n    specialCaseFlags a_flags = getSpecialCases<denorm_mode>(a);\n    specialCaseFlags b_flags = getSpecialCases<denorm_mode>(b);\n\n    bool result;\n    // Check equal\n    if (eq<denorm_mode>(in1, in2))\n    {\n        result = false;\n    }\n    // NaN\n    else if (a_flags.nan || b_flags.nan)\n    {\n        result = false;\n    }\n    // a negative, b positive or zero\n    else if (a.sign == 1 && (b_flags.zero || b.sign == 0))\n    {\n        result = true;\n    }\n    // b negative, a positive or zero\n    else if (b.sign == 1 && (a_flags.zero || a.sign == 0))\n    {\n        result = false;\n    }\n    // same sign\n    else\n    {\n        result = concat(a.exponent, a.mantissa) < concat(b.exponent, b.mantissa);\n        // Reverse if negative\n        if (a.sign == 1)\n        {\n            result = !result;\n        }\n    }\n    return result;\n}"}
{"file": "numeric\\float32.pd", "nl": "Check `in1` greater than `in2`.", "code": "inline bool gt(float32 in1, float32 in2)\n{\n    // Unpack input\n    float32PackedFormat a;\n    float32PackedFormat b;\n    a = cast<float32PackedFormat>(in1);\n    b = cast<float32PackedFormat>(in2);\n\n    // Get zero, nan, or inf\n    specialCaseFlags a_flags = getSpecialCases<denorm_mode>(a);\n    specialCaseFlags b_flags = getSpecialCases<denorm_mode>(b);\n\n    bool result;\n    if (a_flags.nan || b_flags.nan)\n    {\n        result = false;\n    }\n    else\n    {\n        result = !eq<denorm_mode>(in1, in2) && !lt<denorm_mode>(in1, in2);\n    }\n    return result;\n}"}
{"file": "numeric\\float32.pd", "nl": "Subtract `in2` from `in1`.", "code": "inline float32 sub(float32 in1, float32 in2)\n{\n    return add<denorm_mode>(in1, neg(in2));\n}"}
{"file": "numeric\\float32.pd", "nl": "Reciprocal `1 / x`.", "code": "inline float32 rcp(float32 x)\n{\n    auto binary32 = cast<float32PackedFormat>(x);\n    uint32 value = cast<uint32>(x);\n\n    if (binary32.exponent == 0)\n    {\n        value = (binary32.sign == 0)\n            ? float32_constants::POS_INFINITY\n            : float32_constants::NEG_INFINITY;\n    }\n    else if (value == float32_constants::POS_INFINITY)\n    {\n        value = float32_constants::POS_ZERO;\n    }\n    else if (value == float32_constants::NEG_INFINITY)\n    {\n        value = float32_constants::NEG_ZERO;\n    }\n    else if (binary32.exponent != 0xFF)\n    {\n        const auto significand = (1 << 23) | binary32.mantissa;\n\n        // approximate\n        const auto approxFbitCount = 8;\n        const uint<1 + approxFbitCount> approxValue = fixed_internal::rcp_lookup<23, approxFbitCount>(significand);\n\n        // 1st refinement\n        const auto refinedFbitCount_0 = 16;\n        const uint<1 + refinedFbitCount_0> refinedValue_0 =\n            fixed_internal::rcp_refine<23, approxFbitCount, refinedFbitCount_0>(significand, approxValue);\n\n        // 2nd refinement\n        const auto refinedFbitCount_1 = 25;\n        uint<1 + refinedFbitCount_1> refinedValue_1 =\n            fixed_internal::rcp_refine<23, refinedFbitCount_0, refinedFbitCount_1>(significand, refinedValue_0);\n\n        // Adjust the significand from ~(0.5, 1.0] to [1.0, 2.0).\n        bool is_one = (refinedValue_1 >> refinedFbitCount_1) == 1;\n        refinedValue_1 = is_one ? (refinedValue_1 >> 1) : refinedValue_1;\n        binary32.exponent = 254 - binary32.exponent;\n        binary32.exponent = cast<decltype(binary32.exponent)>(binary32.exponent - (is_one ? 0 : 1));\n\n        // round to 23 fraction bits\n        refinedValue_1 = (refinedValue_1 + (refinedValue_1 & 1)) >> 1;\n\n        if (binary32.exponent == 0 || binary32.exponent == 0xFF)\n        {\n            binary32.exponent = 0;\n            binary32.mantissa = 0;\n        }\n        else\n        {\n            binary32.mantissa = cast<decltype(binary32.mantissa)>(refinedValue_1);\n        }\n\n        value = cast<uint32>(binary32);\n    }\n\n    return cast<float32>(value);\n}"}
{"file": "numeric\\float32.pd", "nl": "$2^x$", "code": "inline float32 exp2(float32 x)\n{\n    const auto structValue = cast<float32PackedFormat>(x);\n    const uint32 binaryValue = cast<uint32>(x);\n\n    const uint32 binaryPositive128 = 0x43000000;\n    const uint32 binaryNegative126 = 0xC2FC0000;\n\n    const specialCaseFlags flags = getSpecialCases<Denorm::Off>(structValue);\n\n    const bool isNegative = signbit(x);\n    const bool isNegInf = flags.inf && isNegative;\n    const bool isPosInf = flags.inf && !isNegative;\n    const bool isOverflow = structValue.sign == 0 && structValue.exponent != 0xFF && binaryValue >= binaryPositive128;\n    const bool isUnderflow = structValue.sign == 1 && structValue.exponent != 0xFF && binaryValue > binaryNegative126;\n\n    const int8 exponent = structValue.exponent - 127;\n    const auto valueFbit = 23 + 7;\n    const auto valueMantissa = ((1 << 23) | structValue.mantissa) << 7;\n\n    const auto structResult =\n        exp2_internal<float32PackedFormat, 1, valueFbit, 23>( {valueMantissa, exponent, structValue.sign} );\n\n    // output\n    float32PackedFormat result;\n    result.sign = 0;\n    result.exponent = (isNegInf || isUnderflow) ? 0 :\n                        (isPosInf || isOverflow || flags.nan) ? 0xFF :\n                        flags.zero ? 127 : structResult.exponent;\n    result.mantissa = (isNegInf || isUnderflow || isPosInf || isOverflow || flags.zero) ? 0 :\n                        flags.nan ? 1 : structResult.mantissa;\n\n    return cast<float32>(result);\n}"}
{"file": "numeric\\float32.pd", "nl": "$e^x$", "code": "inline float32 exp(float32 x)\n{\n    const auto structValue = cast<float32PackedFormat>(x);\n    const uint32 binaryValue = cast<uint32>(x);\n\n    const uint32 MAX_EXP_INPUT = 0x42B17218;    // max input 88.7228393555\n    const uint32 MIN_EXP_INPUT = 0xC2AEAC50;    // min input -87.3365478516\n\n    const specialCaseFlags flags = getSpecialCases<Denorm::Off>(structValue);\n\n    const bool isNegative = signbit(x);\n    const bool isNegInf = flags.inf && isNegative;\n    const bool isPosInf = flags.inf && !isNegative;\n    const bool isOverflow = structValue.sign == 0 && structValue.exponent != 0xFF && binaryValue >= MAX_EXP_INPUT;\n    const bool isUnderflow = structValue.sign == 1 && structValue.exponent != 0xFF && binaryValue >= MIN_EXP_INPUT;\n\n    // translate exp to exp2\n    const int8 exponent = structValue.exponent - 127;\n    const auto significand = (1 << 23) | structValue.mantissa;\n    const auto translatedMantissaFbit = 75;\n    const auto translatedMantissa = exp2_translate<23, translatedMantissaFbit>(significand);\n\n    const auto structResult =\n        exp2_internal<float32PackedFormat, 2, translatedMantissaFbit, 23>( {translatedMantissa, exponent, structValue.sign} );\n\n    // output\n    float32PackedFormat result;\n    result.sign = 0;\n    result.exponent = (isNegInf || isUnderflow) ? 0 :\n                        (isPosInf || isOverflow || flags.nan) ? 0xFF :\n                        flags.zero ? 127 : structResult.exponent;\n    result.mantissa = (isNegInf || isUnderflow || isPosInf || isOverflow || flags.zero) ? 0 :\n                        flags.nan ? 1 : structResult.mantissa;\n\n    return cast<float32>(result);\n}"}
{"file": "numeric\\float32.pd", "nl": "Calculate $e^x - 1$. Denorm inputs and outputs are supported.", "code": "inline float32 expm1(float32 x)\n{\n    const auto structX = cast<float32PackedFormat>(x);\n    const auto binaryX = cast<uint32>(x);\n    const auto flags = getSpecialCases<Denorm::On>(structX);\n\n    float32PackedFormat result;\n    const int8 exponent = structX.exponent - 127;\n    const bool isSmallValue = (exponent < -23) && !flags.inf;\n\n    if(isSmallValue)\n    {\n        result = structX;\n    }\n    else\n    {\n        const bool isNegativeX = structX.sign == 1;\n        const bool isOutputInf = !isNegativeX && structX.exponent != 0xFF && binaryX >= 0x42B17218;\n        const bool isOutputMinus1 = isNegativeX && structX.exponent != 0xFF && binaryX >= 0xC18AA123;\n        const bool isPosInfinity = flags.inf && !isNegativeX;\n        const bool isNegInfinity = flags.inf && isNegativeX;\n\n        // change base to exp2\n        const auto Fbit = 47;\n        const auto exp2ValueSignificand = exp2_translate<23, Fbit>((1 << 23) | structX.mantissa);\n\n        // The exponent of max input is 6 of max input(0x42B17218).\n        const uint55 exp2Value = (exp2ValueSignificand << 6) >> (6 - exponent);\n        const auto temp = cast<tuple2<uint<Fbit>, uint<8>>>(exp2Value);\n        const auto integer = temp.second;\n        const auto fraction = temp.first;\n\n        // Compute exp2m1\n        const auto exp2m1Fbit = 47;\n        const auto exp2Fraction = exp2m1_lookup<Fbit, exp2m1Fbit>(isNegativeX, fraction);\n\n        int<1 + exp2m1Fbit> exp2m1;\n        if(integer == 0)\n        {\n            exp2m1 = exp2Fraction;\n        }\n        else\n        {\n            if(isNegativeX)\n            {\n                // Add 1 to exp2Fraction and divide by 2^integer, then subtract 1.\n                // if exp2Fraction is negtive, int<1 + F>(exp2Fraction) + (1 << F) = uint<F>(exp2Fraction).\n                const auto plus1 = cast<uint<exp2m1Fbit>>(exp2Fraction);\n                exp2m1 = (plus1 >> integer) - (1 << exp2m1Fbit);\n            }\n            else\n            {\n                // Multiply exp2Fraction by 2^integer and subtract 1.\n                exp2m1 = cast<decltype(exp2m1)>(exp2Fraction - (1 << (exp2m1Fbit - integer)));\n            }\n        }\n\n        // convert to float\n        const bool isNegativeExp2m1 = exp2m1 < 0;\n        const auto absValue = isNegativeExp2m1 ? -exp2m1 : exp2m1;\n        const auto leadingOneIndex = highest_one<uint24>(absValue >> (exp2m1Fbit - 24));\n\n        int8 exponentResult;\n        uint<exp2m1Fbit> mantissaResult;\n        if(integer > 0 && !isNegativeX)\n        {\n            exponentResult = cast<decltype(exponentResult)>(isNegativeExp2m1 ? (integer - 1) : integer);\n            mantissaResult = cast<decltype(mantissaResult)>(isNegativeExp2m1 ? (exp2m1 << 1) : exp2m1);\n        }\n        else\n        {\n            exponentResult = leadingOneIndex.value - 24;\n            mantissaResult = cast<decltype(mantissaResult)>(absValue << (-exponentResult));\n        }\n\n        const auto truncatedMantissa = mantissaResult >> (exp2m1Fbit - 24);\n        const auto roundedMantissa = (truncatedMantissa >> 1) + (truncatedMantissa & 1);\n        exponentResult = cast<decltype(exponentResult)>(exponentResult + (cast<uint1>(roundedMantissa >> 23) + 127));\n\n        // output\n        result.sign = cast<uint1>(isNegativeX);\n        result.exponent = (isNegInfinity || isOutputMinus1) ? 127 :\n                        (isOutputInf || isPosInfinity || flags.nan) ? 0xFF : cast<decltype(result.exponent)>(exponentResult);\n        result.mantissa = flags.nan ? 0x1 :\n                        (isOutputInf || isOutputMinus1 || flags.inf) ? 0x0 : cast<decltype(result.mantissa)>(roundedMantissa);\n    }\n    return cast<float32>(result);\n}"}
{"file": "numeric\\float32.pd", "nl": "$log_2(x)$", "code": "inline float32 log2(float32 x)\n{\n    return log2_internal<1, 0>(x);\n}"}
{"file": "numeric\\float32.pd", "nl": "$ln(x)$", "code": "inline float32 log(float32 x)\n{\n    return log2_internal<0x2C5C860, 26>(x);\n}"}
{"file": "numeric\\float32.pd", "nl": "$log_{10}(x)$", "code": "inline float32 log10(float32 x)\n{\n    return log2_internal<0x1344135, 26>(x);\n}"}
{"file": "numeric\\float32.pd", "nl": "Calculate $ln(x+1)$. Denorm inputs and outputs are supported.", "code": "inline float32 log1p(float32 value)\n{\n    const auto structValueOriginal = cast<float32PackedFormat>(value);\n    const auto structValuePlusOne = cast<float32PackedFormat>(value + 1.0);\n\n    const auto binaryValue = cast<uint32>(value);\n    const specialCaseFlags flags = getSpecialCases<Denorm::On>(structValueOriginal);\n\n    const bool isUnderflow = structValueOriginal.sign == 1 && structValueOriginal.exponent != 0xFF && binaryValue > float32_constants::NEG_ONE;\n    const bool isNegative = signbit(value);\n    const bool isPosInfinity = flags.inf && !isNegative;\n    const bool isNegInfinity = flags.inf && isNegative;\n    const bool isPosZero = flags.zero && !isNegative;\n    const bool isNegZero = flags.zero && isNegative;\n    const bool isNegOne = binaryValue == float32_constants::NEG_ONE;\n    const bool isSmallValue = structValueOriginal.exponent < (127 - 23);\n\n    // calculate log2\n    // structValuePlusOne = [0.5, 2) use original precise fraction (before adding 1).\n    // Others use fixed 23-bit resolution fraction after adding 1.\n    const float32PackedFormat lookupFraction =\n        (structValuePlusOne.exponent == 126 || structValuePlusOne.exponent == 127) ? structValueOriginal : {structValuePlusOne.mantissa, 127, 0};\n\n    const auto fractionFbit = 46;\n    const auto log21pFraction = log21p_lookup<fractionFbit>(lookupFraction);\n\n    // When the exponent of structValuePlusOne equals to 126, The log21pValue doesn't need to be recovered by exponent.\n    // Because the log21pFraction is lookuped by the range structValuePlusOne = [0.5, 2).\n    const int8 exponent = (structValuePlusOne.exponent == 126 || structValuePlusOne.exponent == 127) ? 0 : (structValuePlusOne.exponent - 127);\n    const int<8 + fractionFbit> log21pValue = (exponent << fractionFbit) + log21pFraction;\n\n    // change base to log\n    const auto valueChangedBaseFBit = fractionFbit + 30;\n    const auto valueChangedBase = log21pValue * 0x2C5C85FE;\n\n    // convert to float\n    const auto sign = valueChangedBase < 0 ? 1 : 0;\n    const auto absValueFbit = valueChangedBaseFBit;\n    const auto absValue = sign ? -valueChangedBase : valueChangedBase;\n\n    const auto leadingOneIndex = highest_one<uint<(8 + 24)>>(absValue >> (absValueFbit - 24));\n    const auto shift = leadingOneIndex.value - 24;\n    int8 exponentResult = shift + 127;\n\n    sim_assert(absValueFbit + shift >= 24);\n    const auto truncatedValue = absValue >> (absValueFbit + shift - 24);\n    auto mantissaResult = (truncatedValue >> 1) + (truncatedValue & 1);\n\n    if ((mantissaResult >> 23) >= 2)\n    {\n        exponentResult += 1;\n        mantissaResult = mantissaResult >> 1;\n    }\n\n    float32PackedFormat result;\n    result.sign = (isPosInfinity || isPosZero) ? 0 :\n                  (isNegInfinity || isNegZero) ? 1 :\n                  isSmallValue ? structValueOriginal.sign : sign;\n    result.exponent = (isNegOne || flags.inf || flags.nan || isUnderflow) ? 0xFF :\n                      flags.zero ? 0x0 :\n                      isSmallValue ? structValueOriginal.exponent : exponentResult;\n    result.mantissa = (flags.nan || isNegInfinity || isUnderflow) ? 0x1 :\n                      (isNegOne || isPosInfinity || flags.zero) ? 0x0 :\n                      isSmallValue ? structValueOriginal.mantissa : cast<decltype(result.mantissa)>(mantissaResult);\n    return cast<float32>(result);\n}"}
{"file": "numeric\\float32.pd", "nl": "Calculate the floating-point value of the unbiased exponent part of `log(x)`.", "code": "inline float32 logb(float32 x)\n{\n    const auto s = cast<float32PackedFormat>(x);\n    const specialCaseFlags flags = getSpecialCases<Denorm::On>(s);\n    const bool isDenorm = (s.exponent == 0) && !flags.zero;\n    const auto leadingOne = highest_one<uint23>(s.mantissa);\n    const int9 value = isDenorm ? (leadingOne.value - 149) : (s.exponent - 127);\n\n    float32 result;\n    if(flags.zero)\n    {\n        result = cast<float32>(float32_constants::NEG_INFINITY);\n    }\n    else if(flags.inf)\n    {\n        result = cast<float32>(cast<uint32>(float32_constants::POS_INFINITY));\n    }\n    else if(flags.nan)\n    {\n        result = x;\n    }\n    else\n    {\n        result = int_to_float<int9, float32, _mantissa_width, _exponent_width, _exponent_bias>(value);\n    }\n    return result;\n}"}
{"file": "numeric\\float32.pd", "nl": "Return the signed integral value of the unbiased exponent part of `log(x)`.", "code": "inline int32 ilogb(float32 x)\n{\n    const auto s = cast<float32PackedFormat>(x);\n    const specialCaseFlags flags = getSpecialCases<Denorm::On>(s);\n    const bool isDenorm = (s.exponent == 0) && !flags.zero;\n    const auto leadingOne = highest_one<uint23>(s.mantissa);\n\n    const auto intMax = 0x7FFFFFFF;\n    const auto intMin = 0x80000000;\n    int32 result;\n    if (flags.inf)\n    {\n        result = intMax;\n    }\n    else if (flags.zero || flags.nan)\n    {\n        result = intMin;\n    }\n    else if (isDenorm)\n    {\n        result = leadingOne.value - 149;\n    }\n    else\n    {\n        result = s.exponent - 127;\n    }\n    return result;\n}"}
{"file": "numeric\\float32.pd", "nl": "Return the principal values of arctangent. Denorm inputs and outputs are supported.", "code": "inline float32 atan(float32 x)\n{\n    const auto structX = cast<float32PackedFormat>(x);\n    const auto flags = getSpecialCases<Denorm::Off>(structX);\n\n    uint32 binaryResult;\n    if (isnan(x))\n    {\n        binaryResult = float32_constants::DEFAULT_NAN;\n    }\n    else if (flags.zero || structX.exponent <= 115)\n    {\n        binaryResult = cast<uint32>(x);\n    }\n    else if (structX.exponent >= 150)\n    {\n        binaryResult = 0x3FC90FDB | (structX.sign << 31);\n    }\n    else\n    {\n        const uint6 relativeExponent = structX.exponent - 116;\n        const uint23 fraction = structX.mantissa;\n\n        const uint7 index_m11 = ((relativeExponent << 3)        | (fraction >> 20));\n        const uint9 index_m3  = (((relativeExponent - 8) << 5)  | (fraction >> 18)) + 64;\n        const uint9 index_5   = ((relativeExponent << 4)        | (fraction >> 19)) + 64;\n        const uint9 index_9   = (((relativeExponent - 20) << 3) | (fraction >> 20)) + 384;\n        const uint9 index = (relativeExponent < 16) ?\n            ((relativeExponent < 8)  ? index_m11 : index_m3) :\n            ((relativeExponent < 20) ? index_5 : index_9);\n\n        const auto RESIDUAL_FBIT = 20;\n        const uint<RESIDUAL_FBIT> residual = (relativeExponent < 16) ?\n            ((relativeExponent < 8)  ? fraction        : (fraction << 2)) :\n            ((relativeExponent < 20) ? (fraction << 1) : fraction);\n\n        const auto row = atan_table[index];\n\n        const auto c0 = row.c0;\n        const auto c1 = row.c1;\n        const auto c2 = row.c2;\n        const auto c3 = row.c3;\n        const auto exponentBase = row.exponent;\n\n        const auto product_3 = (residual * c3) >> (RESIDUAL_FBIT + ATAN_C3_FBIT - ATAN_C2_FBIT);\n        const auto product_2 = (residual * (c2 + product_3)) >> (RESIDUAL_FBIT + ATAN_C2_FBIT - ATAN_C1_FBIT);\n        const auto product_1 = (residual * (c1 + product_2)) >> (RESIDUAL_FBIT + ATAN_C1_FBIT - ATAN_C0_FBIT);\n        const uint26 mantissa26 = (c0 + product_1) >> (ATAN_C0_FBIT - 26);      // [0.25, 1) with 26 fraction bits\n\n        const uint25 mantissa24 = mux(cast<uint1>(mantissa26 >> 25), mantissa26, mantissa26 >> 1);\n        const auto   mantExpo24 = mux(cast<uint1>(mantissa26 >> 25), -1, 0);    // the initial -1 has been counted in exponentBase\n\n        const uint25 mantissa23 = (mantissa24 >> 1) + (mantissa24 & 1);\n        const auto   mantExpo23 = mantExpo24;\n\n        const uint24 mantissa = mux(cast<uint1>(mantissa23 >> 24), mantissa23, mantissa23 >> 1);\n        const auto   mantExpo = mantExpo23 + mux(cast<uint1>(mantissa23 >> 24), 0, 1);\n\n        const float32PackedFormat structResult = { mantissa, 127 + exponentBase + mantExpo, structX.sign};\n\n        binaryResult = cast<uint32>(structResult);\n    }\n\n    return cast<float32>(binaryResult);\n}"}
{"file": "numeric\\float32.pd", "nl": "$sin(x)$ with `x` in radians.", "code": "inline float32 sin(float32 x)\n{\n    const auto structValue = cast<float32PackedFormat>(x);\n    float32PackedFormat result;\n\n    const specialCaseFlags flags = getSpecialCases<Denorm::On>(structValue);\n\n    // x pass to result directly when input <= 2^-12\n    const bool isSmallValue = structValue.exponent <= 115;\n\n    const auto Fbit = 54;\n    const auto valueInPiOver2 = to_piOver2<Fbit, false>(structValue);\n\n    // table lookup\n    const auto isInternalSmallValue = valueInPiOver2.second.first;\n    const auto sineValue = isInternalSmallValue ? valueInPiOver2.second.second : sin_lookup<Fbit>(valueInPiOver2.second.second);\n\n    // output\n    result.sign = valueInPiOver2.first ^ structValue.sign;\n\n    const auto leadingOne = highest_one<uint<1 + 27>>(sineValue >> (Fbit - 27));\n    int8 exponent = leadingOne.value - 27;\n\n    sim_assert(Fbit + exponent >= 24);\n    const auto truncatedSineValue = sineValue >> (Fbit + exponent - 24);\n    const auto roundedSineValue = (truncatedSineValue >> 1) + (truncatedSineValue & 1);\n    exponent = exponent + (roundedSineValue >> 24);\n\n    result.exponent = (flags.nan || flags.inf) ? 0xFF : (exponent + 127);\n    result.mantissa = (flags.nan || flags.inf) ? 0x1 : cast<decltype(result.mantissa)>(roundedSineValue);\n\n    return isSmallValue ? x : cast<float32>(result);\n}"}
{"file": "numeric\\float32.pd", "nl": "$cos(x)$ with `x` in radians.", "code": "inline float32 cos(float32 x)\n{\n    const auto structValue = cast<float32PackedFormat>(x);\n    float32PackedFormat result;\n\n    const specialCaseFlags flags = getSpecialCases<Denorm::On>(structValue);\n\n    const auto Fbit = 54;\n    const auto valueInPiOver2 = to_piOver2<Fbit, true>(structValue);\n\n    // table lookup\n    const auto isInternalSmallValue = valueInPiOver2.second.first;\n    const auto cosineValue = isInternalSmallValue ? valueInPiOver2.second.second : cos_lookup<Fbit>(valueInPiOver2.second.second);\n\n    // output\n    result.sign = valueInPiOver2.first;\n\n    const auto leadingOne = highest_one<uint<1 + 27>>(cosineValue >> (Fbit - 27));\n    int8 exponent = leadingOne.value - 27;\n\n    sim_assert(Fbit + exponent >= 24);\n    const auto truncatedCosineValue = cosineValue >> (Fbit + exponent - 24);\n    const auto roundedCosineValue = (truncatedCosineValue >> 1) + (truncatedCosineValue & 1);\n    exponent = exponent + (roundedCosineValue >> 24);\n\n    result.exponent = (flags.nan || flags.inf) ? 0xFF : (exponent + 127);\n    result.mantissa = (flags.nan || flags.inf) ? 0x1 : cast<decltype(result.mantissa)>(roundedCosineValue);\n\n    return cast<float32>(result);\n}"}
{"file": "numeric\\float32.pd", "nl": "Return the smaller of `x` and `y`. A NaN is treated as missing data, and the other value will be returned.", "code": "inline float32 min(float32 x, float32 y)\n{\n    return (isnan(y) || lt<denorm_mode>(x, y)) ? x : y;\n}"}
{"file": "numeric\\float32.pd", "nl": "Return the larger of `x` and `y`. A NaN is treated as missing data, and the other value will be returned.", "code": "inline float32 max(float32 x, float32 y)\n{\n    return (isnan(y) || gt<denorm_mode>(x, y)) ? x : y;\n}"}
{"file": "numeric\\float32.pd", "nl": "Return the smallest integer not less than `x`: $\\lceil x \\rceil$", "code": "inline float32 ceil(float32 x)\n{\n    return ceil_internal<float32, _mantissa_width, _exponent_width, _exponent_bias, denorm_mode>(x);\n}"}
{"file": "numeric\\float32.pd", "nl": "Return the largest integer not greater than `x`: $\\lfloor x \\rfloor$", "code": "inline float32 floor(float32 x)\n{\n    return floor_internal<float32, _mantissa_width, _exponent_width, _exponent_bias, denorm_mode>(x);\n}"}
{"file": "numeric\\float32.pd", "nl": "Return the nearest integer to `x`, rounding halfway away from zero.", "code": "inline float32 round(float32 x)\n{\n    return round_internal<float32, _mantissa_width, _exponent_width, _exponent_bias, denorm_mode>(x);\n}"}
{"file": "numeric\\float32.pd", "nl": "Return the nearest integer not greater in magnitude than `x`.", "code": "inline float32 trunc(float32 x)\n{\n    return trunc_internal<float32, _mantissa_width, _exponent_width, _exponent_bias, denorm_mode>(x);\n}"}
{"file": "numeric\\float32.pd", "nl": "The positive difference between `x` and `y`: `max(x - y, 0)`. Return NaN if `x` or `y` is NaN.", "code": "inline float32 dim(float32 x, float32 y)\n{\n    float32 result;\n\n    if (isnan(x) || isnan(y))\n    {\n        result = cast<float32>(cast<uint32>(float32_constants::DEFAULT_NAN));\n    }\n    else\n    {\n        result = gt<denorm_mode>(x, y) ? sub<denorm_mode>(x, y) : 0.0;\n    }\n\n    return result;\n}"}
{"file": "numeric\\float32.pd", "nl": "Return the absolute value of `x`: $|x|$", "code": "template<Denorm denorm_mode>\ninline float32 abs(float32 x)\n{\n    auto structValue = cast<float32PackedFormat>(x);\n    structValue.sign = 0;\n    return cast<float32>(structValue);\n}"}
{"file": "numeric\\float32.pd", "nl": "Convert a signed integer to a float32.", "code": "inline float32 from_int(int<N> value)\n{\n    return int_to_float<int<N>, float32, _mantissa_width, _exponent_width, _exponent_bias>(value);\n}"}
{"file": "numeric\\float32.pd", "nl": "Convert an unsigned integer to a float32.", "code": "inline float32 from_uint(uint<N> value)\n{\n    return int_to_float<uint<N>, float32, _mantissa_width, _exponent_width, _exponent_bias>(value);\n}"}
{"file": "numeric\\float32.pd", "nl:": "//| Convert a float32 to a signed integer.", "code": "\ntemplate <auto N /*< Width of the signed integer.*/>\ninline optional<int<N>> to_int(float32 value)\n{\n    auto result = float_to_int<float32, int<N+1>, _mantissa_width, _exponent_width, _exponent_bias>(value);\n    if (result.is_valid)\n    {\n        auto limits = get_limits<int<N>>();\n        if ((result.value < limits.first) || (result.value > limits.second))\n            result.is_valid = false;\n    }\n    return make_optional<int<N>>(result.is_valid, cast<int<N>>(result.value));\n}"}
{"file": "numeric\\float32.pd", "nl": "//| Convert a float32 to an unsigned integer", "code": "template <auto N /*< Width of the unsigned integer.*/>\ninline optional<uint<N>> to_uint(float32 value)\n{\n    auto result = float_to_int<float32, uint<N+1>, _mantissa_width, _exponent_width, _exponent_bias>(value);\n    if (result.is_valid)\n    {\n        auto limits = get_limits<uint<N>>();\n        if ((result.value < limits.first) || (result.value > limits.second))\n            result.is_valid = false;\n    }\n    return make_optional<uint<N>>(result.is_valid, cast<uint<N>>(result.value));\n}"}
{"file": "data\\buffer.pd", "nl": "This function implements a shift register that accepts one data value per cycle to be shifted in at the most-significant end and returns the contents of the entire register prior to shifting and after shifting. If needed, the number of valid entries in the shift register must be tracked by the user manually. Since this is an inline function, each call-site will have its own private shift register instance; sharing the same instance can be achieved by calling this function from a non-inline shared outer function.", "code": "template< auto N                  \n//< Length of shift register, typename T              \n//< Type of each buffer entry, bool Initialize = true  \n//< true if the state values should be initialized to {}\n>inline pair<T[N], T[N]> serial_in_parallel_out(T data)\n{\n    pair<T[N], T[N]> result;\n\n    atomic\n    {\n        static if (Initialize)\n        {\n            static T[N] reg = {};\n        }\n        else\n        {\n            static T[N] reg;\n        }\n\n        const auto snappedReg = reg;\n\n        static for(const auto i : N)\n        {\n            if (i != N - 1)\n                reg[i] = snappedReg[i+1];\n            else\n                reg[i] = data;\n        }\n\n        result = {snappedReg, reg};\n    }\n\n    return result;\n}"}
{"file": "data\\datetime.pd", "nl": "Converts a `time_day_t` to days since Jan 1 1970.", "code": "inline optional<epoch_days_t> utc_days_to_epoch(time_day_t time)\n{\n    // Compute indices into lookup tables\n    const auto yearTableIndex = time.year - year_tables_start_year;\n    const uint1 isLeapYear = is_leap_year_table[yearTableIndex];\n    const auto monthTableIndex = time.month + (isLeapYear * 16);\n\n    optional<epoch_days_t> result;\n\n    // Validation\n    bool[3] validComponents;\n\n    validComponents[0] = ((time.year >= year_tables_start_year) && (time.year < year_tables_end_year));\n    validComponents[1] = time.month < 12;\n    validComponents[2] = time.day < days_per_month_table[monthTableIndex];\n\n    const bool valid = and(validComponents);\n\n    // Compute the number of days since Jan 1 1970\n    // Each element of this array is in days\n    epoch_days_t[3] dayComponents;\n\n    dayComponents[0] = cummulative_year_days_table[yearTableIndex];\n    dayComponents[1] = cummulative_month_days_table[monthTableIndex];\n    dayComponents[2] = time.day;\n\n    epoch_days_t totalDays = sum<epoch_days_t, epoch_days_t, 3>(dayComponents);\n\n    return make_optional<epoch_days_t>(valid, valid ? totalDays : 0);\n}"}
{"file": "data\\datetime.pd", "nl": "Converts a `time_t` to seconds since Jan 1 1970", "code": "inline optional<epoch_seconds_t> utc_time_to_epoch(time_t time)\n{\n    optional<epoch_seconds_t> result;\n\n    const auto secondsPerMinute = 60;\n    const auto secondsPerHour = secondsPerMinute * 60;\n    const auto secondsPerDay = secondsPerHour * 24;\n\n    // Convert year, month, and day into number of days since Jan 1 1970\n    time_day_t d;\n    d.day = time.day;\n    d.month = time.month;\n    d.year = time.year;\n    auto resultDays = utc_days_to_epoch(d);\n\n    // Validation\n    bool[4] validComponents;\n\n    validComponents[0] = resultDays.is_valid;\n    validComponents[1] = time.hours < 24;\n    validComponents[2] = time.minutes < 60;\n    validComponents[3] = time.seconds < 60;\n\n    const bool valid = and(validComponents);\n\n    // Each element of this array is in seconds\n    epoch_seconds_t[4] secondComponents = {};\n\n    secondComponents[0] = resultDays.value * secondsPerDay;\n    secondComponents[1] = time.hours * secondsPerHour;\n    secondComponents[2] = time.minutes * secondsPerMinute;\n    secondComponents[3] = time.seconds;\n\n    const auto totalSeconds = sum<epoch_seconds_t, epoch_seconds_t, 4>(secondComponents);\n\n    return make_optional<epoch_seconds_t>(valid, valid ? totalSeconds : 0);\n}"}
{"file": "data\\fifo.pd", "nl": "Return the number of elements that have been written and not read. Note that this can be out of date the instant its read due to other threads reading/writing to the FIFO. This cannot be used for checking empty/full for non-blocking versions of the FIFO.", "code": "inline count_t<Size> count()\n    {\n        return _readSemaphore.count();\n    }"}
{"file": "data\\fifo.pd", "nl": "Read one entry from FIFO. Block if FIFO is empty and `DequeueBlocking` is true.", "code": "T dequeue()\n    {\n        // Block the calling thread until an entry is available\n        _readSemaphore.wait();\n\n        // Get the value of the read pointer then increment the read pointer\n        auto consumer_index = first(atomically<pointer_t>(increment));\n\n        // Read the value from the data memory\n        T result = _dataMem[consumer_index];\n\n        // Now that the read has occured, allow another thread to overwrite the data\n        _writeSemaphore.post();\n\n        return result;\n    }"}
{"file": "data\\fifo.pd", "nl": "Write one entry to the FIFO. Block if FIFO is full and `EnqueueBlocking` is true.", "code": "void enqueue(T value)\n    {\n        // Block until the FIFO is no longer full\n        _writeSemaphore.wait();\n\n        // Get the value of the write pointer then increment the write pointer\n        auto producer_index = first(atomically<pointer_t>(increment));\n\n        // Store the value into the memory\n        _dataMem[producer_index] = value;\n\n        // Allow 1 more thread to get a value out\n        _readSemaphore.post();\n    }"}
{"file": "data\\fifo.pd", "nl": "Write one entry to the FIFO. Block if FIFO is full. Return the number of dequeue calls that were released.", "code": "count_t<Size> enqueue(T value, bool releaseDeferredDequeues)\n    {\n        // Block until the FIFO is no longer full\n        _writeSemaphore.wait();\n\n        // Get the value of the write pointer then increment the write pointer\n        auto producer_index = first(atomically<pointer_t>(increment));\n\n        // Store the value into the memory\n        _dataMem[producer_index] = value;\n\n        count_t<Size> snappedDeferredDequeueCount;\n        atomic\n        {\n            if (releaseDeferredDequeues)\n            {\n                // Add one to the deferred dequeue count for the value being enqueued now.\n                snappedDeferredDequeueCount = _deferredDequeueCount + 1;\n                _deferredDequeueCount = 0;\n            }\n            else\n            {\n                // Ensure that the increment of _deferredDequeueCount below won't overflow.\n                sim_assert(_deferredDequeueCount < (1 << bitsizeof(count_t<Size>)) - 1);\n\n                snappedDeferredDequeueCount = 0;\n                _deferredDequeueCount++;\n            }\n        }\n\n        // Allow 0 or more threads to to get a value out\n        _readSemaphore.post_multiple(snappedDeferredDequeueCount);\n\n        return snappedDeferredDequeueCount;\n    }"}
{"file": "data\\fifo.pd", "nl": "Return true if no more entries can be enqueued.", "code": "inline bool full()\n    {\n        return _earlyCounter.count() == Size;\n    }"}
{"file": "data\\fifo.pd", "nl": "Reserve one slot, so that data can be safely written into the FIFO at a future point in time. Typical usage is to call `full` and `reserve_enqueue` in the same atomic block. Each call to `reserve_enqueue` must be paired with 1 call to `enqueue`. The `enqueue` call does not need to be in an atomic block with the call to `reserve_enqueue`.", "code": "inline void reserve_enqueue()\n    {\n        sim_assert(!full());\n        _earlyCounter.add(1);\n    }"}
{"file": "data\\fifo.pd", "nl": "Helper function that checks fifo state and conditionally reserves a slot. If the fifo is not full, then this reserves one slot and returns true. Return false otherwise.", "code": "inline bool check_and_reserve()\n    {\n        bool result = false;\n\n        if (!full())\n        {\n            reserve_enqueue();\n            result = true;\n        }\n\n        return result;\n    }"}
{"file": "data\\fifo.pd", "nl": "Write one data item to the queue. `reserve_enqueue` must have been called previously.", "code": "void enqueue(T value)\n    {\n        // Get the value of the write pointer then increment the write pointer\n        auto producer_index = first(atomically<pointer_t>(increment));\n\n        // Store the value into the memory\n        _dataMem[producer_index] = value;\n\n        // Allow 1 more value to be read out\n        // Check for overflow (late)\n        sim_assert(_lateCounter.count() < Size);\n        _lateCounter.increment();\n    }"}
{"file": "data\\fifo.pd", "nl": "Helper function that blocks the current thread until the output is not full", "code": "void enqueue_blocking(T value)\n    {\n        // Wait for an output slot to be available\n        wait_for(check_and_reserve());\n\n        // Write the data\n        enqueue(value);\n    }"}
{"file": "data\\fifo.pd", "nl": "Return true if there is no more data in the queue.", "code": "inline bool empty()\n    {\n        return _lateCounter.count() == 0;\n    }"}
{"file": "data\\fifo.pd", "nl": "Return the value at the head of the queue.", "code": "inline T front()\n    {\n        return _dataMem[_consumerIndex];\n    }"}
{"file": "data\\fifo.pd", "nl": "Remove 1 item from the queue.", "code": "inline void pop()\n    {\n        // Check for underflow\n        sim_assert(!empty());\n\n        _consumerIndex = modular::increment(_consumerIndex);\n\n        _earlyCounter.subtract(1);\n        _lateCounter.subtract(1);\n    }"}
{"file": "data\\hash_table.pd", "nl": "Computes a hash of input keys using an instance of the `toeplitz` class.", "code": "inline Hash toeplitz_hash(Key key)\n{\n    static toeplitz\n        < 1\n        , bitsizeof Hash\n        , bitsizeof Key\n        , bitsizeof Hash\n        , 0x6D5A1BA6540E36AE7384C94779710E89BAB5778362E9B302C3A2CF202B5615A9DD5E8EF2E2EF40444F7C23BBB76A508BF48BE900D8A33DAE8829FB3C643771A6\n        > _toeplitz;\n\n    return _toeplitz.calc_hash(key);\n}"}
{"file": "data\\hash_table.pd", "nl": "Combined function that can be used to // 1. Insert a new `(Key, Value)` pair. // 2. Lookup the `Value` associated with a `Key` that is already present in the table. // 3. Modify the `Value` associated with a `Key` that is already present in the table. // 4. Reset the table to the initial state. // Inserts, lookups, and modifications use an iterative search. // A hash of the input key is used to determine the starting location for the search. // On each iteration, `Associativity` locations are checked in parallel.  If a matching key is found // then the hash table runs at full throughput.  Otherwise, the search loop proceeds, // searching `Associativity` new locations on each iteration. // Callers must ensure there are never concurrent calls to this function // from separate call sites. // Calls to `allocate_fn` occur in the same order as calls to `insert_or_update`:", "code": "inline optional<result> insert_or_update\n        ( Key key                           //< Key used to find a location to store the value\n        , bool reset                        //< True if all elements in the hash table should be removed before performing the search.\n        , bool insert_on_miss               //< True if a new `(Key, Value)` pair should be inserted into the table if a pair with a matching `key` is not already present.\n        , ()->Value allocate_fn             //< Function that is called when a key is inserted into the hash table.\n                                            // Returns a value that is passed to `access_fn`.\n        , (Value, bool)->Value access_fn    //< Function that accepts a previous value and a bool indicating if an insert occured.\n                                            // Returns a new value to store in the hash table associated with the key.\n                                            // If `key` was not already present in the table then,\n                                            // the first parameter is the value returned by `allocate_fn` and the second parameter is `true`.\n                                            // Otherwise, the first parameter is the value currently stored in the table and the second parameter is `false`.\n        )\n    {\n        // Update generation ID if resetting\n        auto generation_id = init_generational<GenerationBits>(reset);\n\n        // Generation ID 0 is the reset value\n        sim_assert(generation_id.second != 0);\n\n        // Lock the tags\n        // If generation_id.first is true, then acquire exclusive access\n        // which will block until preceding threads have drained\n        _tag_lock.lock(!generation_id.first);\n\n        if (generation_id.first)\n        {\n            // Reset all tags to generation ID 0 (invalid generation ID)\n            pipelined_for(NumSets, [](set_index_t set_index)\n            {\n                static for (const auto way_index : Associativity)\n                {\n                    _tags[way_index][set_index] = {};\n\n                    // Allow writes to be pipelined\n                    barrier;\n                }\n            });\n\n            // Reset hazard tracking history\n            static for (const auto i : HistorySize)\n            {\n                _outer_history[i].is_valid = false;\n            }\n        }\n\n        lookup_one_set_result internal_result;\n\n        static if (MaxIterations == 1)\n        {\n            // only perform 1 lookup, no loop necessary\n            internal_result = lookup_one_set(key, generation_id.second, insert_on_miss, 0);\n        }\n        else\n        {\n            // Linear probing.\n            // It is important to ensure that all threads that are probing\n            // have the same generation id.  If threads with different generation IDs\n            // can be probing at the same time, then a thread could incorrectly\n            // determine that a slot was unsued (because of a generation id mismatch).\n            // When reset=true, block until all younger threads have finished probing.\n            wait_for(test_thread_count(reset));\n\n            count_t<NumSets> offset = 0;\n\n            // allocate_fn is not called inside of this loop\n            // to ensure that calls to allocate_fn occur in the same order as calls\n            // to insert_or_update.\n            do\n            {\n                // will be cast to set_index_t\n                sim_assert(offset < NumSets);\n\n                internal_result = lookup_one_set(key, generation_id.second, insert_on_miss, cast<set_index_t>(offset));\n\n                offset++;\n\n                // internal_result.continue_searching term is for the case where insert_on_miss is false.\n                // In this case the search can stop as soon as 1 emtpy tag is found.\n                // (offset < NumSets) term prevents infinite loop if the table is full.\n            } while(!internal_result.element_index.is_valid && internal_result.continue_searching && (offset < NumSets) && (offset < MaxIterations)); \n\n            _threads_in_flight.decrement();\n        }\n\n        optional<result> r = {};\n\n        if (internal_result.element_index.is_valid)\n        {\n            Value initial_value;\n\n            if (internal_result.inserted)\n            {\n                // First time this key has been inserted\n                // Get initial value\n                initial_value = allocate_fn();\n            }\n\n            bool inserted = internal_result.inserted;\n\n            auto update_result = _data.atomically(\n                internal_result.element_index.value,\n                [access_fn, inserted, initial_value](Value prev)\n                {\n                    return access_fn(inserted ? initial_value : prev, inserted);\n                });\n                \n            r.is_valid = true;\n            r.value.inserted = internal_result.inserted;\n            r.value.value.first = inserted ? initial_value : update_result.first;\n            r.value.value.second = update_result.second;\n        }\n\n        // Unlock the tags\n        _tag_lock.unlock(!generation_id.first);\n\n        return r;\n    }"}
{"file": "data\\representation.pd", "nl": "Generate a onehot of the specified width.  A onehot is an array of booleans with a single value set to true.  Calling with `OutputWidth` 8 and `index` 1 returns an array of 8 bools with only bool 1 set to true.  Or in binary, 00000010.", "code": "template<auto OutputWidth, typename T>\ninline bool[OutputWidth] binary_to_one_hot(T index)\n{\n    // Make sure x isn't too large for the output array.\n    // For example, it's not possible to set the 5th boolean in a 3 element array.\n    sim_assert(index < OutputWidth);\n\n    bool[OutputWidth] result = {};\n    result[index] = true;\n    return result;\n}"}
{"file": "data\\representation.pd", "nl": "Similar to `mux`, but takes a `onehot` rather than an index as the first parameter. Also takes an array rather than a variable number of arguments for the selection list. The least significant bit in the onehot corresponds to index 0 in the data array.", "code": "template<typename T, auto Count>\ninline T onehot_mux(uint<Count> onehot, T[Count] data)\n{\n    uint<bitsizeof(T)>[Count] map;\n    bool[Count] bool_onehot = cast<bool[Count]>(onehot);\n\n    uint<bitsizeof(T)> bitwise_or(uint<bitsizeof(T)> x, uint<bitsizeof(T)> y)\n    {\n        return x | y;\n    }\n\n    // Can't use map here because that doesn't pass the index to the map function.\n    static for(const auto i : Count)\n    {\n        if (bool_onehot[i])\n        {\n            map[i] = cast<uint<bitsizeof(T)>>(data[i]);\n        }\n    }\n\n    uint<bitsizeof(T)> result = reduce(bitwise_or, map);\n\n    return cast<T>(result);\n}"}
{"file": "data\\representation.pd", "nl": "Change a value from big endian to little endian, or vice versa. The input type must be of a size that's a multiple of 8 bits.", "code": "template<typename T>\ninline T endian_change(T input)\n{\n    uint8[bytesizeof(T)] inputAsArray = cast<uint8[bytesizeof(T)]>(input);\n    uint8[bytesizeof(T)] result;\n\n    static for (const auto i : bytesizeof(T))\n    {\n        result[i] = inputAsArray[static(bytesizeof(T) - i - 1)];\n    }\n\n    return cast<T>(result);\n}"}
{"file": "data\\memory.pd", "nl": "Type returned by reads from `memory_ecc` of type `T`", "code": "template <typename T>\nstruct ecc\n{\n    //| True when an ECC error was detected, regardless of whether it was\n    // corrected or not.\n    bool error;\n    //| Value read from the memory, valid if there was no ECC error, or an\n    // error was corrected.\n    optional<T> data;\n}\ntemplate <typename T>\ninline ecc<T> make_ecc(bool error, bool valid, T value)\n{\n    return {error, make_optional(valid, value)};\n}"}
{"file": "data\\memory.pd", "nl": "Alias for error correction code (ECC) memory of type `T` and depth of `N`. // Reads from the memory return values of type `ecc<T>`// Writes to the memory take values of type `T`.", "code": "template <typename T, auto N>\nusing memory_ecc = [[memory, ecc(make_ecc<T>)]] T[N];"}
{"file": "data\\memory.pd", "nl": "Alias for non-replicated, ECC memory of type `T` and depth of `N`. Reads from the memory return values of type `ecc<T>`. Writes to the memory take values of type `T`.", "code": "template <typename T, auto N>\nusing memory_ecc_norep = [[memory, non_replicated, ecc(make_ecc<T>)]] T[N];\n\ntemplate <typename T>\ninline optional<T> make_optional_from_ecc_error(bool error, bool valid, T value)\n{\n    sim_assert(valid || error);\n    return make_optional(!error, value);\n}"}
{"file": "data\\memory.pd", "nl": "Alias for ECC memory of type `T` and depth of `N`. // Reads from the memory return values of type `optional<T>` that is valid if no ECC error, even a correctable one, was detected. Writes to the memory take values of type `T`.", "code": "template <typename T, auto N>\nusing memory_ecc_strict = [[memory, ecc(make_optional_from_ecc_error<T>)]] T[N];\n\ntemplate <typename T>\ninline optional<T> make_optional_from_ecc_valid(bool error, bool valid, T value)\n{\n    return make_optional(valid, value);\n}"}
{"file": "data\\memory.pd", "nl": "Alias for ECC memory of type `T` and depth of `N`. Reads from the memory return values of type `optional<T>` that is valid if there was no ECC error, or an error was corrected. Writes to the memory take values of type `T`.", "code": "template <typename T, auto N>\nusing memory_ecc_relaxed = [[memory, ecc(make_optional_from_ecc_valid<T>)]] T[N];"}
{"file": "numeric\\float64.pd", "nl": "Apply exponent bias and add mantissa implied one", "code": "template<Denorm denorm_mode>\ninline float64ExpandedFormat unpackFloat64(float64PackedFormat a)\n{\n    float64ExpandedFormat a_PostUnpack;\n    a_PostUnpack.sign = a.sign;\n    if (denorm_mode == Denorm::Off)\n    {\n        a_PostUnpack.exponent = cast<int13>(a.exponent) - 1023;\n        a_PostUnpack.mantissa = a.mantissa | (1 << 52);\n    }\n    else\n    {\n        a_PostUnpack.exponent = a.exponent == 0 ? -1022 : cast<int13>(a.exponent) - 1023;\n        a_PostUnpack.mantissa = a.exponent == 0 ? a.mantissa : a.mantissa | (1 << 52);\n    }\n    return a_PostUnpack;\n}"}
{"file": "numeric\\float64.pd", "nl": "Set denorm value to 0.", "code": "inline float64StickyFormat normalizeOutput2Zero(float64StickyFormat input)\n{\n    float64StickyFormat out;\n    out.sticky = 0;\n    out.mantissaGuardRound = 0;\n    out.exponent = -1023;\n    out.sign = input.sign;\n    return(out);\n}"}
{"file": "numeric\\float64.pd", "nl": "Addition.", "code": "template <Denorm denorm_mode>\ninline uint64 add(uint64 in1, uint64 in2)\n{\n    uint64 result;\n    if (denorm_mode == Denorm::On)\n    {\n        result = float64_add(in1, in2);\n    }\n    else\n    {\n        result = float64_add_denormoff(in1, in2);\n    }\n    return result;\n}"}
{"file": "numeric\\float64.pd", "nl": "Multiplication.", "code": "template <Denorm denorm_mode>\ninline uint64 mul(uint64 in1, uint64 in2)\n{\n    uint64 result;\n    if (denorm_mode == Denorm::On)\n    {\n        result = float64_mul(in1, in2);\n    }\n    else\n    {\n        result = float64_mul_denormoff(in1, in2);\n    }\n    return result;\n}"}
{"file": "numeric\\float64.pd", "nl": "Compare two float64 values for equality.", "code": "template <Denorm denorm_mode>\ninline bool eq(uint64 in1, uint64 in2)\n{\n    // Unpack input\n    float64PackedFormat a = cast<float64PackedFormat>(in1);\n    float64PackedFormat b = cast<float64PackedFormat>(in2);\n    // Get zero, nan, or inf\n    specialCaseFlags a_flags = getSpecialCases<denorm_mode>(a);\n    specialCaseFlags b_flags = getSpecialCases<denorm_mode>(b);\n\n    bool result;\n    // Negative and positive zero are equal\n    if (a_flags.zero && b_flags.zero)\n    {\n        result = true;\n    }\n    // NaNs are never equal\n    else if (a_flags.nan || b_flags.nan)\n    {\n        result = false;\n    }\n    else\n    {\n        result = in1 == in2;\n    }\n    return result;\n}"}
{"file": "numeric\\float64.pd", "nl": "Check `in1` less than `in2`.", "code": "template <Denorm denorm_mode>\ninline bool lt(uint64 in1, uint64 in2)\n{\n    // Unpack input\n    float64PackedFormat a;\n    float64PackedFormat b;\n    a = cast<float64PackedFormat>(in1);\n    b = cast<float64PackedFormat>(in2);\n\n    // Get zero, nan, or inf\n    specialCaseFlags a_flags = getSpecialCases<denorm_mode>(a);\n    specialCaseFlags b_flags = getSpecialCases<denorm_mode>(b);\n\n    bool result;\n    // Check equal\n    if (eq<denorm_mode>(in1, in2))\n    {\n        result = false;\n    }\n    // NaN\n    else if (a_flags.nan || b_flags.nan)\n    {\n        result = false;\n    }\n    // a negative, b positive or zero\n    else if (a.sign == 1 && (b_flags.zero || b.sign == 0))\n    {\n        result = true;\n    }\n    // b negative, a positive or zero\n    else if (b.sign == 1 && (a_flags.zero || a.sign == 0))\n    {\n        result = false;\n    }\n    // same sign\n    else\n    {\n        result = concat(a.exponent, a.mantissa) < concat(b.exponent, b.mantissa);\n        // Reverse if negative\n        if (a.sign == 1)\n        {\n            result = !result;\n        }\n    }\n    return result;\n}"}
{"file": "numeric\\float64.pd", "nl": "Check `in1` greater than `in2`.", "code": "template <Denorm denorm_mode>\ninline bool gt(uint64 in1, uint64 in2)\n{\n    // Unpack input\n    float64PackedFormat a;\n    float64PackedFormat b;\n    a = cast<float64PackedFormat>(in1);\n    b = cast<float64PackedFormat>(in2);\n\n    // Get zero, nan, or inf\n    specialCaseFlags a_flags = getSpecialCases<denorm_mode>(a);\n    specialCaseFlags b_flags = getSpecialCases<denorm_mode>(b);\n\n    bool result;\n    if (a_flags.nan || b_flags.nan)\n    {\n        result = false;\n    }\n    else\n    {\n        result = !eq<denorm_mode>(in1, in2) && !lt<denorm_mode>(in1, in2);\n    }\n    return result;\n}"}
{"file": "numeric\\float64.pd", "nl": "Negate.", "code": "inline uint64 neg(uint64 x)\n{\n    float64PackedFormat binary = cast<float64PackedFormat>(x);\n    binary.sign = ~binary.sign;\n    return cast<uint64>(binary);\n}"}
{"file": "numeric\\float64.pd", "nl": "Subtract `in2` from `in1`.", "code": "template <Denorm denorm_mode>\ninline uint64 sub(uint64 in1, uint64 in2)\n{\n    return add<denorm_mode>(in1, neg(in2));\n}"}
{"file": "numeric\\float64.pd", "nl": "Convert a signed integer to a float64.", "code": "template <auto N /*< Width of `value`.*/>\ninline uint64 from_int(int<N> value)\n{\n    return int_to_float<int<N>, uint64, _mantissa_width, _exponent_width, _exponent_bias>(value);\n}"}
{"file": "numeric\\float64.pd", "nl": "Convert an unsigned integer to a float64.", "code": "template <auto N /*< Width of `value`.*/>\ninline uint64 from_uint(uint<N> value)\n{\n    return int_to_float<uint<N>, uint64, _mantissa_width, _exponent_width, _exponent_bias>(value);\n}"}
{"file": "numeric\\float64.pd", "nl": "Convert a float64 to a signed integer", "code": "template <auto N /*< Width of the signed integer.*/>\ninline optional<int<N>> to_int(uint64 value)\n{\n    auto result = float_to_int<uint64, int<N+1>, _mantissa_width, _exponent_width, _exponent_bias>(value);\n    if (result.is_valid)\n    {\n        auto limits = get_limits<int<N>>();\n        if ((result.value < limits.first) || (result.value > limits.second))\n            result.is_valid = false;\n    }\n\n    return make_optional<int<N>>(result.is_valid, cast<int<N>>(result.value));\n}"}
{"file": "numeric\\float64.pd", "nl": "Convert a float64 to an unsigned integer", "code": "template <auto N /*< Width of the unsigned integer.*/>\ninline optional<uint<N>> to_uint(uint64 value)\n{\n    auto result = float_to_int<uint64, uint<N+1>, _mantissa_width, _exponent_width, _exponent_bias>(value);\n    if (result.is_valid)\n    {\n        auto limits = get_limits<uint<N>>();\n        if ((result.value < limits.first) || (result.value > limits.second))\n            result.is_valid = false;\n    }\n\n    return make_optional<uint<N>>(result.is_valid, cast<uint<N>>(result.value));\n}"}
{"file": "numeric\\float64.pd", "nl": "Convert a float32 to a float64.", "code": "inline float64 from_float32(float32 value)\n{\n    const auto float32_mantissa_width = 23;\n    const auto float64_mantissa_width = _mantissa_width;\n    const auto float32_exponent_bias = 127;\n    const auto float64_exponent_bias = _exponent_bias;\n    const auto float32_exponent_all_bits = 0xFF;\n    const auto float64_exponent_all_bits = 0x7FF;\n\n    const auto float_packed = cast<float32PackedFormat>(value);\n    float64PackedFormat double_packed;\n\n    if (float_packed.exponent == 0 && float_packed.mantissa == 0)\n    {\n        // Zero is a bit special\n        double_packed.exponent = 0;\n        double_packed.mantissa = 0;\n    }\n    else if (float_packed.exponent == float32_exponent_all_bits)\n    {\n        // Special values infinity and Nan\n        double_packed.exponent = float64_exponent_all_bits;\n        double_packed.mantissa = float_packed.mantissa;\n        double_packed.mantissa = double_packed.mantissa << (float64_mantissa_width - float32_mantissa_width);\n    }\n    else\n    {\n        if (float_packed.exponent == 0)\n        {\n            // Denormalized floats\n            const auto highest = highest_one<int<float32_mantissa_width>>(float_packed.mantissa);\n            double_packed.exponent = (-(float32_mantissa_width - highest.value)) + (-(float32_exponent_bias - 1)) + float64_exponent_bias;\n            double_packed.mantissa = float_packed.mantissa;\n            double_packed.mantissa = cast<decltype(double_packed.mantissa)>(double_packed.mantissa << (float64_mantissa_width - highest.value));\n        }\n        else\n        {\n            // Normalized floats\n            int23 float_exp = float_packed.exponent;\n            float_exp -= float32_exponent_bias;\n            double_packed.exponent = float_exp;\n            double_packed.exponent += float64_exponent_bias;\n            double_packed.mantissa = float_packed.mantissa;\n            double_packed.mantissa = double_packed.mantissa << (float64_mantissa_width - float32_mantissa_width);\n        }\n    }\n    double_packed.sign = float_packed.sign;\n\n    return cast<float64>(double_packed);\n}"}
{"file": "numeric\\float64.pd", "nl": "Check `x` is not a number.", "code": "inline bool isnan(uint64 x)\n{\n    const auto flags = getSpecialCases<Denorm::On>(cast<float64PackedFormat>(x));\n    return flags.nan;\n}"}
{"file": "numeric\\float64.pd", "nl": "Check `x` is positive or negative infinity.", "code": "inline bool isinf(uint64 x)\n{\n    const auto flags = getSpecialCases<Denorm::On>(cast<float64PackedFormat>(x));\n    return flags.inf;\n}"}
{"file": "numeric\\float64.pd", "nl": "Return sign of `x`.", "code": "inline bool signbit(uint64 x)\n{\n    const auto s = cast<float64PackedFormat>(x);\n    return s.sign == 1;\n}"}
{"file": "numeric\\float64.pd", "nl": "Return the smaller of `x` and `y`. A NaN is treated as missing data, and", "code": "template<Denorm denorm_mode>\ninline uint64 min(uint64 x, uint64 y)\n{\n    return (isnan(y) || lt<denorm_mode>(x, y)) ? x : y;\n}"}
{"file": "numeric\\float64.pd", "nl": "Return the larger of `x` and `y`. A NaN is treated as missing data, and", "code": "template<Denorm denorm_mode>\ninline uint64 max(uint64 x, uint64 y)\n{\n    return (isnan(y) || gt<denorm_mode>(x, y)) ? x : y;\n}"}
{"file": "numeric\\float64.pd", "nl": "Return the smallest integer not less than `x`: \\(\\lceil x \\rceil\\)", "code": "template<Denorm denorm_mode>\ninline uint64 ceil(uint64 x)\n{\n    return ceil_internal<uint64, _mantissa_width, _exponent_width, _exponent_bias, denorm_mode>(x);\n}"}
{"file": "numeric\\float64.pd", "nl": "Return the largest integer not greater than `x`: \\(\\lfloor x \\rfloor\\)", "code": "template<Denorm denorm_mode>\ninline uint64 floor(uint64 x)\n{\n    return floor_internal<uint64, _mantissa_width, _exponent_width, _exponent_bias, denorm_mode>(x);\n}"}
{"file": "numeric\\float64.pd", "nl": "Return the nearest integer to `x`, rounding halfway away from zero.", "code": "template<Denorm denorm_mode>\ninline uint64 round(uint64 x)\n{\n    return round_internal<uint64, _mantissa_width, _exponent_width, _exponent_bias, denorm_mode>(x);\n}"}
{"file": "numeric\\float64.pd", "nl": "Return the nearest integer not greater in magnitude than `x`.", "code": "template<Denorm denorm_mode>\ninline uint64 trunc(uint64 x)\n{\n    return trunc_internal<uint64, _mantissa_width, _exponent_width, _exponent_bias, denorm_mode>(x);\n}"}
{"file": "numeric\\float64.pd", "nl": "Return the positive difference between `x` and `y`, i.e. `max(x - y, 0)`.", "code": "template<Denorm denorm_mode>\ninline uint64 dim(uint64 x, uint64 y)\n{\n    uint64 result;\n\n    if (isnan(x) || isnan(y))\n    {\n        result = float64_constants::DEFAULT_NAN;\n    }\n    else\n    {\n        result = gt<denorm_mode>(x, y) ? sub<denorm_mode>(x, y) : float64_constants::POS_ZERO;\n    }\n\n    return result;\n}"}
{"file": "numeric\\float64.pd", "nl": "Return the absolute value of `x`: $|x|$", "code": "template<Denorm denorm_mode>\ninline uint64 abs(uint64 x)\n{\n    auto structValue = cast<float64PackedFormat>(x);\n    structValue.sign = 0;\n    return cast<uint64>(structValue);\n}"}
{"file": "control\\loop.pd", "nl": "Execute body for a range of values starting from `begin` and ending before `end`, incrementing by `step` on each iteration.", "code": "template <typename T>\ninline void range_for (T begin, T end, auto step, (T) -> void body)\n{\n    sim_assert (step > 0);\n\n    if (begin < end) do\n    {\n        body(begin);\n        begin += step;\n    }\n    while (begin < end);\n}"}
{"file": "control\\loop.pd", "nl": "Keep calling `body` while the `condition` returns true.", "code": "inline void while_do (() -> bool condition, () -> void body)\n{\n    bool proceed;\n\n    do\n    {\n        proceed = condition();\n\n        if (proceed) body();\n    }\n    while (proceed);\n}"}
{"file": "control\\loop.pd", "nl": "Spawn `count` threads executing `body`, which can be a lambda or a function taking one argument specifying the thread index from the range [0, `count`).", "code": "template <typename I>\ninline void pipelined_for(auto count, (I) -> void body)\n{\n    sim_assert(count <= (1 << bitsizeof I));\n\n    static pipelined<I, decltype(body)> loop;\n\n    loop.go(count, body);\n}"}
{"file": "control\\loop.pd", "nl": "Spawn a thread for each element of array `arr` calling `body` which can be a lambda or a function taking two arguments, the thread index and the element value.", "code": "template <typename T, auto N>\ninline void pipelined_for_each(T[N] arr, (index_t<N>, T) -> void body)\n{\n    pipelined_for(N, [arr, body](index_t<N> i)\n    {\n        body(i, arr[i]);\n    });\n}"}
{"file": "control\\loop.pd", "nl": "Spawn threads that will execute the `body` closure until it returns `false`. Number of threads spun is `2^bitsizeof(I)`, and should be larger than the depth of the `body` pipeline. The function returns after `body` returns `false` and all in-flight threads drain from the loop. When an instance of `pipelined_do` is called multiple times, the threads for subsequent calls will not start until all threads for earlier calls have started (although not necessarily exited).", "code": "template <typename I>\ninline void pipelined_do((I) -> bool body)\n{\n    pipelined_for(1 << bitsizeof I, [body](I tid)\n    {\n        do ; while (body(tid));\n    });\n}"}
{"file": "control\\loop.pd", "nl": "Spawn `count` threads executing `body`, which can be a lambda or a function taking one argument specifying the thread index from the range [0, `count`]. The function returns an array `T[N]` of values produced by `body`. `N` must not be greater than `count`.", "code": "template <auto N, typename I, typename T>\ninline T[N] pipelined_map(auto count, (I) -> T body)\n{\n    sim_assert(count <= N);\n    sim_assert(count <= (1 << bitsizeof I));\n\n    const auto fn = [body](I x) -> T\n    {\n        return body(x);\n    };\n\n    static pipelined<I, decltype(fn)> loop;\n\n    return loop.go(count, fn);\n}"}
{"file": "control\\loop.pd", "nl": "Spawn `count` threads executing `body`, which can be a lambda or a function taking one argument specifying the thread index from the range [0, `count`]. The function returns result produced by last call to `body`.", "code": "template <typename I, typename T>\ninline T pipelined_last(auto count, (I) -> T body)\n{\n    using body_t = decltype(body);\n\n    class Helper\n    {\n    public:\n        [[pipelined]] void loop(I tid, I last, body_t body)\n        {\n            const auto x = body(tid);\n\n            if (tid == last)\n            {\n                _result.enqueue(x);\n            }\n        }\n\n        inline T result()\n        {\n            return _result.dequeue();\n        }\n\n    private:\n        FIFO<T, 32, true, false> _result;\n    }\n\n    static Helper helper;\n\n    sim_assert(count > 0);\n    sim_assert(count <= (1 << bitsizeof I));\n\n    helper.loop(count, cast<I>(count - 1), body);\n    return helper.result();\n}"}
{"file": "control\\loop.pd", "nl": "Spawn `count` threads executing `body`, which can be a lambda or a function taking one argument specifying the thread index from the range [0, `count`). Threads execute across `N` instances of the function `body`. There are no ordering guarantees among threads spawned by one call to `parallel_for`. If there are two calls (`A` and `B`) to a single `parallel_for` call site, resulting in threads `A0`, `A1`, `B0`, `B1` executing `body`, then thread `A0` will begin executing `body` ahead of `B0` and `A1` will begin executing `body` ahead of `B1`.", "code": "template\n    < auto N                                            //< Number of replicas to `body` to instantiate.\n    , auto MaxCallerThreads = opt::max_threads_limit    //< Maximum number of threads concurrently executing inside of `parallel_for`.\n                                                        // Caller must ensure this limit is not exceeded.\n    >\ninline void parallel_for\n    ( count_t<N> count              //< Number of times that `body` will be invoked.  Must be no greater than `N`.\n    , (index_t<N>) -> void body     //< Function to invoke.\n    )\n{\n    sim_assert(count <= N);\n    static parallel<N, MaxCallerThreads, false, void> loop;\n    loop.go(count, body);\n}"}
{"file": "control\\loop.pd", "nl": "Spawn a thread for each element of array `arr` calling `body` which can be  a lambda or a function taking two arguments, the thread index and the element value. Threads execute across `N` instances of the function `body`.\n// There are no ordering guarantees among threads spawned by one call to `parallel_for_each`.\n// If there are two calls (`A` and `B`) to a single `parallel_for_each` call site, resulting in threads\n// `A0`, `A1`, `B0`, `B1` executing `body`, then thread `A0` will begin executing `body` ahead of `B0`\n// and `A1` will begin executing `body` ahead of `B1`.", "code": "template\n    < typename T                                        //< Type of each input array element.\n    , auto N                                            //< Number of replicas to `body` to instantiate.\n    , auto MaxCallerThreads = opt::max_threads_limit    //< Maximum number of threads concurrently executing inside of `parallel_for_each`.\n                                                        // Caller must ensure this limit is not exceeded.\n    >\ninline void parallel_for_each\n    ( T[N] arr                      //< Input array to be processed (each element is processed by a separate call to `body`).\n    , (index_t<N>, T) -> void body  //< Function which processes one input array element on each call.\n    )\n{\n    parallel_for<N, MaxCallerThreads>(N, [arr, body](index_t<N> i)\n    {\n        body(i, arr[i]);\n    });\n}"}
{"file": "control\\loop.pd", "nl": "Spawn `count` threads executing `body`, which can be a lambda or a // function taking one argument specifying the thread index from the range [0, `count`]. The function returns an array `T[N]` of values produced by `body`. `N` must not be greater than `count`. Threads execute across `N` instances of the function `body`. There are no ordering guarantees among threads spawned by one call to `parallel_map`. If there are two calls (`A` and `B`) to a single `parallel_map` call site, resulting in threads `A0`, `A1`, `B0`, `B1` executing `body`, then thread `A0` will begin executing `body` ahead of `B0` and `A1` will begin executing `body` ahead of `B1`.", "code": "template\n    < auto N                                            //< Number of replicas to `body` to instantiate.\n    , typename T                                        //< Type of each output array element.\n    , auto MaxCallerThreads = opt::max_threads_limit    //< Maximum number of threads concurrently executing inside of `parallel_map`.\n                                                        // Caller must ensure this limit is not exceeded.\n    >\ninline T[N] parallel_map\n    ( auto count                //< Number of times that `body` will be invoked.  Must be no greater than `N`.\n    , (index_t<N>) -> T body    //< Function which returns one array element on each call.\n    )\n{\n    sim_assert(count <= N);\n    static parallel<N, MaxCallerThreads, true, T> loop;\n    return loop.go(count, body);\n}"}
{"file": "control\\async.pd", "nl": "Execute `task` asynchronously and call `then` with the result once the task completes.", "code": "template <typename T>\ninline void async_then(() -> T task, (T) -> void then)\n{\n    using task_t = decltype(task);\n    using then_t = decltype(then);\n\n    class async\n    {\n    public:\n        [[async]] void exec(task_t task, then_t then)\n        {\n            then(task());\n        }\n    }\n\n    static async _async;\n\n    _async.exec(task, then);\n}"}
{"file": "control\\async.pd", "nl": "Like `async_then` but for tasks that don't produce a result.", "code": "inline void async_then_void(() -> void task, () -> void then)\n{\n    using task_t = decltype(task);\n    using then_t = decltype(then);\n\n    class async\n    {\n    public:\n        [[async]] void exec(task_t task, then_t then)\n        {\n            task();\n            then();\n        }\n    }\n\n    static async _async;\n\n    _async.exec(task, then);\n}"}
{"file": "control\\async.pd", "nl": "Execute a task asynchronously. A call to `async_exec` is implemented as a dataflow fork. For the common case of passing a lambda to `async_exec`, the lambda entry FIFO holds the value of each variable captured by the lambda. If the lambda pipeline does not introduce backpressure, the compiler can optimize away the entry FIFO.", "code": "inline void async_exec(() -> void task)\n{\n    async_then_void(task, [](){});\n}"}
{"file": "control\\async.pd", "nl": "A class faciliating the async/await pattern. `async` spawns a new asynchronous thread in which the provided lambda will be executed. Upon completion, the lambda's return value will be stored into an internal FIFO. In parallel, a call to `await` will block the calling thread until a result from `async` is available. The standard thread ordering guarantee ensures that no threads can overtake another and results will be returned by `await` in the same order as they entered `async`.", "code": "template\n    < typename T          //< Type returned by lambda argument to `async`.\n    , auto ReturnDepth    //< Depth of return value FIFO (maximum number of `fork<i>` results that can\n                          //  be buffered ahead of a corresponding `async` call). A recommended value\n                          //  would be 32 allowing it to be implemented in LUTRAM.\n    , auto WaitForDepth   //< Depth of the wait-for FIFO (maximum number of threads that can queue\n                          //  inside `await`). A conservative value would be 32 allowing it to be\n                          //  implemented in LUTRAM, however, for lambdas that typically take more\n                          //  than 32 cycles to return, this should be increased.\n    >\nclass async_await\n{\n    FIFO<T, ReturnDepth, true /* EnqueueBlocking */, false /* DequeueBlocking */> _returnFifo;\n    // Use a separate counter so that it can be atomically check-and-decremented independently\n    // of the FIFO dequeue operation.\n    // This counter cannot overflow since it is only incremented after a successful blocking\n    // _returnFifo.enqueue() call\n    counter<ReturnDepth, 0> _returnCount;\npublic:\n    //| Spawn a new thread that calls the provided lambda.\n    // Out-of-order behaviour can occur if multiple calls (causing multiple\n    // inlines) to the same method on the same instance exists and is thus\n    // not recommended.\n    inline void async(() -> T task)\n    {\n        async_then<T>(task,\n            [](T value)\n            {\n                _returnFifo.enqueue(value);\n                _returnCount.increment();\n            }\n        );\n    }\n    //| Check to see if the async function has returned.\n    // It is exposed as a public function to provide the option for a consumer\n    // to wait on multiple `async_await` instances simultaneously (e.g. `fork_join`).\n    inline bool check()\n    {\n        auto count = _returnCount.count();\n        return count != 0;\n    }\n    //| Decrement the return counter if argument is true.\n    inline void decrement(bool value)\n    {\n        sim_assert(!value || _returnCount.count() != 0);\n        _returnCount.subtract(cast<uint1>(value));\n    }\n    //| Wait for task started by `async` to complete and return its result.\n    T await()\n    {\n        inline bool check_and_decrement()\n        {\n            auto result = check();\n            decrement(result);\n            return result;\n        }\n        [[fifo_depth(WaitForDepth)]] wait_for(check_and_decrement());\n        return dequeue();\n    }\n    //| Pop the value returned by the lambda function to `async`.\n    // This function is called by `await`.\n    // It is exposed as a public function since `check`, which would typically\n    // be called from a `wait_for`, is unable to return anything but the check\n    // result. The intention is to allow the consumer to `wait_for(check_and_decrement())`\n    // and then `dequeue`.\n    inline T dequeue()\n    {\n        return _returnFifo.dequeue();\n    }\n};"}
{"file": "control\\fsm.pd", "nl": "Speculatively apply a state update to each possible current state and return all results.", "code": "template\n    < auto StateCount               //< Total number of possible states.\n    , typename SpeculativeUpdate    //< The output type of `fn`.\n    >\ninline auto speculate_updates\n    ( (index_t<StateCount>) -> SpeculativeUpdate fn  //< Function which is called `StateCount` times with values equal to either:\n                                                     // `0, 1, 2, ..., StateCount-1`\n                                                     // or\n                                                     // `override.value, override.value, ..., override.value`\n    , optional<index_t<StateCount>> override         //< If valid, then all returned results are equal to `fn(override.value)`.\n                                                     // Useful for cases where downstream code should behave as if it ignores the \"current\" state.\n    )\n{\n    return map_indices([override, fn](index_t<StateCount> i)\n        {\n            return fn(from_optional(i, override));\n        });\n}"}
{"file": "control\\fsm.pd", "nl": "Returns a closure which: // * Aggregates a set of pre-computed state updates into a final state update based on a concrete current state value.\n// * Computes a new state value based on the current state and the aggregated state update.\n// The returned closure can be passed to functions like `atomically`.", "code": "template\n    < auto StateCount                                   //< The number of pre-computed state updates.\n    , typename State                                    //< A type that represent the current state.\n    , typename SpeculativeUpdate                        //< A type that represents a pre-computed update to apply to the state.\n    , typename AggregatedUpdate = SpeculativeUpdate     //< A type that represents an aggregated update to apply to the state.\n    >\ninline auto apply_update\n    ( (SpeculativeUpdate[StateCount], State) -> AggregatedUpdate aggregate  //< Function which computes a final state update to apply,\n                                                                            // based on the current state and an array of pre-computed states updates.\n    , (AggregatedUpdate, State) -> State apply                              //< Function which applies a state update.\n    , SpeculativeUpdate[StateCount] updates                                 //< The array of speculatively pre-computed updates.\n    )\n{\n    return [updates, apply, aggregate](State prev)\n        {\n            return apply(aggregate(updates, prev), prev);\n        };\n}"}
{"file": "control\\wait.pd", "nl": "Block the calling thread and all threads behind it until `fn` returns an `optional` with `is_valid = true`. `fn` is only called when a given thread is at the head of the line. Return the value returned by `fn`. `fn` is called atomically.", "code": "template<typename T>\ninline auto wait_result(()->optional<T> fn)\n{\n    // Assign a unique ID to this thread\n    thread_index_within_function_t thread_id;\n\n    atomic\n    {\n        static thread_index_within_function_t _enter_thread_id = 0;\n\n        thread_id = _enter_thread_id;\n\n        _enter_thread_id = modular::increment(_enter_thread_id);\n    }\n\n    // Loop until fn returns true\n    bool continuing_looping = true;\n\n    optional<T> result;\n\n    // Loop body ensures ordering except in the case where wait_result is predicated\n    [[reorder_by_looping]]\n    do\n    {\n        // Hint to the compiler that these variables are not live at the start of the loop\n        continuing_looping = true;\n\n        result = {};\n\n        atomic\n        {\n            // Check to see if this thread is at the head of the line\n            static thread_index_within_function_t _expected_thread_id = 0;\n\n            bool head_of_line = (_expected_thread_id == thread_id);\n\n            if (head_of_line)\n            {\n                // Call fn()\n                result = fn();\n\n                // increment _expected_thread_id when result.is_valid is set\n                _expected_thread_id = modular::increment_if(_expected_thread_id, result.is_valid);\n\n                continuing_looping = !result.is_valid;\n            }\n        }\n    } while (continuing_looping);\n\n    return result.value;\n}"}
{"file": "control\\wait.pd", "nl": "Like `wait_result` but for functions that don't produce a result other than", "code": "inline void wait(()->bool fn)\n{\n    const auto wrapper = [fn]() -> optional<uint1>\n    {\n        return make_optional<uint1>(fn(), 0);\n    };\n\n    wait_result<uint1>(wrapper);\n}"}
{"file": "control\\wait.pd", "nl": "Block the calling thread until `fn` returns true. `fn` is checked atomically every cycle. If `T` is `void` then fn should return a `bool`. Otherwise, `fn` should return an `optional<T>` and this function will return the value of of this optional.", "code": "template <typename T>\ninline auto atomic_wait(() -> T fn)\n{\n    static if (T == bool)\n    {\n        atomic do {} while (!fn())\n    }\n    else\n    {\n        T result;\n        atomic do\n        {\n            result = fn();\n        } while (!result.is_valid)\n        return result.value;\n    }\n}"}
{"file": "data\\bitarray\\banked.pd", "nl": "Get the value of multiple bits.", "code": "template<auto MaxCount>\n    inline vec::vector<bool, MaxCount> read_bits\n        ( vec::vector<bit_addr_t, MaxCount> addresses //< Addresses of bits to read.\n        )\n    {\n        // Broadcast addresses to all banks\n        auto results = parallel_map<Banks>(Banks, [addresses](index_t<Banks> bank_index) -> optional<bool>[MaxCount]\n        {\n            // Determine which addresses map to this bank\n            bool[MaxCount] valid = map_indices<MaxCount>([bank_index, addresses](index_t<MaxCount> i)\n            {\n                return (i < addresses.size) && (is_bit_in_bank(addresses.data[i], bank_index));\n            });\n\n            // Map all addresses to the bank\n            bank_t::bit_addr_t[MaxCount] addresses_in_bank = map(to_bank_bit_addr, addresses.data);\n\n            return _banks[bank_index].read_bits(valid, addresses_in_bank);\n        });\n\n        vec::vector<bool, MaxCount> result;\n\n        result.size = addresses.size;\n\n        optional<bool>[MaxCount][Banks] transposed_result = transpose(results);\n\n        result.data = map_indices([transposed_result, result](index_t<MaxCount> i)\n        {\n            optional<bool>[Banks] src_row = transposed_result[i];\n\n            optional<bool> selected_bank = first_valid(src_row);\n\n            // if (i < result.size), then exactly one element in src_row will be valid\n            sim_assert(selected_bank.is_valid || (i >= result.size));\n\n            return selected_bank.value;\n        });\n\n        return result;\n    }"}
{"file": "data\\bitarray\\banked.pd", "nl": "Get the value of one bit.", "code": "sim_assert(result.size == 1);\n\n        return result.data[0];\n    }"}
{"file": "data\\bitarray\\banked.pd", "nl": "Get the value of multiple words.", "code": "template<auto MaxCount>\n    inline vec::vector<word_t, MaxCount> read_words\n        ( vec::vector<word_addr_t, MaxCount> addresses //< Addresses of words to read.\n        )\n    {\n        // Broadcast addresses to all banks\n        auto results = parallel_map<Banks>(Banks, [addresses](index_t<Banks> bank_index) -> optional<word_t>[MaxCount]\n        {\n            // Determine which addresses map to this bank\n            bool[MaxCount] valid = map_indices<MaxCount>([bank_index, addresses](index_t<MaxCount> i)\n            {\n                return (i < addresses.size) && (is_word_in_bank(addresses.data[i], bank_index));\n            });\n\n            // Map all addresses to bank addresses\n            bank_t::word_addr_t[MaxCount] addresses_in_bank = map(to_bank_word_addr, addresses.data);\n\n            return _banks[bank_index].read_words(valid, addresses_in_bank);\n        });\n\n        vec::vector<word_t, MaxCount> result;\n\n        result.size = addresses.size;\n\n        optional<word_t>[MaxCount][Banks] transposed_result = transpose(results);\n\n        result.data = map_indices<MaxCount>([transposed_result, result](index_t<MaxCount> i)\n        {\n            optional<word_t>[Banks] src_row = transposed_result[i];\n\n            optional<word_t> selected_bank = first_valid(src_row);\n\n            // if (i < result.size), then exactly one element in src_row will be valid\n            sim_assert(selected_bank.is_valid || (i >= result.size));\n\n            return selected_bank.value;\n        });\n\n        return result;\n    }"}
{"file": "data\\bitarray\\banked.pd", "nl": "Get the value of a single multiple word.", "code": "inline word_t read_word( word_addr_t address //< Addresses of the word to read.) {\n        vec::vector<word_t, 1> result = read_words<1>({{address}, 1});\n        sim_assert(result.size == 1);\n        return result.data[0];\n    }"}
{"file": "data\\bitarray\\banked.pd", "nl": "Set the values of multiple bits.", "code": "template<auto MaxCount>\n    inline void write_bits\n        ( vec::vector<pair<bit_addr_t, bool>, MaxCount> addresses_and_values //< Addresses and values of bits to write.\n        )\n    {\n        // Broadcast parameters to all banks\n        parallel_for<Banks>(Banks, [addresses_and_values](index_t<Banks> bank_index)\n        {\n            // Determine which addresses map to this bank\n            bool[MaxCount] valid = map_indices<MaxCount>([bank_index, addresses_and_values](index_t<MaxCount> i)\n            {\n                return (i < addresses_and_values.size) && (is_bit_in_bank(addresses_and_values.data[i].first, bank_index));\n            });\n\n            auto unzip_result = unzip(addresses_and_values.data);\n\n            // Map all addresses to the bank\n            bank_t::bit_addr_t[MaxCount] addresses_in_bank = map(to_bank_bit_addr, unzip_result.first);\n\n            _banks[bank_index].write_bits(valid, addresses_in_bank, unzip_result.second);\n        });\n    }"}
{"file": "data\\bitarray\\banked.pd", "nl": "Set the value of one bit.", "code": "inline void write_bit( bit_addr_t address //< Address of bit to write., bool value         //< Value to write.) { write_bits<1>({{{address, value}}, 1});}"}
{"file": "data\\bitarray\\banked.pd", "nl": "Set the values of multiple words.", "code": "template<auto MaxCount>\n    inline void write_words\n        ( vec::vector<pair<word_addr_t, word_t>, MaxCount> addresses_and_values //< Addresses and values of words to write.\n        )\n    {\n        // Broadcast parameters to all banks\n        parallel_for<Banks>(Banks, [addresses_and_values](index_t<Banks> bank_index)\n        {\n            // Determine which addresses map to this bank\n            bool[MaxCount] valid = map_indices<MaxCount>([bank_index, addresses_and_values](index_t<MaxCount> i)\n            {\n                return (i < addresses_and_values.size) && (is_word_in_bank(addresses_and_values.data[i].first, bank_index));\n            });\n\n            auto unzip_result = unzip(addresses_and_values.data);\n\n            // Map all addresses to the bank\n            bank_t::word_addr_t[MaxCount] addresses_in_bank = map(to_bank_word_addr, unzip_result.first);\n\n            _banks[bank_index].write_words(valid, addresses_in_bank, unzip_result.second);\n        });\n    }"}
{"file": "data\\bitarray\\banked.pd", "nl": "Set the value of one word.", "code": "inline void write_word( word_addr_t address //< Address of word to write.\n, word_t value        //< Value to write.\n)\n{ \n    write_words<1>({{{address, value}}, 1});\n}"}
{"file": "data\\memory\\pipelined.pd", "nl": "Atomically read and write the memory. //  Returns both the old and new value for the specified element. Must not be called concurrently with other calls that may write to the memory. Note that `modify` may be called multiple times concurrently (one call site per bank).", "code": "inline pair<T, T> atomically\n        ( addr_t addr //< Address of the element to read.\n        , (T)->T modify  //< Function that accepts the value of the element read from the memory\n                         //  and returns a value to write into the memory at the same address.\n        )\n    {\n        auto decomposed_addr = decompose_address(addr);\n\n        pair<T, T> result;\n\n        static for (const auto i : Banks)\n        {\n            if (i == decomposed_addr.first)\n            {\n                [[schedule(BankUpdateRate)]]\n                {\n                    result.first = _memories[i][decomposed_addr.second];\n\n                    result.second = modify(result.first);\n\n                    _memories[i][decomposed_addr.second] = result.second;\n                }\n            }\n        }\n\n        return result;\n    }"}
{"file": "data\\memory\\pipelined.pd", "nl": "Atomically read and write the memory up to `N` times. //  Returns both the old and new value for the specified elements. Must not be called concurrently with other calls that may write to the memory. Throughput can be improved by de-duplicating accesses to the same address before calling this method. Note that `modify` may be called multiple times concurrently (one call site per bank).", "code": "inline pair<T, T>[N] atomically_vec\n        ( optional<addr_t>[N] addresses    //< Addresses of the element to access.\n        , (T, index_t<N>)->T modify        //< Function that accepts the value of an element read from the memory\n                                           //  and an index of an element of the addresses array.\n                                           //  This function returns a value to write into the memory at the same address.\n        )\n    {\n        // Determine the number of request for each bank.\n        // Banks parameter explicitly specified to support the case where Banks = 1.\n        // In this case, the number of banks cannoted be deduced from the return type of address_to_bank_index.\n        auto per_bank_request_count = write_requests_per_bank<Banks>(addresses, address_to_bank_index);\n\n        // Determine the maximum number of reads for any single bank\n        count_t<N> thread_count = maximum(per_bank_request_count);\n\n        return pipelined_last(thread_count, [modify, addresses](index_t<N> tid) -> pair<T, T>[N]\n        {\n            // Determine addresses and banks to access on this iteration\n            auto schedule = schedule_write_requests(\n                addresses,\n                address_to_bank_index,\n                tid);\n\n            optional<pair<T, T>>[N] this_iteration_result;\n\n            static for (const auto i : Banks)\n            {\n                optional<index_t<N>> schedule_entry = schedule[i];\n\n                if (schedule_entry.is_valid)\n                {\n                    index_t<N> address_index = schedule_entry.value;\n\n                    sim_assert(addresses[address_index].is_valid);\n\n                    addr_t addr = addresses[address_index].value;\n\n                    auto decomposed_addr = decompose_address(addr);\n\n                    sim_assert(decomposed_addr.first == i);\n\n                    pair<T, T> this_bank_result;\n\n                    [[schedule(BankUpdateRate)]]\n                    {\n                        this_bank_result.first = _memories[i][decomposed_addr.second];\n\n                        this_bank_result.second = modify(this_bank_result.first, address_index);\n\n                        _memories[i][decomposed_addr.second] = this_bank_result.second;\n                    }\n\n                    this_iteration_result[address_index] = make_optional(true, this_bank_result);\n                }\n            }\n\n            // Combine results across iterations\n            return second(sync::atomically([this_iteration_result](pair<T, T>[N] prev)\n            {\n                return zip_with(from_optional<pair<T, T>>, prev, this_iteration_result);\n            }));\n        });\n    }"}
{"file": "data\\memory\\pipelined.pd", "nl": "Combine and update the set of all elements with a given offset with a bank according to a user-specified function. Must not be called concurrently with other calls that may write to the memory.", "code": "template\n        < typename Ctx //< Context type passed to and returned from the combine function.\n        >\n    inline Ctx bankwise_fold\n        ( addr_t addr //< Logical address of one element within the memory.\n                      // All elements that have matching offsets within banks are combined.\n        , Ctx initial //< Context value passed to the first call to `combine`.\n        , (pair<T, Ctx>)->pair<T, Ctx> combine //< Combination function.\n                                               //  Maps a previous value in the memory and the current context\n                                               //  to a new value stored in the memory and a new context.\n        )\n    {\n        // Determine offset within any given bank\n        auto decomposed_addr = decompose_address(addr);\n        Ctx current_context = initial;\n        static for (const auto i : Banks)         {\n            atomic\n            {\n                T prev = _memories[i][decomposed_addr.second];\n                auto combined = combine(make_pair(prev, current_context));\n                current_context = combined.second;\n                _memories[i][decomposed_addr.second] = combined.first; } }\n        return current_context;\n    }"}
{"file": "data\\memory\\pipelined.pd", "nl": "Write one value into the memory.  Must not be called concurrently with other calls that may write to the memory.", "code": " inline void write\n( addr_t addr //< Address of the element to write.\n    , T data      //< Data to write.\n    )\n{\n    auto decomposed_addr = decompose_address(addr);\n    static for (const auto i : Banks)\n    {\n        if (i == decomposed_addr.first)\n        {\n            _memories[i][decomposed_addr.second] = data;\n        }\n        // Ensure banks are accessed in unique pipeline stages\n        barrier;\n    }\n}"}
{"file": "data\\memory\\pipelined.pd", "nl": "Read one element from the memory.", "code": " inline T read\n    ( addr_t addr //< Address of the element to read.\n    )\n{\n    T result;\n    auto decomposed_addr = decompose_address(addr);\n    static for (const auto i : Banks)\n    {\n        if (i == decomposed_addr.first)\n        {\n            result = _memories[i][decomposed_addr.second];\n        }\n    }\n    return result;\n}"}
{"file": "data\\memory\\pipelined.pd", "nl": "Read `N` elements from the memory.", "code": "\ntemplate\n        < auto N //< The number of elements to read.\n        >\n    inline T[N] read_vec\n        ( addr_t[N] addresses //< The addresses to read from.\n        )\n    {\n        // Banks parameter explicitly specified to support the case where Banks = 1.\n        // In this case, the number of banks cannoted be deduced from the return type of address_to_bank_index.\n        auto per_bank_request_count = read_requests_per_bank<Banks>(addresses, address_to_bank_index);\n        // Determine the maximum number of reads for any single bank\n        count_t<N> thread_count = maximum(per_bank_request_count);\n        return pipelined_last(thread_count, [addresses](index_t<N> tid) -> T[N]\n        {\n            auto schedule = schedule_read_requests(addresses, address_to_bank_index, tid);\n            T[Banks] per_bank_results;\n            static for (const auto i : Banks)\n            {\n                // Select an address for this bank\n                auto address_index = schedule.first[i];\n                addr_t addr = addresses[address_index.value];\n                auto decomposed_addr = decompose_address(addr);\n                sim_assert(!address_index.is_valid || (decomposed_addr.first == i));\n                // Read from this bank\n                per_bank_results[i] = _memories[i][decomposed_addr.second];\n                // Ensure banks are accessed in unique pipeline stages\n                barrier;\n            }\n            // Broadcast per-bank values to requests\n            auto this_thread_results = map(\n                [per_bank_results](optional<bank_index_t> i)\n                {\n                    return make_optional(i.is_valid, per_bank_results[i.value]);\n                },\n                schedule.second);\n            // Combine requests across threads\n            return second(sync::atomically([this_thread_results](T[N] prev)\n            {\n                return zip_with(from_optional<T>, prev, this_thread_results);\n            }));\n        });\n    "}
{"file": "data\\memory\\pipelined.pd", "nl": "Write up to `N` values into the memory. Must not be called concurrently with other calls that may write to the memory. Throughput can be improved by de-duplicating writes to the same address before calling this method.", "code": "template\n    < auto N //< The maximum number of elements to write.\n    >\ninline void write_vec\n    ( optional<pair<addr_t, T>>[N] writes //< Addresses and corresponding values.\n    )\n{\n    // unzip to address and data arrays\n    pair<optional<addr_t>[N], T[N]> unzipped = unzip_with(\n        [](optional<pair<addr_t, T>> write) -> pair<optional<addr_t>, T>\n        {\n            return { make_optional(write.is_valid, write.value.first), write.value.second };\n        },\n        writes\n    );\n    // Determine the number of request for each bank.\n    // Banks parameter explicitly specified to support the case where Banks = 1.\n    // In this case, the number of banks cannoted be deduced from the return type of address_to_bank_index.\n    auto per_bank_request_count = write_requests_per_bank<Banks>(unzipped.first, address_to_bank_index);\n    // Determine the maximum number of reads for any single bank\n    count_t<N> thread_count = maximum(per_bank_request_count);\n    pipelined_for (thread_count, [unzipped](index_t<N> tid)\n    {\n        // Determine which data to write to which bank on this iteration.\n        auto schedule = schedule_write_requests(\n            unzipped.first,\n            address_to_bank_index,\n            tid);\n        static for (const auto i : Banks)\n        {\n            optional<index_t<N>> schedule_entry = schedule[i];\n            if (schedule_entry.is_valid)\n            {\n                sim_assert(unzipped.first[schedule_entry.value].is_valid);\n                addr_t addr = unzipped.first[schedule_entry.value].value;\n                T data = unzipped.second[schedule_entry.value];\n                auto decomposed_addr = decompose_address(addr);\n                sim_assert(decomposed_addr.first == i);\n                _memories[i][decomposed_addr.second] = data;\n            }\n            // Ensure banks are accessed in unique pipeline stages\n            barrier;\n        }\n    });\n}"}
{"file": "type\\stdtype.pd", "nl": "Type of index for a collection of N elements", "code": "template <auto N>\nusing index_t = uint<(N > 1) ? clog2(N) : 1>;\n\ntemplate <typename T>\nusing bitindex_t = index_t<bitsizeof(T)>;"}
{"file": "type\\stdtype.pd", "nl": "Type to express a count of N elements", "code": "template <auto N>\nusing count_t = uint<clog2(N + 1)>;\n\ntemplate <typename T>\nusing bitcount_t = count_t<bitsizeof(T)>;"}
{"file": "type\\newtype.pd", "nl": "Defines a struct with one field of type `T`. At runtime a value of newtyp<T> is equivalent to a value of type T. Since newtype<T> is a unique type that is not implicitly convertible to/from T, it can be used to improve type safety.", "code": "template <typename T>\nstruct newtype\n{\n    T unwrap;\n}"}
{"file": "type\\newtype.pd", "nl": "Wrap a value into a newtype", "code": "template <typename T>\ninline newtype<T> wrap_newtype(T x)\n{\n    return {x};\n}"}
{"file": "type\\newtype.pd", "nl": "Unwrap a value of a newtype", "code": "template <typename T>\ninline T unwrap_newtype(newtype<T> x)\n{\n    return x.unwrap;\n}"}
{"file": "type\\coerce.pd", "nl": "Forcibly convert the input type to the output type `T`. // This overrides any compile-time check from the built-in `cast` operator by casting the input to an intermediate `uint` type before casting to `T`. If `T` is wider than the input, then due to the intermediate trip through `uint` the result is zero extended. If `T` is narrower than the input, truncate the most-significant bits.", "code": "template <typename T /*< Output*/>\ninline T reinterpret_cast(auto x)\n{\n    return cast<T>(cast<uint<bitsizeof T>>(cast<uint<bitsizeof x>>(x)));\n}"}
{"file": "type\\coerce.pd", "nl": "A wrapper around the built-in `cast` operator, allowing it to be used", "code": "template <typename T>\ninline T static_cast(auto x)\n{\n    return cast<T>(x);\n}"}
{"file": "type\\coerce.pd", "nl": "`cast` then `sim_assert` that the output equals the input.", "code": "template <typename T>\ninline T checked_cast(auto x)\n{\n    auto y = cast<T>(x);\n\n    sim_assert(y == x);\n\n    return y;\n}"}
{"file": "type\\coerce.pd", "nl": "Cast a value from type `From` to type `To` and return whether the cast was done without losing information. For example, the `uint32` value `255` can be cast to a `uint8` without losing information, but casting the `uint32` value `257` to a `uint8` is lossy.", "code": "template<typename To, typename From>\ninline optional<To> safe_cast(From input)\n{\n    To result = cast<To>(input);\n\n    bool castWasSafe = (cast<From>(result) == input);\n\n    return make_optional<To>(castWasSafe, result);\n}"}
{"file": "numeric\\int\\operator\\unsigned.pd", "nl": "Returns `t - u`. // The result type is the same (unsigned) type as `t`.`u` must be no greater than `t` (to ensure the result is non-negative).", "code": "inline T sub(T t, U u)\n{\n    static assert(!limits<T>::is_signed);\n    static assert(!limits<U>::is_signed);\n\n    sim_assert(u <= t);\n\n    return static_cast<T>(t - u);\n}"}
{"file": "numeric\\int\\operator\\unsigned.pd", "nl": "Returns `t - 1` // The result type is the same (unsigned) type as `t`.`t` must be positive (to ensure the result is positive).", "code": "inline T decrement(T t)\n{\n    return sub(t, 1);\n}"}
{"file": "numeric\\int\\operator\\unsigned.pd", "nl": "If `b` is true, then returns `t - 1`. // Returns `t` otherwise. The result type is the same (unsigned) type as `t`. The caller must ensure that the decrement would not result in a negative number.", "code": "inline T decrement_if(T t, bool b)\n{\n    return sub(t, cast<uint1>(b));\n}"}
{"file": "numeric\\int\\operator.pd", "nl": "Compute the absolute value of `a`. The return type is an unsigned integer of the same width as `a`.", "code": "template<typename T>\ninline uint<bitsizeof T> abs(T a)\n{\n    // To avoid 2:1 muxes for each output bit\n    // the result is computed as `(a ^ mask) + addend`\n    // When `a` is positive, `mask = 0` and `addend = 0`\n    // and so the logic simply returns `a`.\n    // When `a` is negative, `mask = -1` and `addend = 1`\n    // which has the effect of flipping all bits and then adding one\n    // which is what the unary negate (`-`) operator does.\n    bool is_neg = a < 0;\n\n    bool[bitsizeof T] mask_bits;\n    static for (const auto i : bitsizeof T)\n    {\n        mask_bits[i] = is_neg;\n    }\n\n    T mask = cast<T>(mask_bits);\n\n    uint1 addend = cast<uint1>(is_neg);\n\n    return cast<uint<bitsizeof T>>((a ^ mask) + addend);\n}"}
{"file": "numeric\\int\\operator.pd", "nl": "Add two values of the input type `T` and return the result as the output type `R`, which might be larger.  e.g. 3 fits in a `uint2`, but 3 + 3 does not.", "code": "template <typename R, typename T>\ninline R add(T a, T b)\n{\n    return a + b;\n}"}
{"file": "numeric\\int\\operator.pd", "nl": "Returns the floor of the quotient when dividing `numerator` by `denominator`.", "code": "inline auto div(auto numerator, auto denominator)\n{\n    sim_assert(denominator > 0);\n    return numerator / denominator;\n}"}
{"file": "numeric\\int\\operator.pd", "nl": "Returns the ceiling of the quotient when dividing `numerator` by `denominator`.", "code": "inline auto ceil_div(auto numerator, auto denominator)\n{\n    sim_assert(denominator > 0);\n\n    return cast<decltype(numerator)>((numerator + denominator - 1)) / denominator;\n}"}
{"file": "numeric\\int\\operator.pd", "nl": "Returns the remainder when dividing `numerator` by `denominator`.", "code": "template<auto Offset = 0>\ninline auto mod(auto numerator, auto denominator)\n{\n    static if(Offset == 0)\n    {\n        return numerator % denominator;\n    }\n    else\n    {\n        return (cast<decltype(numerator)>(numerator - Offset) % denominator) + Offset;\n    }\n}"}
{"file": "numeric\\int\\operator.pd", "nl": "Returns the floor of the quotient and remainder when dividing `numerator` by `denominator`.", "code": "template<auto Offset = 0>\ninline auto div_mod(auto numerator, auto denominator)\n{\n    return make_pair(div(numerator, denominator), mod<Offset>(numerator, denominator));\n}"}
{"file": "numeric\\int\\operator.pd", "nl": "Returns the ceiling of the quotient and remainder when dividing `numerator` by `denominator`.", "code": "template<auto Offset = 0>\ninline auto ceil_div_mod(auto numerator, auto denominator)\n{\n    return make_pair(ceil_div(numerator, denominator), mod<Offset>(numerator, denominator));\n}"}
{"file": "numeric\\int\\operator.pd", "nl": "Increment the input by 1.", "code": "inline auto increment(auto a)\n{\n    return a + 1;\n}"}
{"file": "numeric\\int\\operator.pd", "nl": "Return xor of inputs.", "code": "inline auto xor(auto a, auto b)\n{\n    return a ^ b;\n}"}
{"file": "numeric\\int\\operator\\modular.pd", "nl": "Returns `(a + b) mod M`.", "code": "inline auto add(A a, B b)\n{\n    static assert(!limits<A>::is_signed);\n    static assert(!limits<B>::is_signed);\n\n    // Inputs must be less than M\n    sim_assert(a < M);\n    sim_assert(b < M);\n\n    static if (((M & (M - 1)) == 0))\n    {\n        // M is a power of 2, simply throw away upper bits\n        return cast<index_t<M>>(a + b);\n    }\n    else\n    {\n        auto result = a + b;\n\n        // Check if the addition overflowed, substract the modulus value if it did.\n        // This is done with a subtraction (expensive operation) followed by checking the sign bit (cheap operation)\n        // rather than comparison (expensive) followed by subtraction (expensive)\n        auto diff = result - M;\n\n        if (!sign_bit(diff))\n        {\n            // A subtraction of M is sufficient to restore result to [0, M)\n            // because both inputs are < M\n            result = cast<decltype(result)>(diff);\n        }\n\n        sim_assert(result < M);\n\n        return cast<index_t<M>>(result);\n    }\n}"}
{"file": "numeric\\int\\operator\\modular.pd", "nl": "Returns `(a + 1) mod M`. // `a` must be less than `M`.", "code": "inline auto increment(A a)\n{\n    return add<A, uint1, M>(a, 1);\n}"}
{"file": "numeric\\int\\operator\\modular.pd", "nl": "If `b` is true, then returns `(a + 1) mod M`. // returns `a` otherwise. `a` must be less than `M`.", "code": "template\n    < typename A                    // Type of a.  Must be unsigned.\n    , auto M = (1 << bitsizeof(A))  // Modulus value.\n    >inline auto increment_if(A a, bool b)\n{\n    return add<A, uint1, M>(a, cast<uint1>(b));\n}"}
{"file": "numeric\\int\\operator\\modular.pd", "nl": "Returns `(a - b) mod M`.  `a` and `b` must be less than `M`.", "code": "inline auto sub(A a, B b)\n{\n    static assert(!limits<A>::is_signed);\n    static assert(!limits<B>::is_signed);\n\n    // Inputs must be less than M\n    sim_assert(a < M);\n    sim_assert(b < M);\n\n    static if (((M & (M - 1)) == 0))\n    {\n        // M is a power of 2, simply throw away upper bits\n        return cast<index_t<M>>(a - b);\n    }\n    else\n    {\n        auto result = a - b;\n\n        // Check if the subtraction underflowed.  Add the modulus value if it did.\n        // Check for underflow is implemented by checking the sign bit.\n        if (sign_bit(result))\n        {\n            // A single addition of M is sufficient to restore result to [0, M)\n            // because both inputs are < M\n            result = result + M;\n\n            sim_assert(result >= 0);\n        }\n\n        sim_assert(result < M);\n\n        return cast<index_t<M>>(result);\n    }\n}"}
{"file": "numeric\\int\\operator\\modular.pd", "nl": "Returns `(a - 1) mod M`. `a` must be less than `M`.", "code": "template\n    < typename A                    //< Type of the operand.  Must be unsigned.\n    , auto M = (1 << bitsizeof(A))  //< Modulus value.\n    >inline auto decrement(A a)\n{\n    return sub<A, uint1, M>(a, 1);\n}"}
{"file": "numeric\\int\\operator\\modular.pd", "nl": "If `b` is true, then returns `(a - 1) mod M`. // returns `a` otherwise. `a` must be less than `M`.", "code": "template\n    < typename A                    // Type of a.  Must be unsigned.\n    , auto M = (1 << bitsizeof(A))  // Modulus value.\n    >inline auto decrement_if(A a, bool b)\n{\n    return sub<A, uint1, M>(a, cast<uint1>(b));\n}"}
{"file": "device\\Stratix10\\numeric\\float32\\operator.pd", "nl": "Floating-point multiplication.", "code": "inline float32 mul(float32 x, float32 y)\n{\n    return fmul32(x, y);\n}"}
{"file": "device\\Stratix10\\numeric\\float32\\operator.pd", "nl": "Floating-point addition.", "code": "inline float32 add(float32 x, float32 y)\n{\n    return fadd32(x, y);\n}"}
{"file": "device\\Stratix10\\numeric\\float32\\operator.pd", "nl": "Floating-point subtraction.", "code": "inline float32 sub(float32 x, float32 y)\n{\n    return fsub32(x, y);\n}"}
{"file": "device\\Stratix10\\numeric\\float32\\operator.pd", "nl": "Floating-point multiply-accumulate.", "code": "inline float32 mad(float32 x, float32 y, float32 z)\n{\n    return fmad32(x, y, z);\n}"}
{"file": "numeric\\fixed\\internal.pd", "nl": "Input a value in the range [1, 2) without the implicit leading one.", "code": "template<auto F1, auto F2>\ninline uint<1 + F2> rcp_lookup(uint<F1> fraction)\n{\n    const uint<RCP_TABLE_LG_SIZE> index = fraction >> (F1 - RCP_TABLE_LG_SIZE);\n    const uint<F1 - RCP_TABLE_LG_SIZE> delta = fraction;\n\n    static assert(F1 >= RCP_C0_FBIT);\n    static assert(F1 >= RCP_C1_FBIT);\n    const auto coefficients = rcp_coefficient_table[index];\n    const auto c0 = coefficients.c0 << (F1 - RCP_C0_FBIT);\n    const auto c1 = coefficients.c1 << (F1 - RCP_C1_FBIT);\n    const auto sumValue = ((c1 * delta) >> F1) + c0;\n\n    static assert(F1 >= F2);\n    return sumValue >> (F1 - F2);\n}"}
{"file": "numeric\\fixed\\internal.pd", "nl": "[Newton-Raphson method](https://en.wikipedia.org/wiki/Newton%27s_method). Input a significand in the range [1, 2) and an approximation in the range ~(0.5, 1].// Output a value in the range ~(0.5, 1].", "code": "template<auto F1, auto F2, auto F3>\ninline uint<1 + F3> rcp_refine(uint<1 + F1> significand, uint<1 + F2> approximation)\n{\n    const auto tempFbitCount = F1 + F2;\n    const auto temp_0 =  significand * approximation;\n    const auto temp_1 = (2 << tempFbitCount) - temp_0;\n\n    const auto refinedFbitCount = F2 + tempFbitCount;\n    const auto refinedValue = approximation * temp_1;\n\n    static assert(refinedFbitCount >= F3);\n    return refinedValue >> (refinedFbitCount - F3);\n}"}
{"file": "numeric\\fixed\\internal.pd", "nl": "Input a value in the range [0, 2) in multiple of pi radian. // Output the sine in the range [-1, 1].", "code": "template<auto F1, auto F2>\ninline int<2 + F2> sin_pirad(uint<1 + F1> value)\n{\n    uint9 index = (value << (SIN_TABLE_LG_SIZE - 1)) >> F1;\n\n    // base for modified value\n    uint<1 + F1> segmentbase = index << (F1 + 1 - SIN_TABLE_LG_SIZE);\n    uint<1 + F1> difference = value - segmentbase;\n\n    const auto coefficients = sin_coefficient_table[index];\n    const auto c2 = coefficients.c2;\n    const auto c1 = coefficients.c1;\n    const auto c0 = coefficients.c0;\n\n    const uint6 tmpFbit = SIN_C2_FBIT + F1;\n    auto tmp = c2 * difference + (c1 << (tmpFbit - SIN_C1_FBIT));\n    const auto resultTmpFbit = tmpFbit;\n    auto resultTmp = ((tmp * difference) >> F1) + (c0 << (resultTmpFbit - SIN_C0_FBIT));\n    int<2 + F2> result = (resultTmp >> (resultTmpFbit - F2)) + ((resultTmp >> (resultTmpFbit - F2 - 1)) & 1);\n    return result;\n}"}
{"file": "numeric\\fixed\\internal.pd", "nl": "Input a value in the range [0, 2) in multiple of pi radian. Output the cosine in the range [-1, 1].", "code": "template<auto F1, auto F2>\ninline int<2 + F2> cos_pirad(uint<1 + F1> value)\n{\n    uint9 index = (value << (COS_TABLE_LG_SIZE - 1)) >> F1;\n\n    // base for modified value\n    uint<1 + F1> segmentbase = index << (F1 + 1 - COS_TABLE_LG_SIZE);\n    uint<1 + F1> difference = value - segmentbase;\n\n    const auto coefficients = cos_coefficient_table[index];\n    const auto c2 = coefficients.c2;\n    const auto c1 = coefficients.c1;\n    const auto c0 = coefficients.c0;\n\n    const uint6 tmpFbit = COS_C2_FBIT + F1;\n    auto tmp = c2 * difference + (c1 << (tmpFbit - COS_C1_FBIT));\n    const auto resultTmpFbit = tmpFbit;\n    auto resultTmp = ((tmp * difference) >> F1) + (c0 << (resultTmpFbit - COS_C0_FBIT));\n    int<2 + F2> result = (resultTmp >> (resultTmpFbit - F2)) + ((resultTmp >> (resultTmpFbit - F2 - 1)) & 1);\n    return result;\n}"}
{"file": "text\\parser.pd", "nl": "Record a single transition.", "code": "void record_transition(coverage_row_index_t from_state, coverage_columns_index_t to_state)\n    {\n        if (ENABLE_COVERAGE)\n        {\n            index_t<BRAM_WORD_SIZE> bit_index = to_state;\n            auto word_index = ONE_BRAM_WORD_ROW_PER_ROW \n                ? from_state \n                : concat(from_state, cast<bram_word_index_t>(to_state >> BRAM_WORD_SIZE_LOG_2));\n                //_detected_transitions[concat(from_state, biu.indices.word_index)].bits[bit_index] = 1;\n            atomic\n            {\n                bram_word w = _detected_transitions[word_index];\n                w.bits[bit_index] = 1;\n                _detected_transitions[word_index] = w;\n            }\n        }\n    }"}
{"file": "text\\parser.pd", "nl": "Detect a transition at a particular state. 1 indicates a transition.", "code": "uint32 get_result_data(coverage_row_index_t row, bram_word_index_t word_index)\n    {\n        uint32 result;\n        auto idx = ONE_BRAM_WORD_ROW_PER_ROW ? row : concat(row, word_index);\n        result = _detected_transitions[idx].value;\n        return result;\n    }"}
{"file": "text\\parser.pd", "nl": "Check if the parser has encountered an error.", "code": "inline bool is_error(result_t parse_result)\n    {\n        return parse_result.parser_state.current_row_index == 0;\n    }"}
{"file": "text\\parser.pd", "nl": "Check if the parser stack depth == 0 indicating that it is not inside an array or object.", "code": "inline bool is_stack_empty(result_t parse_result)\n    {\n        return parse_result.parser_state.stack.depth == 0;\n    }"}
{"file": "numeric\\int\\multi_word.pd", "nl": "Return the sum and carry generated by adding  `a`, `b`, and `carry`. Expected iteration order while calling this over multiple words: Least significant to most significant", "code": "template\n    < typename T //< Type of values to be added\n    >inline pair<T, uint1> add_with_carry\n    ( T a //< The first operand for addition\n    , T b //< The second operand for addition\n    , uint1 carry //< The input carry\n    )\n{ \n    // The sum with carry can be computed by expression: a + b + carry\n    // but that will generate two T bit adders. The expression below \n    // uses only one T+1 bit adder. The LSB of left operand of '+' \n    // below is 1 and LSB of the second operand is carry. Due to their\n    // addition, the incoming carry for LSB of a and b is same as the \n    // carry passed as paramter. The final right shift removes the \n    // sum of 1 and carry from the result.\n    auto sum_w_carry = (((a << 1) | 1) + ((b << 1) | carry)) >> 1;\n    auto carry_out = cast<uint1>(sum_w_carry >> bitsizeof(T));\n    auto sum = cast<T>(sum_w_carry);\n    return make_pair(sum, carry_out);\n}"}
{"file": "numeric\\int\\multi_word.pd", "nl": "Return the difference and borrow generated by subtracting `a`, `b`, and `borrow`. Expected iteration order while calling this over multiple words: Least significant to most significant", "code": "inline pair<T, uint1> sub_with_borrow\n    ( T a //< The first operand for subtraction\n    , T b //< The second operand for subtraction\n    , uint1 borrow //< The input borrow\n    )\n{ \n    // The sub with borrow can be computed by expression: a - b - borrow\n    // but that will generate two T bit subtractors. The expression below \n    // uses only one T+1 bit subtractor. The LSB of left operand of '-' \n    // below is 0 and LSB of the second operand is borrow. Due to their\n    // subtraction, the incoming borrow for LSB of a and b is same as the \n    // borrow passed as paramter. The final right shift removes the \n    // subtraction of 0 and borrow from the result.\n    auto sub_w_borrow = ((a << 1) - ((b << 1) | borrow)) >> 1;\n    auto borrow_out = cast<uint1>(sub_w_borrow >> bitsizeof(T));\n    auto sub = cast<T>(sub_w_borrow);\n    return make_pair(sub, borrow_out);\n}"}
{"file": "numeric\\int\\multi_word.pd", "nl": "This function is used while computing min of two multi-word variables a_words and b_words, to which a and b belong. It selects `a` if a_words < b_words, or `b` if b_words < a_words. It also returns the metadata to be used as incoming metadata for the next call to this function. Expected iteration order while calling this over multiple words: Most significant to least significant", "code": "inline pair<T, comp_metadata> min_with_metadata\n    ( T a //< The first operand for min\n    , T b //< The second operand for min\n    , comp_metadata prev_metadata //< The incoming metadata\n    )\n{\n    \n    T ret_word = prev_metadata.all_previous_words_eq ?\n                    a < b ? a : b\n                 :  prev_metadata.select_a_words_on_prevnoteq ? a : b;\n    comp_metadata ret_metadata;\n    bool eq_a_b = a == b;\n    ret_metadata.all_previous_words_eq = prev_metadata.all_previous_words_eq && eq_a_b;\n    ret_metadata.select_a_words_on_prevnoteq = !prev_metadata.all_previous_words_eq ?\n                                                     prev_metadata.select_a_words_on_prevnoteq\n                                                :    !eq_a_b ? a < b : prev_metadata.select_a_words_on_prevnoteq;\n    return make_pair(ret_word, ret_metadata);\n}"}
{"file": "numeric\\int\\multi_word.pd", "nl": "This function is used while computing max of two multi-word variables a_words and b_words, to which a and b belong. It selects `a` if a_words > b_words, or `b` if b_words > a_words. It also returns the metadata to be used as incoming metadatafor the next call to this function. Expected iteration order while calling this over multiple words: Most significant to least significant", "code": "inline pair<T, comp_metadata> max_with_metadata\n    ( T a //< The first operand for max\n    , T b //< The second operand for max\n    , comp_metadata prev_metadata //< The incoming metadata\n    )\n{\n    \n    T ret_word = prev_metadata.all_previous_words_eq ?\n                    a > b ? a : b\n                 :  prev_metadata.select_a_words_on_prevnoteq ? a : b;\n    comp_metadata ret_metadata;\n    bool eq_a_b = a == b;\n    ret_metadata.all_previous_words_eq = prev_metadata.all_previous_words_eq && eq_a_b;\n    ret_metadata.select_a_words_on_prevnoteq = !prev_metadata.all_previous_words_eq ?\n                                                     prev_metadata.select_a_words_on_prevnoteq\n                                                :    !eq_a_b ? a > b : prev_metadata.select_a_words_on_prevnoteq;\n    return make_pair(ret_word, ret_metadata);\n}"}
{"file": "numeric\\decimal\\internal.pd", "nl": "Check if NaN, zero, infinite, or finite.", "code": "template\n    < auto Width //< Width in bits of the decimal. This must be 32 for decimal32 or 64 for decimal64.\n    >inline specialCaseFlags getSpecialCases_internal(uint<Width> a)\n{\n    static assert(Width == 32 || Width == 64);\n    specialCaseFlags flags;\n    const auto input = parseDecimalValue<Width>(a);\n    const uint4 first4CombinationBits = (a >> (Width - 5));\n    const auto nonfiniteCheck = (first4CombinationBits == ((1 << 4) - 1));\n    const uint1 fifthCombinationBit = (a >> (Width - 6));\n    flags.nan = nonfiniteCheck && (fifthCombinationBit == 1);\n    flags.inf = nonfiniteCheck && (fifthCombinationBit == 0);\n    flags.finite = !nonfiniteCheck;\n    flags.zero = input.integer == 0 && !nonfiniteCheck;\n    return flags;\n}"}
{"file": "numeric\\decimal\\internal.pd", "nl": "If `a + b` cannot be represented exactly return invalid.", "code": "template<auto Width, auto Max>\ninline optional<uint<Width>> add_exactly_internal(decimalParsedValue<Width> a, decimalParsedValue<Width> b)\n{\n    // normalize exponent\n    const auto params = get_normalized_params<Width, decimal<Width>::normalized_width, decimal<Width>::max_valid_exp_diff>(a, b);\n    const auto isLargerA = params.integerA > params.integerB;\n\n    decimalParsedValue<Width> result;\n    uint<decimal<Width>::normalized_width> sum;\n    if(a.sign == b.sign)\n    {\n        sum = params.integerA + params.integerB;\n        result.sign = a.sign;\n    }\n    else\n    {\n        if(isLargerA)\n        {\n            sum = params.integerA - params.integerB;\n            result.sign = (a.sign == 1) ? 1 : 0;\n        }\n        else\n        {\n            sum = params.integerB - params.integerA;\n            result.sign = (b.sign == 1) ? 1 : 0;\n        }\n    }\n    result.integer = cast<decltype(result.integer)>(sum); // sum <= Max check below handles the overflow case\n    result.exponent = params.isMinusOrder ? a.exponent : b.exponent;\n\n    return {(sum <= Max) && params.isLessMaxValidExpDiff, toDecimal<Width>(result)};\n}"}
{"file": "numeric\\decimal\\internal.pd", "nl": "If `a * b` cannot be represented exactly return invalid.", "code": "template<auto Width, auto Max, auto Bias>\ninline optional<uint<Width>> mul_exactly_internal(decimalParsedValue<Width> a, decimalParsedValue<Width> b)\n{\n    const auto sign = (a.sign == b.sign) ? 0 : 1;\n    const auto mul = a.integer * b.integer;\n    const auto exponent = a.exponent + b.exponent - Bias;\n    const auto isNormal = exponent >= 0;\n    return {(mul <= Max) && isNormal, toDecimal<Width>({mul, exponent, sign})};\n}"}
{"file": "numeric\\decimal\\internal.pd", "nl": "Calculate the quotient and remainder from dividing `a` by `b`. The return value is an array with the first element being the quotient and the second element being the remainder. If the result cannot be represented exactly return invalid.", "code": "template\n    < auto Width\n     , auto Max\n     , auto Bias\n     , auto UnrollingFactor //< Chunks of numerator bits of this size are processed in parallel,\n                            // meaning the outer loop only has to execute\n                            // `bitsizeof(uint<normalizedIntegerWidth>)/UnrollingFactor` iterations.\n     >inline optional<uint<Width>[2]> div_exactly_internal(decimalParsedValue<Width> a, decimalParsedValue<Width> b)\n{\n    // normalize exponent\n    const auto MaxValidExpDiff = (decimal<Width>::max_valid_exp_diff) * 2 - 1;\n    const auto normalizedIntegerWidth = MaxValidExpDiff * 5 + 3;\n    const auto params = get_normalized_params<Width, normalizedIntegerWidth, MaxValidExpDiff>(a, b);\n    const auto exponent = params.isMinusOrder ? a.exponent : b.exponent;\n\n    // unsigned divider\n    // integerB is used to pass the assert of non-zero denominator\n    const uint<normalizedIntegerWidth> integerB = (params.integerB != 0) ? params.integerB : 1;\n    const auto div =\n        DU::divide<uint<normalizedIntegerWidth>, uint<normalizedIntegerWidth>, UnrollingFactor>(params.integerA, integerB);\n\n    // check exponent gap\n    const bool isExtraLargerB = params.isMinusOrder && !params.isLessMaxValidExpDiff;\n    const bool isExtraLargerA = !params.isMinusOrder && !params.isLessMaxValidExpDiff;\n\n    const auto signQuotient = a.sign ^ b.sign;\n    const auto signRemainder = a.sign;\n    const uint<Width> quotient = isExtraLargerB ? 0 : toDecimal<Width>({div[0], Bias, signQuotient});\n    const uint<Width> remainder =\n        isExtraLargerB ? toDecimal<Width>({a.integer, a.exponent, signRemainder}) : toDecimal<Width>({div[1], exponent, signRemainder});\n    const bool isValid = isExtraLargerA ? false :\n                         isExtraLargerB ? true : ((div[0] <= Max) && params.isLessMaxValidExpDiff);\n\n    uint<Width>[2] result;\n    result[0] = quotient;\n    result[1] = remainder;\n\n    return make_optional<uint<Width>[2]>(isValid, result);\n}"}
{"file": "numeric\\decimal\\internal.pd", "nl": "Return the smaller of x and y.", "code": "template<auto Width, auto Nan>\ninline uint<Width> min_internal(uint<Width> x, uint<Width> y)\n{\n    return minmax<Width, Nan>(lt_internal<Width>, x, y);\n}"}
{"file": "numeric\\decimal\\internal.pd", "nl": "Return the larger of x and y.", "code": "template<auto Width, auto Nan>\ninline uint<Width> max_internal(uint<Width> x, uint<Width> y)\n{\n    return minmax<Width, Nan>(gt_internal<Width>, x, y);\n}"}
{"file": "numeric\\decimal\\internal.pd", "nl": "Return `max(x - y, 0)`. Return NaN if x or y is NaN.", "code": "template<auto Width, auto Max, auto Zero, auto Nan, auto PosInf, auto NegInf>\ninline optional<uint<Width>> dim_exactly_internal(uint<Width> x, uint<Width> y)\n{\n    const auto a = parseDecimalValue<Width>(x);\n    auto b = parseDecimalValue<Width>(y);\n    const auto a_flags = getSpecialCases_internal<Width>(x);\n    const auto b_flags = getSpecialCases_internal<Width>(y);\n\n    optional<uint<Width>> result;\n    if(a_flags.nan || b_flags.nan)\n    {\n        result.is_valid = true;\n        result.value = Nan;\n    }\n    else\n    {\n        if(gt_internal<Width>(x, y))\n        {\n            // substract\n            if (a_flags.inf || b_flags.inf)\n            {\n                result.is_valid = true;\n                if(a_flags.inf && b_flags.inf)\n                {\n                    result.value = (a.sign == b.sign) ? Nan :\n                            (a.sign == 0) ? PosInf : NegInf;\n                }\n                else\n                {\n                    result.value =\n                        ((a.sign == 1 && !b_flags.inf) || (b.sign == 0 && !a_flags.inf)) ? NegInf : PosInf;\n                }\n            }\n            else if(a_flags.zero)\n            {\n                // negate y\n                result.is_valid = true;\n                result.value = y ^ (1 << (Width - 1));\n            }\n            else if(b_flags.zero)\n            {\n                result.is_valid = true;\n                result.value = x;\n            }\n            else\n            {\n                b.sign = ~b.sign;\n                result = add_exactly_internal<Width, Max>(a, b);\n            }\n        }\n        else\n        {\n            result = {true, Zero};\n        }\n    }\n    return result;\n}"}
{"file": "data\\memory\\bank\\schedule.pd", "nl": "Count the number of unique read requests for each bank. More than 1 request per bank indicates conflict.", "code": "template < auto Banks, typename Address, auto Addresses   //< Number of addresses processed per call.\n>inline count_t<Addresses>[Banks] read_requests_per_bank\n    ( Address[Addresses] addresses                      //< Input addresses, duplicates allowed.\n    , (Address) -> index_t<Banks> address_to_bank_index //< Map `Address` to bank index.\n    )\n{\n    return requests_per_bank<Banks>(unique(addresses), address_to_bank_index);\n}"}
{"file": "data\\memory\\bank\\schedule.pd", "nl": "Count the number of write requests for each bank.", "code": "inline count_t<Addresses>[Banks] write_requests_per_bank\n    ( optional<Address>[Addresses] addresses            //< Input addresses, valid duplicates __not__ allowed.\n    , (Address) -> index_t<Banks> address_to_bank_index //< Map `Address` to bank index.\n    )\n{\n    return requests_per_bank<Banks>(addresses, address_to_bank_index);\n}"}
{"file": "data\\memory\\bank\\schedule.pd", "nl": "For each iteration, calculate the pair: //  1. The optional address indices for each bank.//  2. The optional bank index for each address.", "code": "inline pair<optional<index_t<Addresses>>[Banks], optional<index_t<Banks>>[Addresses]> schedule_read_requests\n    ( Address[Addresses] addresses                      //< Input addresses, duplicates allowed.\n    , (Address) -> index_t<Banks> address_to_bank_index //< Map `Address` to bank index.\n    , index_t<Addresses> iteration                      //< Index of bank requests to retrieve from schedule.\n    )\n{\n    // Example:\n    // 3 Banks, 5 addresses per call.\n    // unique_addresses =  {0, x, 3, 2, 1}\n    // bank_indices     =  {0, 0, 2, 1, 1}\n    // -----------------------------------\n    // table = { {true,  0, 0}\n    //         , {false, 0, 1}\n    //         , {true,  2, 2}\n    //         , {true,  1, 3}\n    //         , {true,  1, 4}\n    //         }\n    // ----------------------------------\n    // masked_table bank 0 = { {true,  0}\n    //                       , {false, 1}\n    //                       , {false, 2}\n    //                       , {false, 3}\n    //                       , {false, 4}\n    //                       }\n    // masked_table bank 1 = { {false, 0}\n    //                       , {false, 1}\n    //                       , {false, 2}\n    //                       , {true,  3}\n    //                       , {true,  4}\n    //                       }\n    // masked_table bank 2 = { {false, 0}\n    //                       , {false, 1}\n    //                       , {true,  2}\n    //                       , {false, 3}\n    //                       , {false, 4}\n    //                       }\n    // ------------------------------------\n    // gathered_table bank 0 = { {true,  0}\n    //                         , {false, 1}\n    //                         , {false, 2}\n    //                         , {false, 3}\n    //                         , {false, 4}\n    //                         }\n    // gathered_table bank 1 = { {true,  3}\n    //                         , {true,  4}\n    //                         , {false, 0}\n    //                         , {false, 1}\n    //                         , {false, 2}\n    //                         }\n    // gathered_table bank 2 = { {true,  2}\n    //                         , {false, 0}\n    //                         , {false, 1}\n    //                         , {false, 3}\n    //                         , {false, 4}\n    //                         }\n    // ------------------------------------\n    // iteration 0:\n    // iteration_address_indices = {0, 3, 2}\n    // iteration_bank_indices    = {0, x, 2, 1, x}\n    //\n    // iteration 1:\n    // iteration_address_indices = {x, 4, x}\n    // iteration_bank_indices    = {x, x, x, x, 1}\n\n    optional<Address>[Addresses] unique_addresses = unique(addresses);\n    auto iai = schedule_requests(unique_addresses, address_to_bank_index, iteration);\n\n    // Calculate iteration_bank_indices.\n    // For each address a:\n    // Return true if any element a' of iteration_address_indices is valid\n    // and addresses[a'.value] == a.\n    // Finally, zip the valids together with the bank_indices into an optional.\n    bool[Addresses] valid_addresses = map\n        ( [iai, addresses](Address address)\n          {\n              return any\n                  ( [addresses, address](optional<index_t<Addresses>> iteration_address_index)\n                    {\n                        return iteration_address_index.is_valid && addresses[iteration_address_index.value] == address;\n                    }\n                  , iai\n                  );\n          }\n        , addresses\n        );\n    auto bank_indices = map(address_to_bank_index, addresses);\n    auto iteration_bank_indices = zip_with(make_optional<index_t<Banks>>, valid_addresses, bank_indices);\n    return make_pair(iai, iteration_bank_indices);\n}"}
{"file": "data\\memory\\bank\\schedule.pd", "nl": "Calculate the optional address indices for each bank at specific iteration.", "code": "template< auto Banks, typename Address, auto Addresses   //< Number of addresses processed per call.\n>inline optional<index_t<Addresses>>[Banks] schedule_write_requests\n    ( optional<Address>[Addresses] addresses            //< Input addresses, valid duplicates __not__ allowed.\n    , (Address) -> index_t<Banks> address_to_bank_index //< Map `Address` to bank index.\n    , index_t<Addresses> iteration                      //< Index of bank requests to retrieve from schedule.\n    )\n{\n    return schedule_requests(addresses, address_to_bank_index, iteration);\n}"}
{"file": "data\\memory\\bank\\schedule.pd", "nl": "Validate all bank indices are less than Banks. In the case where Banks=1, index_t<Banks> is uint<1> and could have the value 1.", "code": "template <auto Banks, typename Address, auto Addresses>\ninline bool validate_bank_indices\n    ( optional<Address>[Addresses] addresses\n    , (Address) -> index_t<Banks> address_to_bank_index\n    ) {\n    return all\n        ( [address_to_bank_index](optional<Address> address)\n          {\n              return !address.is_valid || address_to_bank_index(address.value) < Banks;\n          }\n        , addresses\n        );\n}"}
{"file": "numeric\\fixed.pd", "nl": "Fixed-point representation.", "code": "template<auto I /*< Integer bit-width.*/, auto F /*< Fractional bit-width.*/>\nstruct fixed\n{\n    int<I + F> value;\n}"}
{"file": "numeric\\fixed.pd", "nl": "Internal function which conditionally performs a `checked_cast` on valid source values.", "code": "template<auto I, auto F>\ninline optional<fixed<I, F>> checked_cast_opt_fixed(auto src, bool is_valid)\n{\n    const auto fn = lift_optional(checked_cast<int<I + F>>);\n\n    auto opt_result = fn(make_optional(is_valid, src));\n\n    return make_optional(opt_result.is_valid, cast<fixed<I, F>>(opt_result.value));\n}"}
{"file": "numeric\\fixed.pd", "nl": "Round half up.", "code": "template<auto I, auto F>\ninline optional<fixed<I, F>> round(fixed<I, F> x)\n{\n    auto value = x.value;\n    optional<fixed<I, F>> result;\n\n    result.value.value = cast<decltype(result.value.value)>((((value >> (F-1)) + 1) >> 1) << F); // error checking below\n    result.is_valid = (value < 0) || (result.value.value >= 0);\n    return result;\n}"}
{"file": "numeric\\fixed.pd", "nl": "Ceiling.", "code": "template<auto I, auto F>\ninline optional<fixed<I, F>> ceil(fixed<I, F> x)\n{\n    auto value = x.value;\n    optional<fixed<I, F>> result;\n    int<I> integ = value >> F;\n    uint<F> frac = value;\n\n    result.value.value = cast<decltype(result.value.value)>((frac == 0 ? integ : integ + 1) << F); // error checking below\n    result.is_valid = (value < 0) || (result.value.value >= 0);\n    return result;\n}"}
{"file": "numeric\\fixed.pd", "nl": "Truncate.", "code": "template<auto I, auto F>\ninline fixed<I, F> trunc(fixed<I, F> x)\n{\n    const auto value = x.value;\n    const int<I> i = value >> F;\n    const uint<F> f = value;\n    return { (i + ((i < 0 && f > 0) ? 1 : 0)) << F };\n}"}
{"file": "numeric\\fixed.pd", "nl": "Return the absolute value of x.", "code": "template<auto I, auto F>\ninline optional<fixed<I, F>> abs(fixed<I, F> x)\n{\n    optional<fixed<I, F>> result;\n\n    result.value.value = cast<decltype(result.value.value)>(x.value < 0 ? -x.value : x.value);\n    result.is_valid = result.value.value >= 0;\n    return result;\n}"}
{"file": "numeric\\fixed.pd", "nl": "Return the smaller of x and y.", "code": "template<auto I, auto F>\ninline fixed<I, F> min(fixed<I, F> x, fixed<I, F> y)\n{\n    return y.value < x.value ? y : x;\n}"}
{"file": "numeric\\fixed.pd", "nl": "Return the larger of x and y.", "code": "template<auto I, auto F>\ninline fixed<I, F> max(fixed<I, F> x, fixed<I, F> y)\n{\n    return y.value > x.value ? y : x;\n}"}
{"file": "numeric\\fixed.pd", "nl": "Return the positive difference between x and y, i.e. `max(x - y, 0)`.", "code": "template<auto I, auto F>\ninline optional<fixed<I, F>> dim(fixed<I, F> x, fixed<I, F> y)\n{\n    optional<fixed<I, F>> result;\n\n    result.value.value = cast<decltype(result.value.value)>(y.value < x.value ? x.value - y.value : 0);\n    result.is_valid = result.value.value >= 0;\n    return result;\n}"}
{"file": "numeric\\fixed.pd", "nl": "Base-2 logarithm.", "code": "template<auto I, auto F>\ninline optional<fixed<I, F>> log2(fixed<I, F> x)\n{\n    return make_optional(x.value > 0, log2_calc(x));\n}"}
{"file": "numeric\\fixed.pd", "nl": "Base-10 logarithm.", "code": "template<auto I, auto F>\ninline optional<fixed<I, F>> log10(fixed<I, F> x)\n{\n    return make_optional(x.value > 0, logbase_calc<1262611>(x));\n}"}
{"file": "numeric\\fixed.pd", "nl": "Base-e logarithm.", "code": "template<auto I, auto F>\ninline optional<fixed<I, F>> log(fixed<I, F> x)\n{\n    return make_optional(x.value > 0, logbase_calc<2907270>(x));\n}"}
{"file": "numeric\\fixed.pd", "nl": "Convert from radian to pi-radian", "code": "template<auto I, auto F1, auto F2>\ninline int<I + F2> to_pirad(int<I + F1> value)\n{\n    // invPi = 1/Pi\n    const auto oriInvPiFbit = 41;\n    const auto oriInvPi = 0xa2f9836e4e;\n\n    const auto invPiFbit = I + F2;\n    const auto invPiShiftRight = oriInvPiFbit - I - F2;\n    static assert(invPiShiftRight > 0);\n    const uint<I + F2> invPi =  (oriInvPi >> invPiShiftRight) + ((oriInvPi >> (invPiShiftRight - 1)) & 1);\n\n    const auto resultTmpFbit = F1 + invPiFbit;\n    auto resultTmp = value * invPi;\n    int<I + F2> result = (resultTmp >> (resultTmpFbit - F2)) + ((resultTmp >> (resultTmpFbit - F2 - 1)) & 1);\n    return result;\n}"}
{"file": "numeric\\fixed.pd", "nl": "Base-2 exponent.", "code": "template<auto I, auto F>\ninline optional<fixed<I, F>> exp2(fixed<I, F> x)\n{\n    const auto value = x.value;\n\n    const int<I> exponent = value >> F;\n    const uint<F> fraction = value;\n\n    const auto fractionExp2Bit = I + F;\n    const uint<1 + fractionExp2Bit> fractionExp2 = exp2_lookup<F, fractionExp2Bit>(fraction);\n\n    return to_fixed<I, fractionExp2Bit, F>(exponent, fractionExp2);\n}"}
{"file": "numeric\\fixed.pd", "nl": "Base-e exponent.", "code": "template<auto I, auto F>\ninline optional<fixed<I, F>> exp(fixed<I, F> x)\n{\n    const auto value = x.value;\n\n    const auto log2eFbit = 38;\n    const auto log2e = 0x5C551D94AE;\n\n    static assert(F + log2eFbit > 19);\n    const auto expFbit = F + log2eFbit - 19;\n    const auto exp = (value * log2e) >> 19;\n\n    const int<I> exponent = exp >> expFbit;\n    const uint<expFbit> fraction = exp;\n\n    const auto fractionExpBit = I + F;\n    const uint<1 + fractionExpBit> fractionExp = exp2_lookup<expFbit, fractionExpBit>(fraction);\n\n    return to_fixed<I, fractionExpBit, F>(exponent, fractionExp);\n}"}
{"file": "numeric\\fixed.pd", "nl": "Return the reciprocal of the square root of x.", "code": "template<auto I, auto F>\ninline optional<fixed<I, F>> invsqrt(fixed<I, F> x)\n{\n    const auto value = x.value;\n    optional<fixed<I, F>> result;\n    result.is_valid = value > 0;\n\n    const auto leadingOneIndex = highest_one<uint<I + F>>(value);\n    int6 exponent = leadingOneIndex.value - F;\n    const auto significandFbit = I + F - 1;\n    const uint<I + F> significand = value << (I + F - 1 - leadingOneIndex.value);\n\n    // calculate 1/sqrt(x)\n    const auto invsqrtValueFbit = I / 2 + F + 1;\n    const uint<1 + invsqrtValueFbit> invsqrtValue = invsqrt_internal<significandFbit, invsqrtValueFbit>(exponent, significand);\n\n    const auto shiftedValueFbit = F + 1;\n    exponent = (exponent >> 1) + (exponent & 1);\n    sim_assert(invsqrtValueFbit - shiftedValueFbit + exponent >= 0);\n    const auto shiftedValue = invsqrtValue >> (invsqrtValueFbit - shiftedValueFbit + exponent);\n\n    result.value.value = (shiftedValue >> 1) + (shiftedValue & 1);\n    return result;\n}"}
{"file": "numeric\\fixed.pd", "nl": "Return the square root of x. This function provides better accuracy than calling `invsqrt` and then multiplying by x.", "code": "template<auto I, auto F>\ninline optional<fixed<I, F>> sqrt(fixed<I, F> x)\n{\n    const auto value = x.value;\n    optional<fixed<I, F>> result;\n    result.is_valid = value >= 0;\n\n    const auto leadingOneIndex = highest_one<uint<I + F>>(value);\n    int6 exponent = leadingOneIndex.value - F;\n    const auto significandFbit = I + F - 1;\n    const uint<I + F> significand = value << (I + F - 1 - leadingOneIndex.value);\n\n    // compute 1/sqrt(x)\n    const auto invsqrtValueFbit = I + F;\n    const uint<1 + invsqrtValueFbit> invsqrtValue = invsqrt_internal<significandFbit, invsqrtValueFbit>(exponent, significand);\n\n    // sqrt(x) = value * 1/sqrt(x)\n    const auto sqrtFbit = invsqrtValueFbit + F;\n    const auto sqrt = value * invsqrtValue;\n\n    const auto shiftedValueFbit = F + 1;\n    const auto halfExponent = (exponent >> 1) + (exponent & 1);\n    sim_assert(sqrtFbit - shiftedValueFbit + halfExponent >= 0);\n    const auto shiftedValue = sqrt >> (sqrtFbit - shiftedValueFbit + halfExponent);\n\n    result.value.value = (shiftedValue >> 1) + (shiftedValue & 1);\n    return result;\n}"}
{"file": "numeric\\fixed.pd", "nl": "Raise `base` to the power of `expo`.", "code": "template<auto I, auto F>\ninline optional<fixed<I, F>> pow(fixed<I, F> base, fixed<I, F> expo)\n{\n    const auto baseValue = base.value;\n    const auto expoValue = expo.value;\n    optional<fixed<I, F>> result;\n\n    // detect invalid input pattern\n    bool sign = baseValue < 0;\n    const uint<F> expoFraction = expoValue;\n    const bool isValid = !sign || (sign && expoFraction == 0);\n\n    // normalize base value\n    const auto baseAbsValue = sign ? -baseValue : baseValue;\n    const auto leadingOneIndex = highest_one<uint<I + F>>(baseAbsValue);\n    const int6 exponent = leadingOneIndex.value - F;\n\n    const auto significandFbit = I + F - 1;\n    const uint<1 + significandFbit> significand = (baseAbsValue << (I + F - 1 - leadingOneIndex.value));\n\n    // log2(base)\n    const auto log2Fbit = 55;\n    const auto log2Fraction = log2_40_lookup<significandFbit, (log2Fbit + 1)>(significand);\n    const auto roundLog2Frcation = (log2Fraction >> 1) + (log2Fraction & 1);\n    const int<6 + log2Fbit> log2Value = (exponent << log2Fbit) + roundLog2Frcation;\n\n    // expo * log2(base)\n    const auto productFbit = F + log2Fbit;\n    const auto product = log2Value * expoValue;\n    const int<6 + (I - 1)> productExponent = product >> productFbit;\n\n    const auto productFractionBit = 38;\n    const uint<productFractionBit + 1> productFraction = product >> (productFbit - (productFractionBit + 1));\n    const auto roundProductFraction = (productFraction >> 1) + (productFraction & 1);\n\n    const auto fractionExp2Bit = I + F + 1;\n    const auto fractionExp2 = exp2_lookup<productFractionBit, fractionExp2Bit>(roundProductFraction);\n\n    // convert to fixed point\n    const auto truncatedFbitCount = F + 1;\n    const auto shiftedValue = (fractionExp2 << truncatedFbitCount) >> (truncatedFbitCount - productExponent);\n    const auto truncatedValue = shiftedValue >> (fractionExp2Bit - truncatedFbitCount);\n\n    const uint<I + 1 + F> roundedValue = (truncatedValue >> 1) + (truncatedValue & 1);\n    const bool isExpoEvenInteger = ((expoValue >> F) & 1) == 0;\n    sign = isExpoEvenInteger ? false : sign;\n\n    const int<I + 2 + F> signedValue = sign ? -roundedValue : roundedValue;\n    result.value.value = signedValue;\n\n    const int<I + F> minValue = -(1 << (I + F - 1));\n    const int<I + F> maxValue = (1 << (I + F - 1)) - 1;\n    result.is_valid = (minValue <= signedValue) && (signedValue <= maxValue) && isValid;\n\n    return result;\n}"}
{"file": "numeric\\float32\\internal\\operator.pd", "nl": "Apply exponent bias and add mantissa implied one.", "code": "template<Denorm denorm_mode>\ninline float32ExpandedFormat unpackFloat32(float32PackedFormat a)\n{\n    float32ExpandedFormat a_PostUnpack;\n    a_PostUnpack.sign = a.sign;\n\n    if (denorm_mode == Denorm::Off)\n    {\n        a_PostUnpack.exponent = cast<int9>(a.exponent) - 127;\n        a_PostUnpack.mantissa = a.mantissa | 1 << 23;\n    }\n    else\n    {\n        a_PostUnpack.exponent = (a.exponent == 0) ? -126 : cast<int9>(a.exponent) - 127;\n        a_PostUnpack.mantissa = (a.exponent == 0) ? a.mantissa : a.mantissa | (1 << 23);\n    }\n\n    return a_PostUnpack;\n}"}
{"file": "numeric\\float32\\internal\\operator.pd", "nl": "Set denorm values to 0.", "code": "inline float32StickyFormat normalizeOutput2Zero(float32StickyFormat input)\n{\n    float32StickyFormat out;\n    out.sticky = 0;\n    out.mantissaGuardRound = 0;\n    out.exponent = -127;\n    out.sign = input.sign;\n\n    return(out);\n}"}
{"file": "numeric\\float32\\internal\\operator.pd", "nl": "Shift left to normalize small mantissa values. There is guaranteed to be a 1 in either the MSB or the second-most significant bit because mantissas are normalized before taking the product.", "code": "inline float32StickyFormat multNormalizeOutput1(float32StickyFormat in)\n{\n    float32StickyFormat out;\n\n    uint1 shiftAmount = ~cast<uint1>(in.mantissaGuardRound >> 25);\n\n    out.sticky = in.sticky;\n    out.mantissaGuardRound = in.mantissaGuardRound << shiftAmount;\n    out.exponent = in.exponent - shiftAmount;\n    out.sign = in.sign;\n\n    return(out);\n}"}
{"file": "numeric\\float32\\internal\\operator.pd", "nl": "Check if nan, zero, inf, or finite.", "code": "template<Denorm denorm_mode>\ninline specialCaseFlags getSpecialCases(float32PackedFormat a)\n{\n    return getSpecialCases_internal<_mantissa_width, _exponent_width, denorm_mode>(a);\n}"}
{"file": "numeric\\float32\\internal\\operator.pd", "nl": "Shift left to normalize small mantissa values. There is no guarantee the input isn't all zeros.", "code": "inline float32StickyFormat addNormalizeOutput1(float32StickyFormat in)\n{\n    float32StickyFormat out;\n\n    //The priority encoder will always find a shift amount between 0 and 26\n    //Thus, we can get into a few situations:\n    //  1) The exponent is already too small to shift at all (exp < -126).\n    //      Solution is to shift by 0.\n    //  2) The priority encoder finds a shift about that would make the exponent too small (exp - PE shift amount < -126).\n    //      Solution is to cap the shift amount to (exp + 126).\n    //  3) Otherwise, use the priority encoder shift amount.\n    uint5 priorityEncoderShiftAmount = priorityOneEncoderCountDown26(in.mantissaGuardRound);\n    uint5 leftShiftAmount = cast<uint5>(in.exponent - priorityEncoderShiftAmount < -126 ? in.exponent + 126 : priorityEncoderShiftAmount);\n    out.sticky = in.sticky;\n    out.mantissaGuardRound = in.mantissaGuardRound << leftShiftAmount;\n\n    //The priority encoder might have found a shift amount that was actually too small (maxes out at 26).\n    //If so, make the exponent -126.  The mantissa is already zeroed out, so there is nothing to fix.\n    out.exponent = priorityEncoderShiftAmount == 26 ? -126 : in.exponent - leftShiftAmount;\n    out.sign = in.sign;\n\n    return(out);\n}"}
{"file": "numeric\\float32\\internal\\operator.pd", "nl": "Multiply two float32 values with denorm off and return the float32 result.", "code": "inline float32 float32_mul_denormoff(float32 in1, float32 in2)\n{\n    // Unpack input\n    float32PackedFormat a;\n    float32PackedFormat b;\n    a = cast<float32PackedFormat> (in1);\n    b = cast<float32PackedFormat> (in2);\n    float32ExpandedFormat a_PostUnpack = unpackFloat32<Denorm::Off>(a);\n    float32ExpandedFormat b_PostUnpack = unpackFloat32<Denorm::Off>(b);\n\n    //Multiplication\n    float32StickyFormat z_postMultiply;\n    z_postMultiply.sign = a_PostUnpack.sign ^ b_PostUnpack.sign;\n    z_postMultiply.exponent = a_PostUnpack.exponent + b_PostUnpack.exponent + 1;\n\n    uint50 productTemp = cast<uint50>((a_PostUnpack.mantissa * b_PostUnpack.mantissa) << 2);\n    productFormat product;\n    product = cast<productFormat> (productTemp);\n\n    z_postMultiply.mantissaGuardRound = cast<uint26> (product.product << 2);\n    z_postMultiply.mantissaGuardRound |= product.guard << 1;\n    z_postMultiply.mantissaGuardRound |= product.round;\n    z_postMultiply.sticky = cast<uint1> (product.sticky != 0);\n\n    //Output Normalization\n    bool z_denorm = z_postMultiply.exponent < -126 ||\n                    (z_postMultiply.exponent == -126 && ((z_postMultiply.mantissaGuardRound >> 25) & 1) == 0);\n    float32StickyFormat z_postNormalize2 = z_denorm ? normalizeOutput2Zero(z_postMultiply) : multNormalizeOutput1(z_postMultiply);\n\n    //Rounding\n    float32ExpandedFormat z_postRounding;\n\n    bool guard = ((z_postNormalize2.mantissaGuardRound >> 1) & 1) == 1;\n    bool round = (z_postNormalize2.mantissaGuardRound & 1) == 1;\n    bool m0 = ((z_postNormalize2.mantissaGuardRound >> 2) & 1) == 1;\n    bool sticky = z_postNormalize2.sticky == 1;\n\n    bool roundUp = guard && (round || sticky || m0);\n    z_postRounding.mantissa = (z_postNormalize2.mantissaGuardRound >> 2) + cast<uint1>(roundUp);\n    uint1 exp_inc = roundUp && (z_postNormalize2.mantissaGuardRound >> 2 == 0xffffff) ? 1 : 0;\n    z_postRounding.exponent = z_postNormalize2.exponent + exp_inc;\n    z_postRounding.sign = z_postNormalize2.sign;\n\n    //Packing\n    float32PackedFormat zOutput;\n    //Handle special cases\n    specialCaseFlags a_flags = getSpecialCases<Denorm::Off>(a);\n    specialCaseFlags b_flags = getSpecialCases<Denorm::Off>(b);\n\n    bool specialCaseNaN = a_flags.nan || b_flags.nan || (a_flags.inf && b_flags.zero) || (a_flags.zero && b_flags.inf);\n    bool specialCaseZero = a_flags.zero || b_flags.zero;\n    bool specialCaseInf = (a_flags.inf && !b_flags.zero) || (!a_flags.zero && b_flags.inf);\n\n    zOutput.mantissa = specialCaseNaN ? 1 << 22 :\n                        (specialCaseZero || specialCaseInf || (z_postRounding.exponent > 127) ? 0 : z_postRounding.mantissa);\n    zOutput.exponent = (specialCaseNaN || specialCaseInf || (z_postRounding.exponent > 127)) ? 255 :\n                        (specialCaseZero) ? 0 :\n                        z_postRounding.exponent + 127;\n    zOutput.sign = z_postRounding.sign;\n\n    return cast<float32> (zOutput);\n}"}
{"file": "numeric\\float32\\internal\\operator.pd", "nl": "Add two float32 values with denorm off and return the float32 result.", "code": "inline float32 float32_add_denormoff(float32 in1, float32 in2)\n{\n    // Unpack input\n    float32PackedFormat a;\n    float32PackedFormat b;\n    a = cast<float32PackedFormat> (in1);\n    b = cast<float32PackedFormat> (in2);\n    float32ExpandedFormat a_PostUnpack = unpackFloat32<Denorm::Off>(a);\n    float32ExpandedFormat b_PostUnpack = unpackFloat32<Denorm::Off>(b);\n\n    float32StickyFormat a_PostAlign;\n    float32StickyFormat b_PostAlign;\n\n    uint8 alignShiftAmountA;\n    uint8 alignShiftAmountB;\n    if (a_PostUnpack.exponent > b_PostUnpack.exponent)\n    {\n        alignShiftAmountA = 0;\n        alignShiftAmountB = a_PostUnpack.exponent - b_PostUnpack.exponent;\n    }\n    else\n    {\n        alignShiftAmountA = b_PostUnpack.exponent - a_PostUnpack.exponent;\n        alignShiftAmountB = 0;\n    }\n    a_PostAlign = align(a_PostUnpack, alignShiftAmountA);\n    b_PostAlign = align(b_PostUnpack, alignShiftAmountB);\n\n    //Addition\n    float32StickyFormat z_postAdd;\n    uint27 aTemp = cast<uint27>(a_PostAlign.mantissaGuardRound << 1 | a_PostAlign.sticky);\n    uint27 bTemp = cast<uint27>(b_PostAlign.mantissaGuardRound << 1 | b_PostAlign.sticky);\n\n    uint28 sumTemp = cast<uint28>(a_PostAlign.sign == b_PostAlign.sign ? aTemp + bTemp :\n                        (aTemp >= bTemp ? aTemp - bTemp : bTemp - aTemp));\n    z_postAdd.sign =  a_PostAlign.sign == b_PostAlign.sign ? a_PostAlign.sign :\n                        (aTemp >= bTemp ? a_PostAlign.sign : b_PostAlign.sign);\n\n    bool shiftSum = sumTemp >> 27 == 1;\n    z_postAdd.exponent = a_PostAlign.exponent + cast<uint1>(shiftSum);\n    z_postAdd.mantissaGuardRound = shiftSum ? cast <uint26> (sumTemp >> 2) : cast <uint26> (sumTemp >> 1);\n    z_postAdd.sticky = shiftSum ? cast <uint1> (sumTemp >> 1) | cast <uint1> (sumTemp) : cast <uint1> (sumTemp);\n\n    // Shift left to normalize small mantissa values\n    float32StickyFormat z_postNormalize = addNormalizeOutput1(z_postAdd);\n\n    //Rounding\n    float32ExpandedFormat z_postRounding;\n\n    bool guard = ((z_postNormalize.mantissaGuardRound >> 1) & 1) == 1;\n    bool round = (z_postNormalize.mantissaGuardRound & 1) == 1;\n    bool m0 = ((z_postNormalize.mantissaGuardRound >> 2) & 1) == 1;\n    bool sticky = z_postNormalize.sticky == 1;\n\n    bool roundUp = guard && (round || sticky || m0);\n    z_postRounding.mantissa = cast<decltype(z_postRounding.mantissa)>((z_postNormalize.mantissaGuardRound >> 2) + cast<uint1>(roundUp));\n    uint1 exp_inc = roundUp && (z_postNormalize.mantissaGuardRound >> 2 == 0xffffff) ? 1 : 0;\n    z_postRounding.exponent = z_postNormalize.exponent + exp_inc;\n    z_postRounding.sign = z_postNormalize.sign;\n\n    //Packing\n    float32PackedFormat zOutput;\n\n    //Handle special cases\n    specialCaseFlags a_flags = getSpecialCases<Denorm::Off>(a);\n    specialCaseFlags b_flags = getSpecialCases<Denorm::Off>(b);\n    bool justAInf = a_flags.inf && !b_flags.inf;\n    bool justBInf = !a_flags.inf && b_flags.inf;\n    bool AandBInf = a_flags.inf && b_flags.inf;\n    bool specialCaseSignsEqual = a.sign == b.sign;\n\n    bool specialCaseNaN = a_flags.nan || b_flags.nan || (AandBInf && !specialCaseSignsEqual);\n    bool specialCaseZero = a_flags.zero && b_flags.zero;\n    bool specialCaseInf = justAInf || justBInf || (AandBInf && specialCaseSignsEqual);\n    //Careful that you check for specialCaseZero first!\n    bool specialCaseReturnA = b_flags.zero;\n    bool specialCaseReturnB = a_flags.zero;\n    uint1 specialCaseSign = justAInf ? a_PostUnpack.sign :\n                            justBInf ? b_PostUnpack.sign :\n                            a_PostUnpack.sign & b_PostUnpack.sign;\n\n    bool positiveZero = z_postRounding.exponent == -126 && z_postRounding.mantissa == 0;\n    bool zeroOut = z_postRounding.exponent == -126 && ((z_postRounding.mantissa >> 23) & 1) == 0;\n    bool overflow = z_postRounding.exponent > 127;\n\n    zOutput.mantissa = specialCaseNaN ? 1 << 22 :\n                       (specialCaseZero || specialCaseInf) ? 0 :\n                       specialCaseReturnA ? a.mantissa :\n                       specialCaseReturnB ? b.mantissa:\n                       (overflow || zeroOut) ? 0 :\n                       cast<decltype(zOutput.mantissa)>(z_postRounding.mantissa);\n    zOutput.exponent = (specialCaseNaN || specialCaseInf) ? 255 :\n                       specialCaseZero ? 0 :\n                       specialCaseReturnA ? a.exponent :\n                       specialCaseReturnB ? b.exponent :\n                       (positiveZero || zeroOut) ? 0 :\n                       overflow ? 255 :\n                       cast<decltype(zOutput.exponent)>(z_postRounding.exponent + 127);\n    zOutput.sign = (specialCaseInf || specialCaseZero) ? specialCaseSign :\n                   specialCaseReturnA ? a.sign :\n                   specialCaseReturnB ? b.sign :\n                   positiveZero ? 0 : z_postRounding.sign;\n\n    return cast<float32> (zOutput);\n}"}
{"file": "numeric\\float32\\internal\\operator.pd", "nl": "Negate input.", "code": "inline float32 neg(float32 x)\n{\n    float32PackedFormat binary = cast<float32PackedFormat>(x);\n    binary.sign = ~binary.sign;\n    return cast<float32>(binary);\n}"}
{"file": "numeric\\float32\\internal\\operator.pd", "nl": "Subtract `in2` from `in1`.", "code": "inline float32 float32_sub_denormoff(float32 in1, float32 in2)\n{\n    return float32_add_denormoff(in1, neg(in2));\n}"}
{"file": "processor\\risc_v\\isa.pd", "nl": "Sign-extend an integer to XLEN bits", "code": "template <auto N>\ninline int32 sign_extend(uint<N> x)\n{\n    return cast<int32>(cast<int<N>>(x));\n}"}
{"file": "processor\\risc_v\\isa.pd", "nl": "I-type instruction format", "code": "struct I_type {\n    Opcode  opcode;\n    Reg     rd;\n    Funct3  funct3;\n    Reg     rs1;\n    uint12  imm_11_0;\n}inline int32 I_immediate(I_type i)\n{\n    return sign_extend(i.imm_11_0);\n}"}
{"file": "processor\\risc_v\\isa.pd", "nl": "S-type instruction format", "code": "struct S_type\n{\n    Opcode  opcode;\n    uint5   imm_4_0;\n    Funct3  funct3;\n    Reg     rs1;]n    Reg     rs2;\n    uint7   imm_11_5;\n}inline int32 S_immediate(S_type s)\n{\n    return sign_extend(concat(s.imm_11_5, s.imm_4_0));\n}"}
{"file": "processor\\risc_v\\isa.pd", "nl": "B-type instruction format", "code": "struct B_type\n{\n    Opcode  opcode;\n    uint1   imm_11;\n    uint4   imm_4_1;\n    Funct3  funct3;\n    Reg     rs1;\n    Reg     rs2;\n    uint6   imm_10_5;\n    uint1   imm_12;\n}\ninline int32 B_immediate(B_type b)\n{\n    const uint1 zero_0 = 0;\n    return sign_extend(concat(b.imm_12, b.imm_11, b.imm_10_5, b.imm_4_1, zero_0));\n}"}
{"file": "processor\\risc_v\\isa.pd", "nl": "U-type instruction format", "code": "struct U_type {\n    Opcode  opcode;\n    Reg     rd;\n    uint20  imm_31_12;\n}inline int32 U_immediate(U_type u)\n{\n    const uint12 zero_11_0 = 0;\n    return sign_extend(concat(u.imm_31_12, zero_11_0));\n}"}
{"file": "processor\\risc_v\\isa.pd", "nl": "J-type instruction format", "code": "struct J_type {\n    Opcode  opcode;\n    Reg     rd;\n    uint8   imm_19_12;\n    uint1   imm_11;\n    uint10  imm_10_1;\n    uint1   imm_20; }\ninline int32 J_immediate(J_type j)\n{\n    const uint1 zero_0 = 0;\n    return sign_extend(concat(j.imm_20, j.imm_19_12, j.imm_11, j.imm_10_1, zero_0));\n}"}
{"file": "processor\\risc_v\\isa.pd", "nl": "Decode instruction word in given instruction format", "code": "template <Base ISA>\ninline auto decode_format\n    ( Instr instr   //< Instruction word\n    , Format format //< Instruction format\n    )\n{\n    Types<ISA>::Decoded decoded;\n\n    static assert(bitoffsetof(R_type, rd) == bitoffsetof(I_type, rd));\n    static assert(bitoffsetof(R_type, rd) == bitoffsetof(U_type, rd));\n    static assert(bitoffsetof(R_type, rd) == bitoffsetof(J_type, rd));\n\n    const bool rd_valid = format != Format::B && format != Format::S;\n    decoded.rd = make_optional(rd_valid && instr.r.rd != ABI::zero, cast<Types<ISA>::register_index_t>(instr.r.rd));\n\n    static assert(bitoffsetof(R_type, rs1) == bitoffsetof(I_type, rs1));\n    static assert(bitoffsetof(R_type, rs1) == bitoffsetof(S_type, rs1));\n    static assert(bitoffsetof(R_type, rs1) == bitoffsetof(B_type, rs1));\n\n    const bool rs1_valid = format == Format::R || format == Format::S || format == Format::B || format == Format::I;\n    decoded.rs1 = make_optional(rs1_valid, cast<Types<ISA>::register_index_t>(instr.r.rs1));\n\n    static assert(bitoffsetof(R_type, rs2) == bitoffsetof(S_type, rs2));\n    static assert(bitoffsetof(R_type, rs2) == bitoffsetof(B_type, rs2));\n\n    const bool rs2_valid = format == Format::R || format == Format::S || format == Format::B;\n    decoded.rs2 = make_optional(rs2_valid, cast<Types<ISA>::register_index_t>(instr.r.rs2));\n\n    const auto dont_care = I_immediate(instr.i);\n\n    decoded.imm = mux(format,\n            dont_care,\n            I_immediate(instr.i),\n            S_immediate(instr.s),\n            B_immediate(instr.b),\n            U_immediate(instr.u),\n            J_immediate(instr.j),\n            dont_care,\n            dont_care);\n\n    decoded.funct7 = instr.r.funct7;\n\n    return decoded;\n}"}
{"file": "numeric\\fft.pd", "nl": "Structure of numbers representing $sin(x)$ and $cos(x)$. // Used for the FFT's twiddle factor table.", "code": "template<typename NativeDataType> \nstruct sin_cos_t\n{\n    NativeDataType sin;\n    NativeDataType cos;\n}template<typename NativeDataType, auto MaxTwiddleFactors>\nclass processor\n{\nprivate:\n    using twiddle_addr_t = index_t<MaxTwiddleFactors>;\n    memory_norep<sin_cos_t<NativeDataType>, MaxTwiddleFactors> _twiddle_factors;\npublic:\n    inline sin_cos_t<NativeDataType> read_twiddle_factors(twiddle_addr_t read_address)\n    {\n        return (_twiddle_factors[read_address]);\n    }\n    inline void write_twiddle_factors(twiddle_addr_t write_address, sin_cos_t<NativeDataType> input_data)\n    {\n        _twiddle_factors[write_address] = input_data;\n    }}"}
{"file": "numeric\\fft.pd", "nl": "Set the size of FFT you would like to process, which must be a power of 2. // To assist the hardware, also provide `log2(FFT size)` and `log2(FFT size / 2 / NumProcs) - 1`. This function should be called once for a given FFT size. When using multiple threads, all threads need to use the same parameters. `fft_size_in` must be a power of 2, between `NumProcs * 16` and `MaxFFTSize`, inclusive.", "code": "void set_parameters(fft_size_t fft_size_in, fft_size_log2_addr_t fft_size_log2_in, num_iterations_per_processor_log2_addr_t num_iterations_per_processor_log2_minus1_in)\n    {\n        _fft_size = fft_size_in;\n        _fft_size_log2 = fft_size_log2_in;\n        _num_iterations_per_processor = fft_size_in >> 1 >> _num_proc_log2;\n        _num_iterations_per_processor_log2_minus1 = num_iterations_per_processor_log2_minus1_in;\n        _num_threads_launched = _fft_size_log2 * _num_iterations_per_processor;\n        _expected_input_transfers = (_fft_size / InputWordWidth) - 1;\n        _expected_output_transfers = (_fft_size / OutputWordWidth) - 1;\n\n        num_iterations_per_processor_log2_addr_t twiddle_factor_reuse_log2 = _fft_size_log2 - 1 - _num_proc_log2;\n        twiddle_addr_t twiddle_base_address = 0;\n\n        //The twiddle base address must accumulate over the stages, so it is computed via a loop here\n        for(const auto i : _fft_size_log2)\n        {\n            auto stage_num = _fft_size_log2 - i - 1;\n            \n            _twiddle_base_address_array[stage_num] = twiddle_base_address;\n\n            if(static(IoType == FftInputOutputType::NaturalInputReverseOutput))\n            {\n                twiddle_base_address += _num_iterations_per_processor >> ((stage_num <= _crossover_stage) ? 0 : stage_num - _crossover_stage);\n            }\n            else\n            {\n                fft_size_log2_addr_t level = _fft_size_log2 - 1 - stage_num;\n                twiddle_base_address += (level <= _crossover_stage) ? 1 : 1 << (level - _crossover_stage);\n            }\n        }\n        //Initialize the _completed_thread variable\n        for(const auto i : NumThreads)\n        {\n            _completed_thread[i] = -2;\n        }\n    }"}
{"file": "numeric\\fft.pd", "nl": "Load the twiddle factor array generated by `generate_addresses_and_twiddle_factors_*_input_*_output`. / This function should be called one set of times for each processor in the processing array for a given FFT size. When using multiple threads, all threads need to use the same twiddle factors.", "code": "inline void load_twiddle_factors(proc_addr_t processor_id, twiddle_addr_t address, sin_cos_t<NativeDataType> input_data)\n    {\n        static for (const auto i: NumProcs)\n        {\n            if(i == processor_id)\n            {\n                _processor_array[i].write_twiddle_factors(address, input_data);\n            }\n            barrier;\n        }\n    }"}
{"file": "numeric\\fft.pd", "nl": "Load the input data into the processor for a given thread at a word address  from 0 to `(number of FFT * size of FFT / InputWordWidth) - 1`.", "code": "inline void input_values(thread_addr_t thread_num, primary_input_addr_t address, complex <NativeDataType> [InputWordWidth] input_data){\n        sim_assert(thread_num < NumThreads);\n\n        const auto input_word_width_log2 = clog2(InputWordWidth);\n        //The processor number and the address are interleaved\n        //There 4 regions of bits:\n        // 1) the lowest _num_proc_log2-input_word_width_log2 bits\n        // 2) the next (_fft_size_log2 - 1 - _num_proc_log2) bits\n        // 3) the next 1 bit\n        // 4) the topmost bits\n        //The base processor number is concat(3, 1) << 2\n        // part1_mask works correctly (i.e. the topmost bits of input_id are removed) because we negate before shifting\n        auto part3_mask = NumProcs >> input_word_width_log2;\n        auto part1_mask = (NumProcs-1) >> input_word_width_log2;\n        auto base_processor_number = (((address >> (_fft_size_log2 - 1 - _num_proc_log2)) & part3_mask) | (address & part1_mask)) << input_word_width_log2;\n        //The address is concat(4, 2)\n        //part4_mask works correctly (i.e. the topmost bits of address are retained) because the cast for _fft_size\n        // makes the mask wide.\n        auto part4_mask = ~((cast<uint32>(_fft_size) >> (_num_proc_log2 + 1))-1);\n        auto part2_mask = ((_fft_size >> (_num_proc_log2 + 1))-1);\n        auto local_address = ((address >> (_num_proc_log2 - 1)) & part4_mask) | ((address >> (_num_proc_log2 - 2)) & part2_mask);\n\n        sim_assert(local_address < _mem_depth);\n\n        //Wait until there is no activity in this thread\n        wait_for(_completed_thread[thread_num] == -2);\n\n        static for (const auto k: NumThreads)\n        {\n            static for (const auto i: NumProcs * 2)\n            {\n                static for (const auto j: InputWordWidth)\n                {\n                    if(i == base_processor_number + j && k == thread_num)\n                    {\n                        _data_memory[k][i][cast<mem_addr_t>(local_address)] = input_data[j];\n                    }\n                    barrier;\n                }\n            }\n        }\n        atomic\n        {\n            if(_received_input_transfers[thread_num] == _expected_input_transfers)\n            {\n                _received_input_transfers[thread_num] = 0;\n                _completed_thread[thread_num] = -1;\n            }\n            else\n            {\n                _received_input_transfers[thread_num]++;\n            }\n        }\n    }"}
{"file": "numeric\\fft.pd", "nl": "Perform the FFT computation for a given thread.", "code": "void compute(thread_addr_t thread_num, FftDirection d){\n        _direction[thread_num] = d;\n        compute_slice_folded(_num_threads_launched + 2, thread_num);\n    }"}
{"file": "numeric\\fft.pd", "nl": "Send back the output data for a given thread at a word address", "code": "inline complex <NativeDataType> [OutputWordWidth] return_values(thread_addr_t thread_num, primary_output_addr_t address)\n    {\n        sim_assert(thread_num < NumThreads);\n\n        const auto output_word_width_log2 = clog2(OutputWordWidth);\n        complex <NativeDataType> [OutputWordWidth] temp;\n\n        //The processor number and the address are interleaved\n        //There 4 regions of bits:\n        // 1) the lowest _num_proc_log2-output_word_width_log2 bits\n        // 2) the next (_fft_size_log2 - 1 - _num_proc_log2) bits\n        // 3) the next 1 bit\n        // 4) the topmost bits\n        //The base processor number is concat(3, 1) << 2\n        // part1_mask works correctly (i.e. the topmost bits of input_id are removed) because we negate before shifting\n        auto part3_mask = NumProcs >> output_word_width_log2;\n        auto part1_mask = (NumProcs-1) >> output_word_width_log2;\n        auto base_processor_number = (((address >> (_fft_size_log2 - 1 - _num_proc_log2)) & part3_mask) | (address & part1_mask)) << output_word_width_log2;\n        //The address is concat(4, 2)\n        //part4_mask works correctly (i.e. the topmost bits of address are retained) because the cast for _fft_size\n        // makes the mask wide.\n        auto part4_mask = ~((cast<uint32>(_fft_size) >> (_num_proc_log2 + 1))-1);\n        auto part2_mask = ((_fft_size >> (_num_proc_log2 + 1))-1);\n        auto local_address = ((address >> (_num_proc_log2 - 1)) & part4_mask) | ((address >> (_num_proc_log2 - 2)) & part2_mask);\n\n        sim_assert(local_address < _mem_depth);\n\n        //Don't continue until the FFT has completed processing\n        wait_for(_completed_thread[thread_num] == (_num_threads_launched - 1));\n\n        static for (const auto k: NumThreads)\n        {\n            static for (const auto i: NumProcs * 2)\n            {\n                static for (const auto j: OutputWordWidth)\n                {\n                    if(i == base_processor_number + j && k == thread_num)\n                    {\n                        temp[j] =_data_memory[k][i][cast<mem_addr_t>(local_address)];\n                    }\n                    barrier;\n                }\n            }\n        }\n\n        atomic\n        {\n            if(_received_output_transfers[thread_num] == _expected_output_transfers)\n            {\n                _received_output_transfers[thread_num] = 0;\n                _completed_thread[thread_num] = -2;\n            }\n            else\n            {\n                _received_output_transfers[thread_num]++;\n            }\n        }\n\n        return temp;\n    }"}
{"file": "numeric\\decimal\\bid64.pd", "nl": "Check if NaN.", "code": "inline bool isnan(bid64_t x)\n{\n    const auto flags = getSpecialCases(x);\n    return flags.nan;\n}"}
{"file": "numeric\\decimal\\bid64.pd", "nl": "Check infinity.", "code": "inline bool isinf(bid64_t x)\n{\n    const auto flags = getSpecialCases(x);\n    return flags.inf;\n}"}
{"file": "numeric\\decimal\\bid64.pd", "nl": "Compare two `bid64_t` values for equality.", "code": "inline bool eq(bid64_t in1, bid64_t in2)\n{\n    return eq_internal<_width>(in1, in2);\n}"}
{"file": "numeric\\decimal\\bid64.pd", "nl": "Check `in1` greater than `in2`.", "code": "inline bool gt(bid64_t in1, bid64_t in2)\n{\n    return gt_internal<_width>(in1, in2);\n}"}
{"file": "numeric\\decimal\\bid64.pd", "nl": "Check `in1` less than `in2`.", "code": "inline bool lt(bid64_t in1, bid64_t in2)\n{\n    return lt_internal<_width>(in1, in2);\n}"}
{"file": "numeric\\decimal\\bid64.pd", "nl": "Negate input.", "code": "inline bid64_t neg(bid64_t x)\n{\n    auto binary = cast<decimal64PackedFormat_t>(x);\n    binary.sign = ~binary.sign;\n    return cast<bid64_t>(binary);\n}"}
{"file": "numeric\\decimal\\bid64.pd", "nl": "Add decimal64 numbers. If the result cannot be represented as decimal64 return invalid.", "code": "inline optional<bid64_t> add_exactly(bid64_t in1, bid64_t in2)\n{\n    const auto a = parseDecimalValue<_width>(in1);\n    const auto b = parseDecimalValue<_width>(in2);\n    const auto a_flags = getSpecialCases_internal<_width>(in1);\n    const auto b_flags = getSpecialCases_internal<_width>(in2);\n\n    optional<bid64_t> result;\n    if (a_flags.nan || b_flags.nan)\n    {\n        result.is_valid = true;\n        result.value = decimal64_constants::DEFAULT_NAN;\n    }\n    else if (a_flags.inf || b_flags.inf)\n    {\n        result.is_valid = true;\n        if(a_flags.inf && b_flags.inf)\n        {\n            result.value = (a.sign != b.sign) ? decimal64_constants::DEFAULT_NAN :\n                     (a.sign == 0) ? decimal64_constants::POS_INFINITY : decimal64_constants::NEG_INFINITY;\n        }\n        else\n        {\n            result.value = ((a.sign == 1 && !b_flags.inf) || (b.sign == 1 && !a_flags.inf)) ?\n                decimal64_constants::NEG_INFINITY : decimal64_constants::POS_INFINITY;\n        }\n    }\n    else if(a_flags.zero)\n    {\n        result.is_valid = true;\n        result.value = in2;\n    }\n    else if(b_flags.zero)\n    {\n        result.is_valid = true;\n        result.value = in1;\n    }\n    else\n    {\n        result = add_exactly_internal<_width, _max_integer>(a, b);\n    }\n    return result;\n}"}
{"file": "numeric\\decimal\\bid64.pd", "nl": "Subtract decimal64 numbers. If the result cannot be represented as decimal64 return invalid.", "code": "inline optional<bid64_t> sub_exactly(bid64_t in1, bid64_t in2)\n{\n    const auto a = parseDecimalValue<_width>(in1);\n    const auto b = parseDecimalValue<_width>(in2);\n    const auto a_flags = getSpecialCases_internal<_width>(in1);\n    const auto b_flags = getSpecialCases_internal<_width>(in2);\n\n    optional<bid64_t> result;\n    if (a_flags.nan || b_flags.nan)\n    {\n        result.is_valid = true;\n        result.value = decimal64_constants::DEFAULT_NAN;\n    }\n    else if (a_flags.inf || b_flags.inf)\n    {\n        result.is_valid = true;\n        if(a_flags.inf && b_flags.inf)\n        {\n            result.value = (a.sign == b.sign) ? decimal64_constants::DEFAULT_NAN :\n                     (a.sign == 0) ? decimal64_constants::POS_INFINITY : decimal64_constants::NEG_INFINITY;\n        }\n        else\n        {\n            result.value = ((a.sign == 1 && !b_flags.inf) || (b.sign == 0 && !a_flags.inf)) ?\n                decimal64_constants::NEG_INFINITY : decimal64_constants::POS_INFINITY;\n        }\n    }\n    else if(a_flags.zero)\n    {\n        result.is_valid = true;\n        result.value = neg(in2);\n    }\n    else if(b_flags.zero)\n    {\n        result.is_valid = true;\n        result.value = in1;\n    }\n    else\n    {\n        result = add_exactly_internal<_width, _max_integer>(a, {b.integer, b.exponent, ~b.sign});\n    }\n    return result;\n}"}
{"file": "numeric\\decimal\\bid64.pd", "nl": "Multiply decimal64 numbers. If the result cannot be represented as decimal64 return invalid.", "code": "inline optional<bid64_t> mul_exactly(bid64_t in1, bid64_t in2)\n{\n    const auto a = parseDecimalValue<_width>(in1);\n    const auto b = parseDecimalValue<_width>(in2);\n    const auto a_flags = getSpecialCases_internal<_width>(in1);\n    const auto b_flags = getSpecialCases_internal<_width>(in2);\n\n    optional<bid64_t> result;\n    if (a_flags.nan || b_flags.nan)\n    {\n        result.is_valid = true;\n        result.value = decimal64_constants::DEFAULT_NAN;\n    }\n    else if (a_flags.inf || b_flags.inf)\n    {\n        result.is_valid = true;\n        result.value = (a_flags.zero || b_flags.zero) ? decimal64_constants::DEFAULT_NAN :\n                       (a.sign != b.sign) ? decimal64_constants::NEG_INFINITY : decimal64_constants::POS_INFINITY;\n    }\n    else if(a_flags.zero || b_flags.zero)\n    {\n        result.is_valid = true;\n        result.value = 0;\n    }\n    else\n    {\n        result = mul_exactly_internal<_width, _max_integer, _bias>(a, b);\n    }\n    return result;\n}"}
{"file": "numeric\\decimal\\bid64.pd", "nl": "Calculate the quotient and remainder from dividing decimal64 numbers. The return value is an array with the first element being the quotient and the second element being the remainder. If the result cannot be represented as decimal64 return invalid.", "code": "inline optional<bid64_t[2]> div_exactly(bid64_t in1, bid64_t in2)\n{\n    const auto a = parseDecimalValue<_width>(in1);\n    const auto b = parseDecimalValue<_width>(in2);\n    const auto a_flags = getSpecialCases_internal<_width>(in1);\n    const auto b_flags = getSpecialCases_internal<_width>(in2);\n\n    bool isValid;\n    uint<_width> quotient;\n    uint<_width> remainder;\n    if (a_flags.nan || b_flags.nan)\n    {\n        isValid = true;\n        quotient = decimal64_constants::DEFAULT_NAN;\n        remainder = decimal64_constants::DEFAULT_NAN;\n    }\n    else if(a_flags.zero)\n    {\n        isValid = true;\n        quotient = 0;\n        remainder = 0;\n    }\n    else if (a_flags.inf || b_flags.inf || b_flags.zero)\n    {\n        isValid = true;\n        if(a_flags.inf && b_flags.inf)\n        {\n            quotient = decimal64_constants::DEFAULT_NAN;\n            remainder = decimal64_constants::DEFAULT_NAN;\n        }\n        else\n        {\n            const auto sign = a.sign ^ b.sign;\n            if(a_flags.inf || b_flags.zero)\n            {\n                quotient = (sign == 1) ? decimal64_constants::NEG_INFINITY : decimal64_constants::POS_INFINITY;\n                remainder = decimal64_constants::DEFAULT_NAN;\n            }\n            else\n            {\n                quotient = 0;\n                remainder = in1;\n            }\n        }\n    }\n    else\n    {\n        const auto div = div_exactly_internal<_width, _max_integer, _bias, UnrollingFactor>(a, b);\n        isValid = div.is_valid;\n        quotient = div.value[0];\n        remainder = div.value[1];\n    }\n\n    bid64_t[2] result;\n    result[0] = quotient;\n    result[1] = remainder;\n\n    return make_optional<bid64_t[2]>(isValid, result);\n}"}
{"file": "numeric\\decimal\\bid64.pd", "nl": "Return the absolute value of x.", "code": "inline bid64_t abs(bid64_t x)\n{\n    auto s = cast<decimal64PackedFormat_t>(x);\n    s.sign = 0;\n    return cast<bid64_t>(s);\n}"}
{"file": "numeric\\decimal\\bid64.pd", "nl": "Return the smaller of x and y. A qNaN value is treated as missing data,", "code": "inline bid64_t min(bid64_t x, bid64_t y)\n{\n    return min_internal<_width, decimal64_constants::DEFAULT_NAN>(x, y);\n}"}
{"file": "numeric\\decimal\\bid64.pd", "nl": "Return the larger of x and y. A qNaN value is treated as missing data,", "code": "inline bid64_t max(bid64_t x, bid64_t y)\n{\n    return max_internal<_width, decimal64_constants::DEFAULT_NAN>(x, y);\n}"}
{"file": "numeric\\decimal\\bid64.pd", "nl": "Return `max(x - y, 0)`. Return NaN if x or y is NaN.", "code": "inline optional<bid64_t> dim_exactly(bid64_t x, bid64_t y)\n{\n    return dim_exactly_internal<_width, _max_integer,\n                                decimal64_constants::POS_ZERO,\n                                decimal64_constants::DEFAULT_NAN,\n                                decimal64_constants::POS_INFINITY,\n                                decimal64_constants::NEG_INFINITY>(x, y);\n}"}
{"file": "numeric\\decimal\\bid32.pd", "nl": "Check not-a-number.", "code": "inline bool isnan(bid32_t x)\n{\n    const auto flags = getSpecialCases(x);\n    return flags.nan;\n}"}
{"file": "numeric\\decimal\\bid32.pd", "nl": "Check infinity.", "code": "inline bool isinf(bid32_t x)\n{\n    const auto flags = getSpecialCases(x);\n    return flags.inf;\n}"}
{"file": "numeric\\decimal\\bid32.pd", "nl": "Compare two `bid32_t` values for equality.", "code": "inline bool eq(bid32_t in1, bid32_t in2)\n{\n    return eq_internal<_width>(in1, in2);\n}"}
{"file": "numeric\\decimal\\bid32.pd", "nl": "Check `in1` greater than `in2`.", "code": "inline bool gt(bid32_t in1, bid32_t in2)\n{\n    return gt_internal<_width>(in1, in2);\n}"}
{"file": "numeric\\decimal\\bid32.pd", "nl": "Check `in1` less than `in2`.", "code": "inline bool lt(bid32_t in1, bid32_t in2)\n{\n    return lt_internal<_width>(in1, in2);\n}"}
{"file": "numeric\\decimal\\bid32.pd", "nl": "Negate input.", "code": "inline bid32_t neg(bid32_t x)\n{\n    auto binary = cast<decimal32PackedFormat_t>(x);\n    binary.sign = ~binary.sign;\n    return cast<bid32_t>(binary);\n}"}
{"file": "numeric\\decimal\\bid32.pd", "nl": "Add decimal32 numbers. If the result cannot be represented as decimal32 return invalid.", "code": "inline optional<bid32_t> add_exactly(bid32_t in1, bid32_t in2)\n{\n    const auto a = parseDecimalValue<_width>(in1);\n    const auto b = parseDecimalValue<_width>(in2);\n    const auto a_flags = getSpecialCases_internal<_width>(in1);\n    const auto b_flags = getSpecialCases_internal<_width>(in2);\n\n    optional<bid32_t> result;\n    if (a_flags.nan || b_flags.nan)\n    {\n        result.is_valid = true;\n        result.value = decimal32_constants::DEFAULT_NAN;\n    }\n    else if (a_flags.inf || b_flags.inf)\n    {\n        result.is_valid = true;\n        if(a_flags.inf && b_flags.inf)\n        {\n            result.value = (a.sign != b.sign) ? decimal32_constants::DEFAULT_NAN :\n                     (a.sign == 0) ? decimal32_constants::POS_INFINITY : decimal32_constants::NEG_INFINITY;\n        }\n        else\n        {\n            result.value = ((a.sign == 1 && !b_flags.inf) || (b.sign == 1 && !a_flags.inf)) ?\n                decimal32_constants::NEG_INFINITY : decimal32_constants::POS_INFINITY;\n        }\n    }\n    else if(a_flags.zero)\n    {\n        result.is_valid = true;\n        result.value = in2;\n    }\n    else if(b_flags.zero)\n    {\n        result.is_valid = true;\n        result.value = in1;\n    }\n    else\n    {\n        result = add_exactly_internal<_width, _max_integer>(a, b);\n    }\n    return result;\n}"}
{"file": "numeric\\decimal\\bid32.pd", "nl": "Subtract decimal32 numbers. If the result cannot be represented as decimal32 return invalid.", "code": "inline optional<bid32_t> sub_exactly(bid32_t in1, bid32_t in2)\n{\n    const auto a = parseDecimalValue<_width>(in1);\n    const auto b = parseDecimalValue<_width>(in2);\n    const auto a_flags = getSpecialCases_internal<_width>(in1);\n    const auto b_flags = getSpecialCases_internal<_width>(in2);\n\n    optional<bid32_t> result;\n    if (a_flags.nan || b_flags.nan)\n    {\n        result.is_valid = true;\n        result.value = decimal32_constants::DEFAULT_NAN;\n    }\n    else if (a_flags.inf || b_flags.inf)\n    {\n        result.is_valid = true;\n        if(a_flags.inf && b_flags.inf)\n        {\n            result.value = (a.sign == b.sign) ? decimal32_constants::DEFAULT_NAN :\n                     (a.sign == 0) ? decimal32_constants::POS_INFINITY : decimal32_constants::NEG_INFINITY;\n        }\n        else\n        {\n            result.value = ((a.sign == 1 && !b_flags.inf) || (b.sign == 0 && !a_flags.inf)) ?\n                decimal32_constants::NEG_INFINITY : decimal32_constants::POS_INFINITY;\n        }\n    }\n    else if(a_flags.zero)\n    {\n        result.is_valid = true;\n        result.value = neg(in2);\n    }\n    else if(b_flags.zero)\n    {\n        result.is_valid = true;\n        result.value = in1;\n    }\n    else\n    {\n        result = add_exactly_internal<_width, _max_integer>(a, {b.integer, b.exponent, ~b.sign});\n    }\n    return result;\n}"}
{"file": "numeric\\decimal\\bid32.pd", "nl": "Multiply decimal32 numbers. If the result cannot be represented as decimal32 return invalid.", "code": "inline optional<bid32_t> mul_exactly(bid32_t in1, bid32_t in2)\n{\n    const auto a = parseDecimalValue<_width>(in1);\n    const auto b = parseDecimalValue<_width>(in2);\n    const auto a_flags = getSpecialCases_internal<_width>(in1);\n    const auto b_flags = getSpecialCases_internal<_width>(in2);\n\n    optional<bid32_t> result;\n    if (a_flags.nan || b_flags.nan)\n    {\n        result.is_valid = true;\n        result.value = decimal32_constants::DEFAULT_NAN;\n    }\n    else if (a_flags.inf || b_flags.inf)\n    {\n        result.is_valid = true;\n        result.value = (a_flags.zero || b_flags.zero) ? decimal32_constants::DEFAULT_NAN :\n                       (a.sign != b.sign) ? decimal32_constants::NEG_INFINITY : decimal32_constants::POS_INFINITY;\n    }\n    else if(a_flags.zero || b_flags.zero)\n    {\n        result.is_valid = true;\n        result.value = 0;\n    }\n    else\n    {\n        result = mul_exactly_internal<_width, _max_integer, _bias>(a, b);\n    }\n    return result;\n}"}
{"file": "numeric\\decimal\\bid32.pd", "nl": "Calculate the quotient and remainder from dividing decimal32 numbers. The return value is an array with the first element being the quotient and the second element being the remainder. If the result cannot be represented as decimal32 return invalid.", "code": "template < auto UnrollingFactor //< Chunks of numerator bits of this size are processed in parallel,\n                                // meaning the outer loop only has to execute\n                                // `bitsizeof(uint<normalizedIntegerWidth>)/UnrollingFactor` iterations.\n                                // The `UnrollingFactor` value can be 1, 2, 4, 17, 34, or 68.\n         >\ninline optional<bid32_t[2]> div_exactly(bid32_t in1, bid32_t in2)\n{\n    const auto a = parseDecimalValue<_width>(in1);\n    const auto b = parseDecimalValue<_width>(in2);\n    const auto a_flags = getSpecialCases_internal<_width>(in1);\n    const auto b_flags = getSpecialCases_internal<_width>(in2);\n\n    bool isValid;\n    uint<_width> quotient;\n    uint<_width> remainder;\n    if (a_flags.nan || b_flags.nan)\n    {\n        isValid = true;\n        quotient = decimal32_constants::DEFAULT_NAN;\n        remainder = decimal32_constants::DEFAULT_NAN;\n    }\n    else if(a_flags.zero)\n    {\n        isValid = true;\n        quotient = 0;\n        remainder = 0;\n    }\n    else if (a_flags.inf || b_flags.inf || b_flags.zero)\n    {\n        isValid = true;\n        if(a_flags.inf && b_flags.inf)\n        {\n            quotient = decimal32_constants::DEFAULT_NAN;\n            remainder = decimal32_constants::DEFAULT_NAN;\n        }\n        else\n        {\n            const auto sign = a.sign ^ b.sign;\n            if(a_flags.inf || b_flags.zero)\n            {\n                quotient = (sign == 1) ? decimal32_constants::NEG_INFINITY : decimal32_constants::POS_INFINITY;\n                remainder = decimal32_constants::DEFAULT_NAN;\n            }\n            else\n            {\n                quotient = 0;\n                remainder = in1;\n            }\n        }\n    }\n    else\n    {\n        const auto div = div_exactly_internal<_width, _max_integer, _bias, UnrollingFactor>(a, b);\n        isValid = div.is_valid;\n        quotient = div.value[0];\n        remainder = div.value[1];\n    }\n\n    bid32_t[2] result;\n    result[0] = quotient;\n    result[1] = remainder;\n\n    return make_optional<bid32_t[2]>(isValid, result);\n}"}
{"file": "numeric\\decimal\\bid32.pd", "nl": "Return the absolute value of x.", "code": "inline bid32_t abs(bid32_t x)\n{\n    auto s = cast<decimal32PackedFormat_t>(x);\n    s.sign = 0;\n    return cast<bid32_t>(s);\n}"}
{"file": "numeric\\decimal\\bid32.pd", "nl": "Return the smaller of x and y. A qNaN value is treated as missing data, and the other value will be returned. The qNaN value will be returned in sNaN condition.", "code": "inline bid32_t min(bid32_t x, bid32_t y)\n{\n    return min_internal<_width, decimal32_constants::DEFAULT_NAN>(x, y);\n}"}
{"file": "numeric\\decimal\\bid32.pd", "nl": "Return the larger of x and y. A qNaN value is treated as missing data, and the other value will be returned. The qNaN result will be returned in sNaN condition.", "code": "inline bid32_t max(bid32_t x, bid32_t y)\n{\n    return max_internal<_width, decimal32_constants::DEFAULT_NAN>(x, y);\n}"}
{"file": "numeric\\decimal\\bid32.pd", "nl": "Return `max(x - y, 0)`. Return NaN if x or y is NaN.", "code": "inline optional<bid32_t> dim_exactly(bid32_t x, bid32_t y)\n{\n    return dim_exactly_internal<_width, _max_integer,\n                                decimal32_constants::POS_ZERO,\n                                decimal32_constants::DEFAULT_NAN,\n                                decimal32_constants::POS_INFINITY,\n                                decimal32_constants::NEG_INFINITY>(x, y);\n}"}
{"file": "numeric\\bfloat16.pd", "nl": "Addition.", "code": "template <Denorm denorm_mode>\ninline bfloat16 add(bfloat16 in1, bfloat16 in2)\n{\n    bfloat16 result;\n    if (denorm_mode == Denorm::On)\n    {\n        result = bfloat16_add(in1, in2);\n    }\n    else\n    {\n        result = bfloat16_add_denormoff(in1, in2);\n    }\n    return result;\n}"}
{"file": "numeric\\bfloat16.pd", "nl": "Multiplication.", "code": "template <Denorm denorm_mode>\ninline bfloat16 mul(bfloat16 in1, bfloat16 in2)\n{\n    bfloat16 result;\n    if (denorm_mode == Denorm::On)\n    {\n        result = bfloat16_mul(in1, in2);\n    }\n    else\n    {\n        result = bfloat16_mul_denormoff(in1, in2);\n    }\n    return result;\n}"}
{"file": "numeric\\bfloat16.pd", "nl": "Compare two `bfloat16` values for equality.", "code": "template <Denorm denorm_mode>\ninline bool eq(bfloat16 in1, bfloat16 in2)\n{\n    // Unpack input\n    bfloat16PackedFormat a = cast<bfloat16PackedFormat>(in1);\n    bfloat16PackedFormat b = cast<bfloat16PackedFormat>(in2);\n    // Get zero, nan, or inf\n    specialCaseFlags a_flags = getSpecialCases<denorm_mode>(a);\n    specialCaseFlags b_flags = getSpecialCases<denorm_mode>(b);\n\n    bool result;\n    // Negative and positive zero are equal\n    if (a_flags.zero && b_flags.zero)\n    {\n        result = true;\n    }\n    // NaNs are never equal\n    else if (a_flags.nan || b_flags.nan)\n    {\n        result = false;\n    }\n    else\n    {\n        result = in1 == in2;\n    }\n    return result;\n}"}
{"file": "numeric\\bfloat16.pd", "nl": "Check `in1` less than `in2`.", "code": "template <Denorm denorm_mode>\ninline bool lt(bfloat16 in1, bfloat16 in2)\n{\n    // Unpack input\n    bfloat16PackedFormat a;\n    bfloat16PackedFormat b;\n    a = cast<bfloat16PackedFormat>(in1);\n    b = cast<bfloat16PackedFormat>(in2);\n\n    // Get zero, nan, or inf\n    specialCaseFlags a_flags = getSpecialCases<denorm_mode>(a);\n    specialCaseFlags b_flags = getSpecialCases<denorm_mode>(b);\n\n    bool result;\n    if (a_flags.nan || b_flags.nan)\n    {\n        result = false;\n    }\n    else\n    {\n        int16 a_tc = a.sign != 0 ? -cast<int16>(in1 & 0x7FFF) : cast<int16>(in1);\n        int16 b_tc = b.sign != 0 ? -cast<int16>(in2 & 0x7FFF) : cast<int16>(in2);\n\n        result = a_tc < b_tc;\n    }\n\n    return result;\n}"}
{"file": "numeric\\bfloat16.pd", "nl": "Check `in1` greater than `in2`.", "code": "template <Denorm denorm_mode>\ninline bool gt(bfloat16 in1, bfloat16 in2)\n{\n    // Unpack input\n    bfloat16PackedFormat a;\n    bfloat16PackedFormat b;\n    a = cast<bfloat16PackedFormat>(in1);\n    b = cast<bfloat16PackedFormat>(in2);\n\n    // Get zero, nan, or inf\n    specialCaseFlags a_flags = getSpecialCases<denorm_mode>(a);\n    specialCaseFlags b_flags = getSpecialCases<denorm_mode>(b);\n\n    bool result;\n    if (a_flags.nan || b_flags.nan)\n    {\n        result = false;\n    }\n    else\n    {\n        int16 a_tc = a.sign != 0 ? -cast<int16>(in1 & 0x7FFF) : cast<int16>(in1);\n        int16 b_tc = b.sign != 0 ? -cast<int16>(in2 & 0x7FFF) : cast<int16>(in2);\n\n        result = a_tc > b_tc;\n    }\n\n    return result;\n}"}
{"file": "numeric\\bfloat16.pd", "nl": "Negate.", "code": "inline bfloat16 neg(bfloat16 x)\n{\n    bfloat16PackedFormat binary = cast<bfloat16PackedFormat>(x);\n    binary.sign = ~binary.sign;\n    return cast<bfloat16>(binary);\n}"}
{"file": "numeric\\bfloat16.pd", "nl": "Subtract `in2` from `in1`.", "code": "template <Denorm denorm_mode>\ninline bfloat16 sub(bfloat16 in1, bfloat16 in2)\n{\n    return add<denorm_mode>(in1, neg(in2));\n}"}
{"file": "numeric\\bfloat16.pd", "nl": "Convert a signed integer to a bfloat16", "code": "template <auto N /*< Signed integer width*/>\ninline bfloat16 from_int(int<N> value)\n{\n    return int_to_float<int<N>, bfloat16, _mantissa_width, _exponent_width, _exponent_bias>(value);\n}"}
{"file": "numeric\\bfloat16.pd", "nl": "Convert an unsigned integer to a float64", "code": "template <auto N /*< Unsigned integer width*/>\ninline bfloat16 from_uint(uint<N> value)\n{\n    return int_to_float<uint<N>, bfloat16, _mantissa_width, _exponent_width, _exponent_bias>(value);\n}"}
{"file": "numeric\\bfloat16.pd", "nl": "Convert a float64 to a signed integer", "code": "template <auto N /*< Signed integer width*/>\ninline optional<int<N>> to_int(bfloat16 value)\n{\n    auto result = float_to_int<bfloat16, int<N+1>, _mantissa_width, _exponent_width, _exponent_bias>(value);\n    if (result.is_valid)\n    {\n        auto limits = get_limits<int<N>>();\n        if ((result.value < limits.first) || (result.value > limits.second))\n            result.is_valid = false;\n    }\n\n    return make_optional<int<N>>(result.is_valid, cast<int<N>>(result.value));\n}"}
{"file": "numeric\\bfloat16.pd", "nl": "Convert a float64 to an unsigned integer", "code": "template <auto N /*< Unsigned integer width*/>\ninline optional<uint<N>> to_uint(bfloat16 value)\n{\n    auto result = float_to_int<bfloat16, uint<N+1>, _mantissa_width, _exponent_width, _exponent_bias>(value);\n    if (result.is_valid)\n    {\n        auto limits = get_limits<uint<N>>();\n        if ((result.value < limits.first) || (result.value > limits.second))\n            result.is_valid = false;\n    }\n\n    return make_optional<uint<N>>(result.is_valid, cast<uint<N>>(result.value));\n}"}
{"file": "numeric\\bfloat16.pd", "nl": "Convert a float32 to a bfloat16.", "code": "inline bfloat16 from_float32(float32 value)\n{\n    const auto float32_mantissa_width = 23;\n    const auto exponent_all_bits = cast<uint<_exponent_width>>(-1);\n    // bfloat16 and float32 have the same exponent width and bias\n\n    using float32PackedFormat = floatPackedFormat<float32_mantissa_width, _exponent_width>;\n\n    const auto float_packed = cast<float32PackedFormat>(value);\n\n    bfloat16PackedFormat bfloat16_packed;\n\n    bfloat16_packed.sign = float_packed.sign;\n\n    if (float_packed.exponent == 0 && float_packed.mantissa == 0)\n    {\n        // Zero is a bit special\n        bfloat16_packed.exponent = 0;\n        bfloat16_packed.mantissa = 0;\n    }\n    else if (float_packed.exponent == exponent_all_bits)\n    {\n        // Special values infinity and Nan\n        bfloat16_packed.exponent = exponent_all_bits;\n        bfloat16_packed.mantissa = float_packed.mantissa >> (float32_mantissa_width - _mantissa_width);\n    }\n    else\n    {\n        // Normal and sub-normal cases work out the same here because our exponent widths are the same.\n        // Truncate mantissa, but check truncated bits to see if we should round up the resultant mantissa\n\n        bfloat16_packed.exponent = float_packed.exponent;\n\n        uint<_mantissa_width+1> rounded_mantissa = float_packed.mantissa >> (float32_mantissa_width - _mantissa_width);\n        uint<float32_mantissa_width - _mantissa_width> truncated = cast<uint<float32_mantissa_width - _mantissa_width>>(float_packed.mantissa);\n\n        if\n        (\n            // The more than halfway case -> round up\n            (truncated > concat(1_u1, cast<uint<bitsizeof(truncated)-1>>(0)))\n\n            // The halfway case where rounding up would make lowest bit zero\n            ||  ((truncated == concat(1_u1, cast<uint<bitsizeof(truncated)-1>>(0))) && (cast<uint1>(rounded_mantissa) == 1))\n        )\n        {\n            rounded_mantissa += 1;\n        }\n\n        uint1 overflow = cast<uint1>(rounded_mantissa >> _mantissa_width);\n\n        // If round up overflowed into the high bit of expanded mantissa, then increase exponent by one.\n        bfloat16_packed.exponent =  (overflow == 0)  ? float_packed.exponent : (float_packed.exponent + 1);\n\n        // Take lower 7 bits of expanded 8-bit mantissa, discarding overflow bit, unless exponent overflowed to max value,\n        //   in which case we clear the mantissa so that it correctly reflects positive or negative infinity and not NaN\n        bfloat16_packed.mantissa = (bfloat16_packed.exponent == 0xFF) ? 0 : cast<uint<_mantissa_width>>(rounded_mantissa);\n    }\n\n    return cast<bfloat16>(bfloat16_packed);\n}"}
{"file": "numeric\\bfloat16.pd", "nl": "Convert a bfloat16 to a float32", "code": "inline float32 to_float32(bfloat16 value)\n{\n    const auto float32_mantissa_width = 23;\n    // bfloat16 and float32 have the same exponent width and bias\n\n    using float32PackedFormat = floatPackedFormat<float32_mantissa_width, _exponent_width>;\n    float32PackedFormat float_packed;\n\n    const auto bfloat16_packed = cast<bfloat16PackedFormat>(value);\n\n    float_packed.sign = bfloat16_packed.sign;\n    float_packed.exponent = bfloat16_packed.exponent;\n    float_packed.mantissa = bfloat16_packed.mantissa << (float32_mantissa_width - _mantissa_width);\n\n    return cast<float32>(float_packed);\n}"}
{"file": "numeric\\bfloat16.pd", "nl": "Check `x` is not a number.", "code": "inline bool isnan(bfloat16 x)\n{\n    const auto flags = getSpecialCases<Denorm::On>(cast<bfloat16PackedFormat>(x));\n    return flags.nan;\n}"}
{"file": "numeric\\bfloat16.pd", "nl": "Check `x` is positive or negative infinity.", "code": "inline bool isinf(bfloat16 x)\n{\n    const auto flags = getSpecialCases<Denorm::On>(cast<bfloat16PackedFormat>(x));\n    return flags.inf;\n}"}
{"file": "numeric\\bfloat16.pd", "nl": "Return sign of `x`.", "code": "inline bool signbit(bfloat16 x)\n{\n    const auto s = cast<bfloat16PackedFormat>(x);\n    return s.sign == 1;\n}"}
{"file": "numeric\\bfloat16.pd", "nl": "Return the smaller of `x` and `y`. A NaN is treated as missing data, and the other value will be returned.", "code": "template<Denorm denorm_mode>\ninline bfloat16 min(bfloat16 x, bfloat16 y)\n{\n    return (isnan(y) || lt<denorm_mode>(x, y)) ? x : y;\n}"}
{"file": "numeric\\bfloat16.pd", "nl": "Return the larger of `x` and `y`. A NaN is treated as missing data, and the other value will be returned.", "code": "template<Denorm denorm_mode>\ninline bfloat16 max(bfloat16 x, bfloat16 y)\n{\n    return (isnan(y) || gt<denorm_mode>(x, y)) ? x : y;\n}"}
{"file": "numeric\\bfloat16.pd", "nl": "Return the smallest integer not less than `x`.", "code": "template<Denorm denorm_mode>\ninline bfloat16 ceil(bfloat16 x)\n{\n    return ceil_internal<bfloat16, _mantissa_width, _exponent_width, _exponent_bias, denorm_mode>(x);\n}"}
{"file": "numeric\\bfloat16.pd", "nl": "Return the largest integer not greater than `x`.", "code": "template<Denorm denorm_mode>\ninline bfloat16 floor(bfloat16 x)\n{\n    return floor_internal<bfloat16, _mantissa_width, _exponent_width, _exponent_bias, denorm_mode>(x);\n}"}
{"file": "numeric\\bfloat16.pd", "nl": "Return the nearest integer to `x`, rounding halfway away from zero.", "code": "template<Denorm denorm_mode>\ninline bfloat16 round(bfloat16 x)\n{\n    return round_internal<bfloat16, _mantissa_width, _exponent_width, _exponent_bias, denorm_mode>(x);\n}"}
{"file": "numeric\\bfloat16.pd", "nl": "Return the nearest integer not greater in magnitude than `x`.", "code": "template<Denorm denorm_mode>\ninline bfloat16 trunc(bfloat16 x)\n{\n    return trunc_internal<bfloat16, _mantissa_width, _exponent_width, _exponent_bias, denorm_mode>(x);\n}"}
{"file": "numeric\\bfloat16.pd", "nl": "Return the positive difference between `x` and `y`, i.e. `max(x - y, 0)`.", "code": "template<Denorm denorm_mode>\ninline bfloat16 dim(bfloat16 x, bfloat16 y)\n{\n    bfloat16 result;\n\n    if (isnan(x) || isnan(y))\n    {\n        result = bfloat16_constants::DEFAULT_NAN;\n    }\n    else\n    {\n        result = gt<denorm_mode>(x, y) ? sub<denorm_mode>(x, y) : bfloat16_constants::POS_ZERO;\n    }\n\n    return result;\n}"}
{"file": "numeric\\bfloat16.pd", "nl": "Return the absolute value of `x`.", "code": "template<Denorm denorm_mode>\ninline bfloat16 abs(bfloat16 x)\n{\n    auto structValue = cast<bfloat16PackedFormat>(x);\n    structValue.sign = 0;\n    return cast<bfloat16>(structValue);\n}"}
{"file": "numeric\\bfloat16.pd", "nl": "Return 2 raised to the power of the input value.", "code": "inline bfloat16 exp2(bfloat16 val)\n{\n    const bfloat16PackedFormat in = cast<bfloat16PackedFormat>(val);\n\n    const uint13[2] C0 = {4098, 5794};   // Unsigned, fixed-point, f1.12\n    const uint10[2] C1 = {700, 990};     // Unsigned, fixed-point, f0.10\n    const uint7[2]  C2 = {73, 104};      // Unsigned, fixed-point, f0.8\n\n    uint16 denorm;\n    uint8 working_mantissa;\n\n    uint13 c0;\n    uint10 c1;\n    uint7 c2;\n\n    bool sign = in.sign != 0;\n\n    // Calculate constants and variable input to quadratic expression below\n    if ((in.exponent >= (127 + 7) && !sign) || (in.exponent > (127 + 7) && sign) || in.exponent < (127 - 8))\n    {\n        c0 = 0;\n        c1 = 0;\n        c2 = 0;\n        working_mantissa = 0;\n    }\n    else\n    {\n        // In here, in.exponent is guaranteed to be in [127-8, 127+7]\n        if (in.exponent >= (127 - 1))\n        {\n            // In here, in.exponent is guaranteed to be in [127-1, 127+7], so next line is left shift of [0, 8]\n            // uint8 << 8 => uint16\n            denorm = (cast<uint8>(in.mantissa) | 0x80) << (in.exponent - 127 + 1);\n        }\n        else\n        {\n            // In here, in.exponent is guaranteed to be in [127-8, 127-2], so next line is right shift of [1,7]\n            denorm = (cast<uint8>(in.mantissa) | 0x80) >> (127 - 1 - in.exponent);\n        }\n\n        if (sign)\n        {\n            working_mantissa = cast<uint8>(0 - cast<uint8>(denorm));\n        }\n        else\n        {\n            working_mantissa = cast<uint8>(denorm);\n        }\n\n        // Calculate index into look-up tables\n        uint1 index = working_mantissa >> 7;\n        c0 = C0[index];\n        c1 = C1[index];\n        c2 = C2[index];\n    }\n\n    bool bypass = false;\n    uint7 mantissa_bypass;\n\n    bfloat16PackedFormat r_val;\n    r_val.sign = 0;\n\n    // Check special cases\n    // (Might be able to save a few LUTs by skipping this call and checking for NaN directly)\n    auto flags = getSpecialCases<Denorm::Off>(in);\n\n    if (flags.nan)\n    {\n        // NaN -> NaN\n        bypass = true;\n        r_val.exponent = in.exponent;\n        mantissa_bypass = in.mantissa;\n        r_val.sign = in.sign;\n    }\n    else if ((in.exponent >= (127 + 7) && !sign) || ((in.exponent > (127 + 7) || (denorm >> 8) > 134) && sign))\n    {\n        // 2^(large_positive_number) -> infinity.\n        // 2^(large_negative_number) -> zero.\n        bypass = true;\n        mantissa_bypass = 0x00;\n        r_val.exponent = sign ? 0x00 : 0xFF;\n    }\n    else if (in.exponent < (127 - 8))\n    {\n        // 2^(small_number) -> 1.\n        bypass = true;\n        r_val.exponent = 127;\n        mantissa_bypass = 0x00;\n    }\n    else\n    {\n        uint8 integer_part = cast<uint8>(denorm >> 8);\n\n        if (sign)\n        {\n            bool denorm_lower8_nonzero = (cast<uint8>(denorm) != 0);\n\n            r_val.exponent = (denorm_lower8_nonzero ? 126 : 127) - integer_part;\n            if ( ((integer_part >= 126) && denorm_lower8_nonzero) || ((integer_part > 126) && !denorm_lower8_nonzero) )\n            {\n                bypass = true;\n                r_val.exponent = 0;\n                mantissa_bypass = 0;\n            }\n        }\n        else\n        {\n            r_val.exponent = 127 + integer_part;\n        }\n    }\n\n    // Calculate resultant mantissa using quadratic expression: c0 + c1*x + c2*x^2\n\n    uint7 x = cast<uint7>(working_mantissa);\n\n    uint15 constant_term = c0 << 2;\n\n    uint13 linear_term = (c1 * x) >> 4;\n\n    // Calculate quadratic term\n    uint8 x_squared = (x * x) >> 6;\n\n    uint11 quadratic_term = (c2 * x_squared) >> 4;\n\n    uint7 mantissa = (constant_term + linear_term + quadratic_term) >> 7;\n\n    r_val.mantissa = bypass ? mantissa_bypass : mantissa;\n\n    return cast<bfloat16>(r_val);\n}"}
{"file": "numeric\\bfloat16.pd", "nl": "Returns the reciprocal of the input value `1 / val`.", "code": "inline bfloat16 rcp(bfloat16 val)\n{\n    const bfloat16PackedFormat in = cast<bfloat16PackedFormat>(val);\n\n    const uint13[4] C0 = {8189, 6552, 5461, 4681};\n    const uint12[4]  C1 = {1999, 1289, 899, 662}; // C1 is actually (always) negative, but this is handled below in calculation of linear_term\n    const uint9[4]  C2 = {366, 199, 120, 77};\n\n    bool sign = in.sign != 0;\n\n    bfloat16PackedFormat r_val;\n    r_val.sign = in.sign;\n\n    // Get coefficients for quadratic calculation below\n\n    uint6 x;\n    uint13 c0;\n    uint12 c1;\n    uint9 c2;\n\n    auto flags = getSpecialCases<Denorm::Off>(in);\n\n    if (!(flags.zero || flags.nan))\n    {\n        uint2 index = in.mantissa >> 5;\n        x = (in.mantissa & 0x1F) << 1;\n\n        c0 = C0[index];\n        c1 = C1[index];\n        c2 = C2[index];\n    }\n\n    // Handle special cases and compute the exponent\n    bool bypass = in.mantissa == 0 || in.exponent >= 253;\n\n    uint7 mantissa_bypass = 0;\n\n    r_val.exponent = (in.exponent > 253 || (in.exponent == 253 && in.mantissa != 0)) ? 0 : ((in.mantissa == 0 ? 254 : 253) - in.exponent);\n\n    if (flags.zero)\n    {\n        r_val.exponent = 0xff;\n        mantissa_bypass = 0x00;\n        bypass          = true;\n    }\n    else if (flags.nan)\n    {\n        r_val.exponent = in.exponent;\n        mantissa_bypass = in.mantissa;\n        bypass          = true;\n    }\n    else if (flags.inf)\n    {\n        r_val.exponent      = 0x00;\n        mantissa_bypass = 0x00;\n        bypass          = true;\n    }\n\n    int15 constant_term = (c0 << 2);\n    int15 linear_term = -((c1 * x) >> 4);\n    uint6 x_squared = ((x * x) >> 6);\n    int15 quadratic_term = (c2 * x_squared) >> 4;\n\n    uint7 mantissa = (constant_term + linear_term + quadratic_term) >> 7;\n\n    r_val.mantissa = bypass ? mantissa_bypass : mantissa;\n\n    return cast<bfloat16>(r_val);\n}"}
{"file": "numeric\\bfloat16.pd", "nl": "Return the square-root of the input value.", "code": "inline bfloat16 sqrt(bfloat16 val)\n{\n    const bfloat16PackedFormat in = cast<bfloat16PackedFormat>(val);\n\n    const uint13[2] C0_odd  = {5794, 7094};\n    const uint10[2] C1_odd  = {716, 588};\n    const uint6[2]  C2_odd  = {33, 19}; // Negative values accounted for below in quadratic expression\n    const uint13 C0_even = 4099;\n    const uint10 C1_even = 495;\n    const uint6  C2_even = 18; // Negative values accounted for below in quadratic expression\n\n    bool sign = in.sign != 0;\n    bool even_coeff = cast<uint1>(in.exponent) == 1;\n    bool bypass = false;\n\n    uint7 mantissa_bypass;\n    uint8 x = in.mantissa << 1;\n\n    auto flags = getSpecialCases<Denorm::Off>(in);\n\n    uint13 c0;\n    uint10 c1;\n    uint6 c2;\n\n    if (flags.inf || flags.nan || flags.zero || (sign && !flags.zero))\n    {\n        c0 = 0;\n        c1 = 0;\n        c2 = 0;\n        x = 0;\n    }\n    else\n    {\n        if (even_coeff)\n        {\n            c0 = C0_even;\n            c1 = C1_even;\n            c2 = C2_even;\n\n            x &= 0xff;\n        }\n        else\n        {\n            const uint1 index = cast<uint1>(x >> 7);\n\n            c0 = C0_odd[index];\n            c1 = C1_odd[index];\n            c2 = C2_odd[index];\n\n            x &= 0x7f;\n        }\n    }\n\n    bfloat16PackedFormat r_val;\n\n    // Compute _exp on the side and special cases that must be bypassed\n    if (sign && !flags.zero)\n    {\n        // NaN for negative numbers\n        bypass          = true;\n        mantissa_bypass = 0x7f;\n        r_val.exponent  = 0xff;\n    }\n    else if (flags.inf || flags.nan)\n    {\n        // Propagate these through\n        bypass          = true;\n        mantissa_bypass = in.mantissa;\n        r_val.exponent  = in.exponent;\n    }\n    else if (flags.zero)\n    {\n        bypass          = true;\n        mantissa_bypass = 0;\n        r_val.exponent  = 0;\n    }\n    else\n    {\n        if (even_coeff)\n        {\n            r_val.exponent = in.exponent / 2 - 63 + 127;\n        }\n        else\n        {\n            r_val.exponent = in.exponent / 2 - 64 + 127;\n        }\n    }\n\n    // Quadratic approximation\n    uint15 constant_term = c0 << 2;\n    uint14 linear_term = (c1 * x) >> 4;\n    uint10 x_squared = ((x * x) >> 6);\n    uint12 quadratic_term = (c2 * x_squared) >> 4;\n    uint7 mantissa = (constant_term + linear_term - quadratic_term) >> 7;\n\n    r_val.mantissa = bypass ? mantissa_bypass : mantissa;\n    r_val.sign = in.sign;\n\n    return cast<bfloat16>(r_val);\n}"}
{"file": "numeric\\bfloat16.pd", "nl": "Base 2 logarithm.", "code": "inline bfloat16 log2(bfloat16 val)\n{\n    const bfloat16PackedFormat in = cast<bfloat16PackedFormat>(val);\n    const bool sign = in.sign != 0;\n\n    const uint13[4] C0_nonzero = {0, 1319, 2396, 3307};\n    const int12[4]  C1_nonzero = {1464, 1175, 980, 841};\n    const int9[4]   C2_nonzero = {-147, -98, -69, -52};\n    const uint13[2] C0_zero    = {5907, 4791};\n    const int12[2]  C1_zero    = {-709, -416};\n    const int9[2]   C2_zero    = {76, 34};\n\n    uint13 c0;\n    int12  c1;\n    int9   c2;\n    bool bypass = false;\n    bool zero_postprocess = false;\n    uint8 integer_part = 0;\n    uint7 mantissa_bypass = 0;\n    uint7 x = 0;\n\n    bfloat16PackedFormat r_val;\n    r_val.sign = 0;\n\n    auto flags = getSpecialCases<Denorm::Off>(in);\n\n    if (flags.zero)\n    {\n        // log2(0) = -inf\n        r_val.sign      = 1;\n        bypass          = true;\n        integer_part    = 0xff;\n        mantissa_bypass = 0;\n    }\n    else if (sign)\n    {\n        // log2(-x) = NaN\n        r_val.sign = in.sign;\n        bypass = true;\n        integer_part = 0xff;\n        mantissa_bypass = 0x7f;\n    }\n    else if (flags.inf || flags.nan)\n    {\n        // propagate infinity and NaNs through\n        r_val.sign = in.sign;\n        bypass = true;\n        integer_part = in.exponent;\n        mantissa_bypass = in.mantissa;\n    }\n    else\n    {\n        if (in.exponent >= 127)\n        {\n            integer_part = in.exponent - 127;\n            r_val.sign = 0;\n        }\n        else\n        {\n            integer_part = 127 - in.exponent;\n            r_val.sign = 1;\n        }\n\n        if (in.exponent == 127)\n        {\n            const uint1 index = cast<uint1>(in.mantissa >> 6);\n            c0 = C0_zero[index];\n            c1 = C1_zero[index];\n            c2 = C2_zero[index];\n            x = (in.mantissa & 0x3f) << 1;\n            zero_postprocess = true;\n        }\n        else\n        {\n            const uint2 index = cast<uint2>(in.mantissa >> 5);\n            c0 = C0_nonzero[index];\n            c1 = C1_nonzero[index];\n            c2 = C2_nonzero[index];\n            x = (in.mantissa & 0x1f) << 1;\n        }\n    }\n\n    // Quadratic approximation\n    uint15 accum = c0 << 2;\n\n    uint15 linear_term = ((c1 < 0 ? -c1 : c1) * x) >> 4;\n    accum = (c1 < 0) ? (accum - linear_term) : (accum + linear_term);\n\n    uint10 x_squared_shifted = ((x * x) >> 6);\n    uint15 quadratic_term = ((c2 < 0 ? -c2 : c2) * x_squared_shifted) >> 4;\n\n    accum = (c2 < 0) ? (accum - quadratic_term) : (accum + quadratic_term);\n\n    if (bypass)\n    {\n        r_val.mantissa = mantissa_bypass;\n        r_val.exponent = cast<uint8>(integer_part);\n    }\n    else\n    {\n        uint22 res = 0;\n\n        if (zero_postprocess)\n        {\n            res = (cast<uint9>((accum | 0x4000) >> 6) * in.mantissa) >> 1;\n        }\n        else\n        {\n            if (r_val.sign != 0)\n            {\n                res = (integer_part << 14) - accum;\n            }\n            else\n            {\n                res = (integer_part << 14) + accum;\n            }\n        }\n\n        int8 exp = 0;\n\n        if (res != 0)\n        {\n            auto ho_upper = highest_one(cast<uint8>(res >> 14));\n\n            if (ho_upper.is_valid)\n            {\n                auto rhs = ho_upper.value;\n                exp += rhs;\n                res = res >> rhs;\n            }\n            else\n            {\n                auto ho_lower = highest_one(cast<uint14>(res));\n                if (ho_lower.is_valid)\n                {\n                    uint4 lhs = 14 - ho_lower.value;\n\n                    exp -= lhs;\n                    res = res << lhs;\n                }\n            }\n\n            r_val.mantissa = cast<uint7>(res >> 7);\n            r_val.exponent = 127 + exp;\n        }\n        else\n        {\n            r_val.mantissa = 0;\n            r_val.exponent = 0;\n        }\n    }\n\n    return cast<bfloat16>(r_val);\n}"}
{"file": "numeric\\bfloat16.pd", "nl": "Inverse square-root.", "code": "inline bfloat16 invsqrt(bfloat16 val)\n{\n    const bfloat16PackedFormat in = cast<bfloat16PackedFormat>(val);\n\n    const uint14[4] C0_evenexp = { 8191, 7327, 6689, 6192 };\n    const uint10[4] C1_evenexp = { 1008, 725, 553, 439 }; // Actual C1 coefficients are negative - handled in quadratic calculation below\n    const uint8[4]  C2_evenexp = { 145, 87, 57, 39 };\n\n    const uint13[4] C0_oddexp = { 5792, 5181, 4730, 4379 };\n    const uint10[4] C1_oddexp = { 712, 512, 391, 311 };  // Actual C1 coefficients are negative - handled in quadratic calculation below\n    const uint7[4]  C2_oddexp = { 101, 61, 40, 28 };\n\n    bool sign = in.sign != 0;\n    bool even_exp = cast<uint1>(in.exponent) == 1; // Even because after you subtract the bias (127) it will be an even number\n\n    uint14 c0;\n    uint10 c1;\n    uint8 c2;\n    uint6 x;\n\n    auto flags = getSpecialCases<Denorm::Off>(in);\n\n    if (!(flags.zero || flags.nan || sign))\n    {\n        uint2 index = in.mantissa >> 5;\n        x = (in.mantissa & 0x1F) << 1;\n\n        if (even_exp)\n        {\n            c0 = C0_evenexp[index];\n            c1 = C1_evenexp[index];\n            c2 = C2_evenexp[index];\n        }\n        else\n        {\n            c0 = C0_oddexp[index];\n            c1 = C1_oddexp[index];\n            c2 = C2_oddexp[index];\n        }\n    }\n\n    bfloat16PackedFormat r_val;\n    r_val.sign = 0;\n    uint7 mantissa_bypass;\n    bool bypass = false;\n\n    // Compute _exp on the side and special cases that must be bypassed\n    if (flags.zero)\n    {\n        // 0 -> +Inf\n        bypass = true;\n        mantissa_bypass = 0;\n        r_val.exponent = 0xff;\n    }\n    else if (sign)\n    {\n        // Negative, non-zero input -> NaN\n        bypass          = true;\n        mantissa_bypass = 0x7f;\n        r_val.exponent  = 0xff;\n    }\n    else if (flags.inf)\n    {\n        // Positive, infinite input -> zero\n        bypass          = true;\n        mantissa_bypass = 0;\n        r_val.exponent  = 0;\n    }\n    else if (flags.nan)\n    {\n        // NaN -> NaN\n        bypass          = true;\n        mantissa_bypass = in.mantissa;\n        r_val.exponent  = in.exponent;\n    }\n    else\n    {\n        if (even_exp)\n        {\n            // Result exponent is -E/2 - 1\n            r_val.exponent = 127 - in.exponent/2 + 62;\n        }\n        else\n        {\n            // Result exponent is -(E+1)/2\n            r_val.exponent = 127 - in.exponent/2 + 63;\n        }\n    }\n\n    // Quadratic approximation\n    uint16 constant_term = c0 << 2;\n    uint12 linear_term = (c1 * x) >> 4;\n    uint6 x_squared = ((x * x) >> 6);\n    uint10 quadratic_term = (c2 * x_squared) >> 4;\n    uint7 mantissa = (constant_term - linear_term + quadratic_term) >> 7;\n\n    r_val.mantissa = bypass ? mantissa_bypass : mantissa;\n\n    return cast<bfloat16>(r_val);\n}"}
{"file": "numeric\\bfloat16.pd", "nl": "Hyperbolic tangent.", "code": "inline bfloat16 tanh(bfloat16 val)\n{\n    const bfloat16PackedFormat in = cast<bfloat16PackedFormat>(val);\n\n    const uint12[1] C0_120 = {4095};\n    const uint11[1] C1_120 = {1024};\n    const uint1 [1] C2_120 = {0}; // Actual values negative or zero - handled in quadratic calculation below\n    const uint13[2] C0_121 = {4095, 6143};\n    const uint11[2] C1_121 = {1024, 1023};\n    const uint1 [2] C2_121 = {0, 0}; // Actual values negative or zero - handled in quadratic calculation below\n    const uint13[2] C0_122 = {4094, 6138};\n    const uint10[2] C1_122 = {1023, 1022};\n    const uint1 [2] C2_122 = {0, 0}; // Actual values negative or zero - handled in quadratic calculation below\n    const uint13[2] C0_123 = {4090, 6125};\n    const uint10[2] C1_123 = {1020, 1015};\n    const uint1 [2] C2_123 = {1, 1}; // Actual values negative or zero - handled in quadratic calculation below\n    const uint13[2] C0_124 = {4073, 6072};\n    const uint10[2] C1_124 = {1009, 989};\n    const uint3 [2] C2_124 = {4, 6}; // Actual values negative or zero - handled in quadratic calculation below\n    const uint13[2] C0_125 = {4012, 5869};\n    const uint10[2] C1_125 = {964, 894};\n    const uint5 [2] C2_125 = {17, 21}; // Actual values negative or zero - handled in quadratic calculation below\n    const uint13[4] C0_126 = {3785, 4543, 5203, 5766};\n    const uint10[4] C1_126 = {806, 709, 610, 516};\n    const uint6 [4] C2_126 = {48, 49, 46, 43}; // Actual values negative or zero - handled in quadratic calculation below\n    const uint12[8] C0_127 = {3119, 3315, 3474, 3604, 3707, 3790, 3856, 3908};\n    const uint9 [8] C1_127 = {429, 352, 286, 230, 184, 146, 116, 91};\n    const uint7 [8] C2_127 = {76, 65, 55, 45, 37, 29, 24, 18}; // Actual values negative or zero - handled in quadratic calculation below\n    const uint12[4] C0_128 = {3949, 4041, 4076, 4088};\n    const uint8 [4] C1_128 = {136, 51, 18, 6};\n    const uint6 [4] C2_128 = {44, 16, 5, 1}; // Actual values negative or zero - handled in quadratic calculation below\n    const uint13[2] C0_129 = {4092, 4096};\n    const uint2 [2] C1_129 = {3, 0};\n    const uint1 [2] C2_129 = {0, 0}; // Actual values negative or zero - handled in quadratic calculation below\n\n    uint13 c0;\n    uint11 c1;\n    uint7 c2;\n    uint8 x;\n\n    uint7 mantissa_bypass = 0;\n    uint8 exponent_bypass = 0;\n    bool bypass = false;\n\n    // Preprocessing, bypass if the number is too small or too large\n    auto flags = getSpecialCases<Denorm::Off>(in);\n\n    if (flags.nan)\n    {\n        bypass = true;\n        exponent_bypass = in.exponent;\n        mantissa_bypass = in.mantissa;\n    }\n    else if (in.exponent < 120)\n    {\n        bypass = true;\n        exponent_bypass = in.exponent;\n        mantissa_bypass = in.mantissa;\n    }\n    else if (in.exponent > 129)\n    {\n        bypass = true;\n        exponent_bypass = 127;\n        mantissa_bypass = 0;\n    }\n    else\n    {\n        uint1 idx1 = cast<uint1>(in.mantissa >> 6);\n        uint2 idx2 = cast<uint2>(in.mantissa >> 5);\n        uint3 idx3 = cast<uint3>(in.mantissa >> 4);\n\n        switch(in.exponent)\n        {\n        case 120:\n            c0 = C0_120[0];\n            c1 = C1_120[0];\n            c2 = C2_120[0];\n            x = in.mantissa << 1;\n            exponent_bypass = in.exponent;\n            break;\n        case 121:\n            c0 = C0_121[idx1];\n            c1 = C1_121[idx1];\n            c2 = C2_121[idx1];\n            x = (in.mantissa & 0x3f) << 1;\n            exponent_bypass = in.exponent;\n            break;\n        case 122:\n            c0 = C0_122[idx1];\n            c1 = C1_122[idx1];\n            c2 = C2_122[idx1];\n            x = (in.mantissa & 0x3f) << 1;\n            exponent_bypass = in.exponent;\n            break;\n        case 123:\n            c0 = C0_123[idx1];\n            c1 = C1_123[idx1];\n            c2 = C2_123[idx1];\n            x = (in.mantissa & 0x3f) << 1;\n            exponent_bypass = in.exponent;\n            break;\n        case 124:\n            c0 = C0_124[idx1];\n            c1 = C1_124[idx1];\n            c2 = C2_124[idx1];\n            x = (in.mantissa & 0x3f) << 1;\n            exponent_bypass = in.exponent;\n            break;\n        case 125:\n            c0 = C0_125[idx1];\n            c1 = C1_125[idx1];\n            c2 = C2_125[idx1];\n            x = (in.mantissa & 0x3f) << 1;\n            exponent_bypass = in.exponent;\n            break;\n        case 126:\n            c0 = C0_126[idx2];\n            c1 = C1_126[idx2];\n            c2 = C2_126[idx2];\n            x = (in.mantissa & 0x1f) << 1;\n            exponent_bypass = in.exponent;\n            break;\n        case 127:\n            c0 = C0_127[idx3];\n            c1 = C1_127[idx3];\n            c2 = C2_127[idx3];\n            x = (in.mantissa & 0x0f) << 1;\n            exponent_bypass = in.exponent;\n            break;\n        case 128:\n            c0 = C0_128[idx2];\n            c1 = C1_128[idx2];\n            c2 = C2_128[idx2];\n            x = (in.mantissa & 0x1f) << 1;\n            exponent_bypass = 127;\n            break;\n        case 129:\n            c0 = C0_129[idx1];\n            c1 = C1_129[idx1];\n            c2 = C2_129[idx1];\n            x = (in.mantissa & 0x3f) << 1;\n            exponent_bypass = 127;\n            break;\n        default:\n            sim_assert(false);    // Control should never reach here\n            break;\n        }\n    }\n\n    // Quadratic approximation\n    uint15 constant_term = c0 << 2;\n    uint15 linear_term = (c1 * x) >> 4;\n    uint10 x_squared = ((x * x) >> 6);\n    uint13 quadratic_term = (c2 * x_squared) >> 4;\n    uint8 accum = (constant_term + linear_term - quadratic_term) >> 7;\n\n    bfloat16PackedFormat r_val;\n    r_val.sign = in.sign;\n\n    if (bypass)\n    {\n        r_val.exponent = exponent_bypass;\n        r_val.mantissa = mantissa_bypass;\n    }\n    else\n    {\n        if (cast<uint1>(accum >> 7) != 0)\n        {\n            r_val.exponent = exponent_bypass;\n            r_val.mantissa = cast<uint7>(accum);\n        }\n        else\n        {\n            r_val.exponent = exponent_bypass - 1;\n            r_val.mantissa = cast<uint7>(accum << 1);\n        }\n    }\n\n    return cast<bfloat16>(r_val);\n}"}
{"file": "data\\buffer\\pipelined.pd", "nl": "Pass a variable between consecutive threads X and X+1.", "code": "template<typename T /*< Variable type.*/>\nclass pipelined_variable\n{\npublic:\npublic://| Feed in a new value and push the old value down. This should typically be called exactly once per thread.\n    inline T next(T input) {\n        return first(atomically([input](T x){return input;}));\n    }\n}"}
{"file": "data\\buffer\\pipelined.pd", "nl": "Pass a variable between N consecutive threads X to X + N.", "code": "template<typename T /*< Variable type.*/, auto N /*< Number of threads.*/>\nclass pipelined_variable_array\n{\npublic:    //| Feed in a new value and push the old values down. This should typically be called exactly once per thread.\n    inline T[N] next(T input) {\n        T[N] previous_values;\n        atomic {\n            static T [N] _previous_val;\n            static for (const auto i: N)\n            {\n                previous_values[i] = _previous_val[i];\n                if(i == 0) {\n                    _previous_val[i] = input;\n                }\n                else\n                {\n                    _previous_val[i] = previous_values[i - 1];\n                }\n            }\n        }\n        return(previous_values);\n    }\n}"}
{"file": "data\\memory\\unaligned.pd", "nl": "Read a word from a word aligned address", "code": "inline word_t read_aligned(addr_t addr)\n    {\n        sim_assert((addr & (WordSize - 1)) == 0);\n\n        word_t value;\n\n        static for(const auto i : WordSize)\n        {\n            value[i] = mem[i][addr / WordSize];\n        }\n\n        return value;\n    }"}
{"file": "data\\memory\\unaligned.pd", "nl": "Read a word from an address aligned at `N` element boundary", "code": "template <auto N = 1>\n    inline word_t read(addr_t addr)\n    {\n        static assert((N & (N - 1)) == 0);\n        static assert((WordSize / N) * N == WordSize);\n        sim_assert((addr & (N - 1)) == 0);\n\n        word_t per_bank_value;\n\n        // read per-channel data into local array\n        static for(const auto i : WordSize)\n        {\n            const auto offset = checked_cast<element_index_t>((WordSize - i) - 1);\n\n            per_bank_value[i] = mem[i][(addr + offset) / WordSize];\n        }\n\n        // rotate\n        const auto rotate_amount = cast<index_t<WordSize / N>>(addr / N);\n        return cast<word_t>(rotate_array_right<WordSize / N>(cast<T[WordSize / N][N]>(per_bank_value), rotate_amount));\n    }"}
{"file": "data\\memory\\unaligned.pd", "nl": "Write a word to a word aligned address", "code": "inline void write_aligned(addr_t addr, word_t value)\n    {\n        sim_assert((addr & (WordSize - 1)) == 0);\n\n        static for(const auto i : WordSize)\n        {\n            mem[i][addr / WordSize] = value[i];\n        }\n    }"}
{"file": "data\\memory\\unaligned.pd", "nl": "Write specified number of elements to an address aligned at `N` element boundary. The `size` must be a multiple of `N` and no greater than `WordSize`.", "code": "template <auto N = 1>\n    inline void write(addr_t addr, word_t value, element_count_t size)\n    {\n        static assert((N & (N - 1)) == 0);\n        static assert((WordSize / N)*N == WordSize);\n        sim_assert((addr & (N - 1)) == 0);\n        sim_assert((size & (N - 1)) == 0);\n\n        // Attach write mask to data elements\n        auto mask = mask_less_than<WordSize / N>(size / N);\n        auto data_with_mask = zip_with(make_optional<T[N]>, mask, cast<T[WordSize / N][N]>(value));\n\n        // Rotate both mask and data\n        const auto rotate_amount = cast<index_t<WordSize / N>>(addr / N);\n        const auto per_bank_data_with_mask = rotate_array_left<WordSize / N>(data_with_mask, rotate_amount);\n\n        static for(const auto i : WordSize / N)\n        {\n            if (per_bank_data_with_mask[i].is_valid)\n            {\n                const auto offset = checked_cast<element_index_t>((WordSize - i * N) - 1);\n\n                static for(const auto j : N)\n                {\n                    mem[i * N + j][(addr + offset) / WordSize] = per_bank_data_with_mask[i].value[j];\n                }\n            }\n        }\n    }"}
{"file": "data\\memory\\unaligned.pd", "nl": "Read a word from a word aligned address.", "code": "inline read_word_t read_aligned(addr_t addr)\n    {\n        sim_assert((addr & (WordSize - 1)) == 0);\n\n        T[NumHorizontalBanks][NumVerticalBanks][BankWordSize] value;\n\n        static for(const auto h : NumHorizontalBanks)\n        {\n            static for(const auto v : NumVerticalBanks)\n            {\n                value[h][v] = mem[h][v][addr / NumVerticalBanks];\n            }\n        }\n\n        return reinterpret_cast<read_word_t>(value[addr / WordSize]);\n    }"}
{"file": "data\\memory\\unaligned.pd", "nl": "Read a word from an unaligned address.", "code": "inline read_word_t read(addr_t addr)\n    {\n        T[NumHorizontalBanks][NumVerticalBanks][BankWordSize] per_bank_value;\n\n        static for(const auto h : NumHorizontalBanks)\n        {\n            const auto hoffset = (NumHorizontalBanks - h - 1) * WordSize;\n\n            auto bank_addr = (addr + hoffset) / (NumHorizontalBanks * BankWordSize);\n\n            // read per-bank data into local array\n            static for(const auto v : NumVerticalBanks)\n            {\n                const auto voffset = (NumVerticalBanks - v) - 1;\n\n                per_bank_value[h][v] = mem[h][v][(bank_addr + voffset) / NumVerticalBanks];\n            }\n        }\n\n        // rotate\n        const auto AllBanksWordSize = NumHorizontalBanks * WordSize;\n        read_word_t value;\n        if (AllBanksWordSize > 1)\n        {\n            auto per_bank_value_flattened = cast<T[AllBanksWordSize]>(per_bank_value);\n            index_t<AllBanksWordSize> rotate_amount = addr;\n            value = rotate_array_right<ReadWordSize>(per_bank_value_flattened, rotate_amount);\n        }\n        else\n        {\n            value = reinterpret_cast<read_word_t>(per_bank_value);\n        }\n        return value;\n    }"}
{"file": "data\\memory\\unaligned.pd", "nl": "Write a word to a word aligned address.", "code": "inline void write_aligned(addr_t addr, word_t value)\n    {\n        sim_assert((addr & (WordSize - 1)) == 0);\n\n        auto per_bank_value = cast<T[NumVerticalBanks][BankWordSize]>(value);\n\n        auto word_addr = addr / WordSize;\n        auto mask = reinterpret_cast<bool[NumHorizontalBanks]>(1 << cast<index_t<NumHorizontalBanks>>(word_addr));\n\n        static for(const auto h : NumHorizontalBanks)\n        {\n            if (NumHorizontalBanks == 1 || mask[h])\n            {\n                static for(const auto v : NumVerticalBanks)\n                {\n                    mem[h][v][word_addr / NumHorizontalBanks] = per_bank_value[v];\n                }\n            }\n        }\n    }"}
{"file": "device\\Agilex\\numeric\\float32\\operator.pd", "nl": "Floating-point multiplication.", "code": "inline float32 mul(float32 x, float32 y)\n{\n    return fmul32(x, y);\n}"}
{"file": "device\\Agilex\\numeric\\float32\\operator.pd", "nl": "Floating-point addition.", "code": "inline float32 add(float32 x, float32 y)\n{\n    return fadd32(x, y);\n}"}
{"file": "device\\Agilex\\numeric\\float32\\operator.pd", "nl": "Floating-point subtraction.", "code": "inline float32 sub(float32 x, float32 y)\n{\n    return fsub32(x, y);\n}"}
{"file": "device\\Agilex\\numeric\\float32\\operator.pd", "nl": "Floating-point multiply-accumulate.", "code": "inline float32 mad(float32 x, float32 y, float32 z)\n{\n    return fmad32(x, y, z);\n}"}
{"file": "device\\AgilexAP\\numeric\\float32\\operator.pd", "nl": "Floating-point multiplication.", "code": "inline float32 mul(float32 x, float32 y)\n{\n    return F32::float32_mul_denormoff(x, y);\n}"}
{"file": "device\\AgilexAP\\numeric\\float32\\operator.pd", "nl": "Floating-point addition.", "code": "inline float32 add(float32 x, float32 y)\n{\n    return F32::float32_add_denormoff(x, y);\n}"}
{"file": "device\\AgilexAP\\numeric\\float32\\operator.pd", "nl": "Floating-point subtraction.", "code": "inline float32 sub(float32 x, float32 y)\n{\n    return F32::float32_sub_denormoff(x, y);\n}"}
{"file": "device\\AgilexAP\\numeric\\float32\\operator.pd", "nl": "Floating-point multiply-accumulate.", "code": "inline float32 mad(float32 x, float32 y, float32 z)\n{\n    return F32::float32_add_denormoff(x, F32::float32_mul_denormoff(y, z));\n}"}
{"file": "device\\Arria10\\numeric\\float32\\operator.pd", "nl": "Floating-point multiplication.", "code": "inline float32 mul(float32 x, float32 y)\n{\n    return fmul32(x, y);\n}"}
{"file": "device\\Arria10\\numeric\\float32\\operator.pd", "nl": "Floating-point addition.", "code": "inline float32 add(float32 x, float32 y)\n{\n    return fadd32(x, y);\n}"}
{"file": "device\\Arria10\\numeric\\float32\\operator.pd", "nl": "Floating-point subtraction.", "code": "inline float32 sub(float32 x, float32 y)\n{\n    return fsub32(x, y);\n}"}
{"file": "device\\Arria10\\numeric\\float32\\operator.pd", "nl": "Floating-point multiply-accumulate.", "code": "inline float32 mad(float32 x, float32 y, float32 z)\n{\n    return fmad32(x, y, z);\n}"}
{"file": "device\\ASIC\\numeric\\float32\\operator.pd", "nl": "Floating-point multiplication.", "code": "inline float32 mul(float32 x, float32 y)\n{\n    return F32::float32_mul_denormoff(x, y);\n}"}
{"file": "device\\ASIC\\numeric\\float32\\operator.pd", "nl": "Floating-point addition.", "code": "inline float32 add(float32 x, float32 y)\n{\n    return F32::float32_add_denormoff(x, y);\n}"}
{"file": "device\\ASIC\\numeric\\float32\\operator.pd", "nl": "Floating-point subtraction.", "code": "inline float32 sub(float32 x, float32 y)\n{\n    return F32::float32_sub_denormoff(x, y);\n}"}
{"file": "device\\ASIC\\numeric\\float32\\operator.pd", "nl": "Floating-point multiply-accumulate.", "code": "inline float32 mad(float32 x, float32 y, float32 z)\n{\n    return F32::float32_add_denormoff(x, F32::float32_mul_denormoff(y, z));\n}"}
{"file": "device\\SimOnly\\numeric\\float32\\operator.pd", "nl": "Floating-point multiplication.", "code": "inline float32 mul(float32 x, float32 y)\n{\n    return F32::float32_mul_denormoff(x, y);\n}"}
{"file": "device\\SimOnly\\numeric\\float32\\operator.pd", "nl": "Floating-point addition.", "code": "inline float32 add(float32 x, float32 y)\n{\n    return F32::float32_add_denormoff(x, y);\n}"}
{"file": "device\\SimOnly\\numeric\\float32\\operator.pd", "nl": "Floating-point subtraction.", "code": "inline float32 sub(float32 x, float32 y)\n{\n    return F32::float32_sub_denormoff(x, y);\n}"}
{"file": "device\\SimOnly\\numeric\\float32\\operator.pd", "nl": "Floating-point multiply-accumulate.", "code": "inline float32 mad(float32 x, float32 y, float32 z)\n{\n    return F32::float32_add_denormoff(x, F32::float32_mul_denormoff(y, z));\n}"}
{"file": "device\\U250\\numeric\\float32\\operator.pd", "nl": "Floating-point multiplication.", "code": "inline float32 mul(float32 x, float32 y)\n{\n    return F32::float32_mul_denormoff(x, y);\n}"}
{"file": "device\\U250\\numeric\\float32\\operator.pd", "nl": "Floating-point addition.", "code": "inline float32 add(float32 x, float32 y)\n{\n    return F32::float32_add_denormoff(x, y);\n}"}
{"file": "device\\U250\\numeric\\float32\\operator.pd", "nl": "Floating-point subtraction.", "code": "inline float32 sub(float32 x, float32 y)\n{\n    return F32::float32_sub_denormoff(x, y);\n}"}
{"file": "device\\U250\\numeric\\float32\\operator.pd", "nl": "Floating-point multiply-accumulate.", "code": "inline float32 mad(float32 x, float32 y, float32 z)\n{\n    return F32::float32_add_denormoff(x, F32::float32_mul_denormoff(y, z));\n}"}
{"file": "device\\U250-1\\numeric\\float32\\operator.pd", "nl": "Floating-point multiplication.", "code": "inline float32 mul(float32 x, float32 y)\n{\n    return F32::float32_mul_denormoff(x, y);\n}"}
{"file": "device\\U250-1\\numeric\\float32\\operator.pd", "nl": "Floating-point addition.", "code": "inline float32 add(float32 x, float32 y)\n{\n    return F32::float32_add_denormoff(x, y);\n}"}
{"file": "device\\U250-1\\numeric\\float32\\operator.pd", "nl": "Floating-point subtraction.", "code": "inline float32 sub(float32 x, float32 y)\n{\n    return F32::float32_sub_denormoff(x, y);\n}"}
{"file": "device\\U250-1\\numeric\\float32\\operator.pd", "nl": "Floating-point multiply-accumulate.", "code": "inline float32 mad(float32 x, float32 y, float32 z)\n{\n    return F32::float32_add_denormoff(x, F32::float32_mul_denormoff(y, z));\n}"}
{"file": "device\\U250-2\\numeric\\float32\\operator.pd", "nl": "Floating-point multiplication.", "code": "inline float32 mul(float32 x, float32 y)\n{\n    return F32::float32_mul_denormoff(x, y);\n}"}
{"file": "device\\U250-2\\numeric\\float32\\operator.pd", "nl": "Floating-point addition.", "code": "inline float32 add(float32 x, float32 y)\n{\n    return F32::float32_add_denormoff(x, y);\n}"}
{"file": "device\\U250-2\\numeric\\float32\\operator.pd", "nl": "Floating-point subtraction.", "code": "inline float32 sub(float32 x, float32 y)\n{\n    return F32::float32_sub_denormoff(x, y);\n}"}
{"file": "device\\U250-2\\numeric\\float32\\operator.pd", "nl": "Floating-point multiply-accumulate.", "code": "inline float32 mad(float32 x, float32 y, float32 z)\n{\n    return F32::float32_add_denormoff(x, F32::float32_mul_denormoff(y, z));\n}"}
{"file": "sync\\lock\\multi.pd", "nl": "Increment the semaphore count by the specified `amount`, potentially waking one or more threads.", "code": "void post_multiple(sem_idx_t which, sem_ctr_t amount)\n    {\n        // static for needed due to compiler limitation (Task #6239)\n        static for(const auto i : N)\n        {\n            if (i == which)\n            {\n                sim_assert((cast<sem_ctr_t>(_counter[i].count()) + amount) <= M);\n                _counter[i].add(amount);\n            }\n        }\n    }"}
{"file": "sync\\lock\\multi.pd", "nl": "Increment the semaphore count by 1, potentially waking a thread.", "code": "inline void post(sem_idx_t which)\n    {\n        // static for needed due to compiler limitation (Task #6239)\n        static for(const auto i : N)\n        {\n            if (i == which)\n            {\n                _counter[i].increment();\n            }\n        }\n    }"}
{"file": "sync\\lock\\multi.pd", "nl": "Check if the current count is greater than or equal to value. If `decrement_count` flag is set, and the current count is sufficient, this method will also decrement the count. This function is not inherently threadsafe, and must be called from inside an `atomic` or `wait_for`.", "code": "inline bool test_and_decrement(sem_idx_t which, sem_ctr_t val, bool decrement_count)\n    {\n        bool result = false;\n\n        sem_ctr_t[N] counts;\n\n        static for(const auto i : N)\n        {\n            counts[i] = _counter[i].count();\n        }\n\n        result = counts[which] >= val;\n\n        if (result && decrement_count)\n        {\n            static for(const auto i : N)\n            {\n                if (i == which)\n                {\n                    _counter[i].subtract(val);\n                }\n            }\n        }\n\n        return result;\n    }"}
{"file": "sync\\lock\\multi.pd", "nl": "If blocking, wait for the semaphore count to be non-zero and conditionally decrement the count. Otherwise check if the semaphore count is non-zero, conditionally decrement the count, and assert if `decrement_count` is true and the count is zero.", "code": "inline bool wait(sem_idx_t which, bool decrement_count)\n    {\n        return wait_helper(which, 1, decrement_count);\n    }"}
{"file": "sync\\lock\\multi.pd", "nl": "Acquire a reader lock on the lock at the specified index.", "code": "inline void read_lock(rwlock_index_t index)\n    {\n        lock(index, true);\n    }"}
{"file": "sync\\lock\\multi.pd", "nl": "Acquire a writer lock on the lock at the specified index.", "code": "inline void write_lock(rwlock_index_t index)\n    {\n        lock(index, false);\n    }"}
{"file": "sync\\lock\\multi.pd", "nl": "Release a reader lock on the lock at the specified index.", "code": "inline void read_unlock(rwlock_index_t index)\n    {\n        unlock(index, true);\n    }"}
{"file": "sync\\lock\\multi.pd", "nl": "Release a writer lock on the lock at the specified index.", "code": "inline void write_unlock(rwlock_index_t index)\n    {\n        unlock(index, false);\n    }"}
{"file": "sync\\lock\\multi.pd", "nl": "Atomically acquire the lock with the specified index if it is not already acquired otherwise block waiting on the lock to be released.", "code": "void lock(index_t<NumMutexes> index)\n    {\n        sim_assert(is_initialized);\n\n        wait([index]()\n        {\n            bool result = false;\n\n            uint1 r = _r[index];\n            uint1 w =  _w[index];\n\n            if (r == w)\n            {\n                w = modular::increment(w);\n                result = true;\n            }\n            _w[index] = w;\n\n            return result;\n        });\n    }"}
{"file": "sync\\lock\\multi.pd", "nl": "Release the lock with the specified index. You must never unlock a mutex that is not locked,", "code": "void unlock(index_t<NumMutexes> index)\n    {\n        sim_assert(is_initialized);\n\n        uint1 r = _r[index];\n        r = modular::increment(r);\n        _r[index] = r;\n    }"}
{"file": "sync\\lock\\multi.pd", "nl": "Attempt to acquire either a reader or a writer lock for the lock with the specified index.", "code": "void lock(rwlock_index_t index, bool is_reader)\n    {\n        sim_assert(_is_initialized);\n\n        wait([index, is_reader]()\n        {\n            bool result = false;\n\n            auto r = _r[index];\n            auto w = _w[index];\n\n            bool no_write_locks = r.num_writers == w.num_writers;\n            count_t<MaxThreads> reader_count = w.num_readers - r.num_readers;\n\n            if (is_reader)\n            {\n                // If not write locked and read locks available\n                if (no_write_locks && (reader_count < MaxThreads))\n                {\n                    w.num_readers = modular::increment(w.num_readers);\n\n                    result = true;\n                }\n            }\n            else\n            {\n                // If not write locked and no read locks\n                if (no_write_locks && (reader_count == 0))\n                {\n                    w.num_writers = modular::increment(w.num_writers);\n\n                    result = true;\n                }\n            }\n\n            _w[index] = w;\n\n            return result;\n        });\n    }"}
{"file": "sync\\lock\\multi.pd", "nl": "Return current value of semaphore. Provided primarily for debug/diagnostic purposes.", "code": "inline sem_ctr_t count(sem_idx_t which)\n    {\n        sem_ctr_t result;\n\n        // static for needed due to compiler limitation (Task #6239)\n        static for(const auto i : N)\n        {\n            if (i == which)\n            {\n                result = _counter[i].count();\n            }\n        }\n\n        return result;\n    }"}
{"file": "sync\\lock\\multi.pd", "nl": "Release a reader or writer lock at the specified index. You must never unlock without having previously acquired the same type of lock, otherwise you will create a deadlock situation.", "code": "void unlock(rwlock_index_t index, bool is_reader)\n    {\n        sim_assert(_is_initialized);\n\n        atomic\n        {\n            auto r =  _r[index];\n\n            if (is_reader)\n            {\n                // Decrement read lock ptr (by incrementing unlock side ptr) and leave write-lock ptr alone\n                r.num_readers = modular::increment(r.num_readers);\n            }\n            else\n            {\n                // Decrement write lock ptr (by incrementing unlock side ptr) and leave read-lock ptr alone\n                r.num_writers = modular::increment(r.num_writers);\n            }\n\n            _r[index] = r;\n        }\n    }"}
{"file": "sync\\lock\\multi.pd", "nl": "If blocking, wait for the semaphore count to be greater than or equal to the supplied value and conditionally decrement the count. / Otherwise check if the semaphore count is greater than or equal to `val`, conditionally decrement the count, and assert if `decrement_count` is true and the count is insufficient.", "code": "inline bool wait_multiple(sem_idx_t which, sem_ctr_t val, bool decrement_count)\n    {\n        return wait_helper(which, val, decrement_count);\n    }"}
{"file": "sync\\lock\\multi.pd", "nl": "Multiple instance semaphore.", "code": "//| Multiple instance semaphore.\ntemplate\n    < auto N               //< Number of semaphore instances.\n    , auto M               //< Maximum semaphore value.\n    , auto I               //< Initial value for the semaphore count. Must be less than or equal to `M`.\n    , auto Blocking = true //< By default, this is true and causes the semaphore to\n                           // block when wait is called. Setting this to false should only\n                           // be used when the caller can ensure that the semaphore count is\n                           // greater than 0 when wait is called. If it is not a diagnostics\n                           // assert is raised.\n    >\nclass multi_semaphore {\npublic:\n    using sem_ctr_t = count_t<M>;\n    using sem_idx_t = index_t<N>;\nstatic assert(I <= M);\n\nprivate:\n\n    counter<M, I>[N] _counter;\n\n    bool wait_helper(sem_idx_t which, sem_ctr_t val, bool decrement_count)\n    {\n        bool result;\n\n        if (Blocking)\n        {\n            wait_for(test_and_decrement(which, val, decrement_count));\n            result = true;\n        }\n        else\n        {\n            bool result;\n            atomic\n            {\n                result = test_and_decrement(which, val, decrement_count);\n            }\n\n            sim_assert(result || !decrement_count);\n        }\n\n        return result;\n    }"}
{"file": "device\\Stratix10\\hardware\\network.pd", "nl": "Send up to 64 bytes of data to the TOR link.", "code": "template<auto Channel=0>\n[[async]] void send_tor_100g\n    ( phit_100g_t phit              //< Data to send.\n    , [[last]] bool end_of_packet   //< Set to true for the last phit in a packet.\n    )\n{\n    // The end_of_packet parameter exists to enable multiple call sites to this function\n    // The information is duplicated inside of the phit\n    sim_assert(phit.end_of_packet == end_of_packet);\n\n    TOR_100G[Channel].send(phit, end_of_packet);\n}"}
{"file": "device\\Stratix10\\hardware\\network.pd", "nl": "Receive up to 64 bytes of data from the TOR link.", "code": "template<auto Channel=0>\nphit_100g_t recv_tor_100g()\n{\n    return TOR_100G[Channel].recv();\n}"}
{"file": "device\\Stratix10NX\\hardware\\network.pd", "nl": "Send up to 32 bytes of data to the TOR link.", "code": "template<auto Channel=0>\n[[async]] void send_tor_50g\n    ( phit_50g_t phit               //< Data to send.\n    , [[last]] bool end_of_packet   //< Set to true for the last phit in a packet.\n    )\n{\n    // The end_of_packet parameter exists to enable multiple call sites to this function\n    // The information is duplicated inside of the phit\n    sim_assert(phit.end_of_packet == end_of_packet);\n\n    TOR_50G[Channel].send(phit, end_of_packet);\n}"}
{"file": "device\\Stratix10NX\\hardware\\network.pd", "nl": "Receive up to 32 bytes of data from the TOR link.", "code": "template<auto Channel=0>\nphit_50g_t recv_tor_50g()\n{\n    return TOR_50G[Channel].recv();\n}"}
{"file": "codec\\crc.pd", "nl": "Process up to `MaxBytes` of new input data.", "code": "inline uint<Width> compute\n        ( count_t<ThreadCount> identifier   //< Which of the `ThreadCount` CRCs to update.\n        , uint8[MaxBytes] input             //< Input data.\n        , count_t<MaxBytes> input_bytes     //< Number of valid bytes in the input data.\n        , bool reset                        //< Indicates if CRC value should be reset before processing `input`.  Should be set to `true` on the first call associated with a particular input stream.\n        )\n    {\n        const auto table = generate();\n\n        // Because the CRC calculator operates on a reversed polynomial\n        // input bits are reversed in order to produce the same output\n        // as a normal (not reversed) polynomial.\n        // If ReflectInput is true, then input bits are not reversed\n        // which produces the same output as a CRC operating on a normal polynomial\n        // and reversed inputs.\n        if(!ReflectInput)\n        {\n            static for(const auto i : MaxBytes)\n            {\n                input[i] = reverse<uint8>(input[i]);\n            }\n        }\n\n        // The initial value is given in big-endian.\n        const auto initial = reverse<uint<Width>>(Init);\n        const auto input_bits = input_bytes * 8;\n        const auto off_bits = max_bits - input_bits;\n\n        // crc(r1, d) = crc(r1, 0) + crc(0, d). crc(0, d) depends on the width of input\n        const auto off_input = cast<uint<max_bits>>(cast<uint<max_bits>>(input) << off_bits);\n        const uint<Width> reduced_crc = crc_lookup(table, off_input);\n\n        uint<Width> crc_local;\n        atomic\n        {\n            // crc(r1, 0) depends on the width of remainer\n            uint<Width> crc_keep = reset ? initial : _crc_results[identifier];\n            uint<Width> updated_crc = crc_map(table, crc_keep, checked_cast<count_t<data_segments>>(off_bits / 4));\n\n            // combine crc(0,d) and crc(r,0)\n            crc_local = updated_crc ^ reduced_crc ^ (crc_keep >> input_bits);\n            _crc_results[identifier] = crc_local;\n        }\n\n        // Similar to the handling of ReflectInput, only reverse output bits\n        // when ReflectOutput is false (because the CRC operates on a reversed polynomial)\n        return (ReflectOutput ? crc_local : reverse<uint<Width>>(crc_local)) ^ XorOut;\n    }"}
{"file": "text\\parser\\float.pd", "nl": "Use a sign, mantissa and exponent to create a float or double. // Combination of mantissa and exponent must be within the allowable range for the requested type, e.g. 314159, -33 is equivalent to 3.14159e-38, which is within the range of a float. Return a `uint64` with bits packed as either a double or float, depending on value of `parseType`. 32-bit mode result can be cast directly to float.", "code": "inline optional<uint64> parse_scientific_format_to_float\n    ( bool positive\n    , uint64 mantissa\n    , int32 decimalExponent\n    , float_parser_parse_type parseType\n    )\n{\n    using productSize = uint<PRODUCT_SIZE>;\n    using correctLUTSize = uint<CORRECTED_LUT_BIT_WIDTH>;\n\n    bool succeeded = false;\n    uint64 result = 0;\n    auto resultMantissaBitWidth = (parseAsFloat32(parseType) ? 23 : 52);\n    auto resultExponentBitWidth = (parseAsFloat32(parseType) ? 8 : 11);\n    auto resultBitWidth = (parseAsFloat32(parseType) ? 32 : 64);\n    auto exponentMiddle = (parseAsFloat32(parseType) ? (128) : (1024));\n    auto effectiveMinDecimalExponent = (parseAsFloat32(parseType) ? MIN_FLOAT_DECIMAL_EXPONENT : MIN_DECIMAL_EXPONENT);\n    uint64 sign = (positive ? 0 : 1) << (resultBitWidth - 1);\n    auto infinityExponent = (parseAsFloat32(parseType) ? INF_EXP_32 : INF_EXP_64);\n    uint52 removeImplicitBitsMask = (1 << resultMantissaBitWidth) - 1;\n\n    uint10 lutIndex = decimalExponent - MIN_DECIMAL_EXPONENT;    \n    multiplier_entry multiplier = precomputedMultiplierLUT[lutIndex];\n    //lut has implicit 1 removed for compactness. We'll need to add it back on.\n    correctLUTSize implicit1 = 1 << LUT_BIT_WIDTH;\n    productSize product = mantissa * (implicit1 + multiplier.significand);\n    \n    if (decimalExponent > MAX_DECIMAL_EXPONENT){\n        succeeded = true;\n\n        result = sign + (infinityExponent << resultMantissaBitWidth);\n    }\n    else if (product == 0 || decimalExponent < effectiveMinDecimalExponent)\n    {\n        succeeded = true;\n        \n        //need to return 0, but also respect -0\n        result = sign;\n    }\n    else\n    {\n        auto highestBitIndex = highest_one<productSize>(product);\n        int16 binaryExponent = multiplier.exponent + exponentMiddle + highestBitIndex.value - CORRECTED_LUT_BIT_WIDTH;    \n\n        //shouldn't need more than 128bits removed\n        uint8 numBitsToRemove = highestBitIndex.value - resultMantissaBitWidth - (binaryExponent <= 0 ? binaryExponent-1 : 0);\n\n        productSize mask = (1 << numBitsToRemove) - 1;\n        productSize exactlyOneHalf = 1 << (numBitsToRemove - 1);\n\n        productSize bitsToRemove = product & mask;\n        uint55 resultMan = product >> numBitsToRemove;\n        uint54 mantissaOverflowed = 1 << (resultMantissaBitWidth + 1);\n\n        if (bitsToRemove > exactlyOneHalf)\n        {\n            resultMan++;\n        }\n        else if (bitsToRemove == exactlyOneHalf)\n        {\n            // round to nearest even\n            if ((resultMan & 1) == 1)\n            {\n                resultMan++;\n            }\n        }\n\n        if (binaryExponent < 0){\n            binaryExponent = 0;\n        }\n\n        if (resultMan >= mantissaOverflowed) {\n            binaryExponent++;\n        }\n\n        if (binaryExponent >= infinityExponent){\n            binaryExponent = infinityExponent;\n            resultMan = 0;\n        }\n\n        if (binaryExponent > 0) {\n            resultMan = resultMan & removeImplicitBitsMask;\n        }\n\n        result = sign + (binaryExponent << resultMantissaBitWidth) + resultMan;\n        succeeded = true;\n    }\n\n    return make_optional<uint64>(succeeded, result);\n}"}
{"file": "numeric\\float\\internal.pd", "nl": "Denormalization flag.", "code": "template<auto MantissaWidth, auto ExponentWidth>\nstruct floatPackedFormat\n{\n    uint<MantissaWidth> mantissa;\n    uint<ExponentWidth> exponent;\n    uint1 sign;\n}\n\nstruct specialCaseFlags\n{\n    bool nan;\n    bool zero;\n    bool inf;\n    bool finite;\n}"}
{"file": "numeric\\float\\internal.pd", "nl": "Check if nan, zero, inf, or finite.", "code": "template <auto MantissaWidth, auto ExponentWidth, Denorm denorm_mode>\ninline specialCaseFlags getSpecialCases_internal(floatPackedFormat<MantissaWidth, ExponentWidth> a)\n{\n    specialCaseFlags flags;\n    auto nonfinite_value = static(cast<uint<ExponentWidth>>((1 << ExponentWidth) - 1));\n    flags.nan = a.exponent == nonfinite_value && a.mantissa != 0;\n    flags.inf = a.exponent == nonfinite_value && a.mantissa == 0;\n    flags.finite = a.exponent != nonfinite_value;\n    if (denorm_mode == Denorm::On)\n    {\n        flags.zero = a.exponent == 0 && a.mantissa == 0;\n    }\n    else\n    {\n        flags.zero = a.exponent == 0;\n    }\n    return flags;\n}"}
{"file": "numeric\\float\\internal.pd", "nl": "Convert an integer value to a floating-point value. This generic function handles conversion both to `float32` and to `float64`. This function is not meant to be called by the general public. It is a worker function called by the `from_int` functions in the `float32` and `float64` modules. Those functions are responsible for passing the proper template parameters.", "code": "template\n< typename From      //< Type of the integer to convert.\n, typename To        //< Type to be converted to. This must be either `float32` or `float64`.\n, auto MantissaWidth\n, auto ExponentWidth\n, auto Bias\n>inline To int_to_float(From input)\n{\n    const auto result_width = bitsizeof(To);\n    const auto infinity_exponent = (1 << ExponentWidth) - 1;\n\n    using result_width_t = uint<result_width>;\n    using integer_width_t = uint<bitsizeof(From)>;\n\n    uint1 sign = 0;\n    uint<MantissaWidth> mantissa;\n    uint<ExponentWidth> exponent;\n\n    integer_width_t integer_value = input;\n\n    result_width_t result = 0;\n\n    if (input < 0)\n    {\n        integer_value = -input;\n        sign = 1;\n    }\n\n    auto ndx_high_bit_opt = highest_one<integer_width_t>(integer_value);\n    if (!ndx_high_bit_opt.is_valid)\n    {\n        result = 0;\n    }\n    else\n    {\n        if (ndx_high_bit_opt.value > MantissaWidth)\n        {\n            using extended_mantissa_width_t = uint<MantissaWidth + 2>;\n            // Max shift value is width of integer\n            using shift_width_t = bitindex_t<integer_width_t>;\n\n            shift_width_t shift = ndx_high_bit_opt.value - MantissaWidth;\n\n            extended_mantissa_width_t computed_mantissa = integer_value >> shift;\n            auto discarded_bits_mask = (1 << shift) - 1;\n            auto exactly_one_half = 1 << (shift - 1);\n            auto bits_to_remove = integer_value & discarded_bits_mask;\n            extended_mantissa_width_t mantissa_overflowed = 1 << (MantissaWidth + 1);\n\n            if (bits_to_remove > exactly_one_half)\n            {\n                ++computed_mantissa;\n            }\n            else if (bits_to_remove == exactly_one_half)\n            {\n                // round to nearest even\n                if ((computed_mantissa & 1) == 1)\n                {\n                    ++computed_mantissa;\n                }\n            }\n\n            exponent = Bias + MantissaWidth + shift;\n            if (computed_mantissa >= mantissa_overflowed)\n            {\n                ++exponent;\n            }\n\n            // check for infinity case; adjust mantissa accordingly\n            if (exponent == infinity_exponent)\n            {\n                computed_mantissa = 0;\n            }\n\n            mantissa = cast<uint<MantissaWidth>>(computed_mantissa);\n        }\n        else\n        {\n            // Max shift value is MantissaWidth\n            using shift_width_t = uint<bitsizeof(MantissaWidth)>;\n            shift_width_t shift = MantissaWidth - ndx_high_bit_opt.value;\n            mantissa = cast<uint<MantissaWidth>>(integer_value << shift);\n            exponent = Bias + MantissaWidth - shift;\n        }\n\n        result = cast<result_width_t>(sign) << (MantissaWidth + ExponentWidth);\n        result |= cast<result_width_t>(exponent) << MantissaWidth;\n        result |= mantissa;\n    }\n\n    // This structure acts as a work-around for the fact that we can't cast a uint\n    // directly into a float. We can, however cast a struct. This struct is used to\n    // build up the int_to_float function's return value.\n    struct ReturnStruct\n    {\n        result_width_t ret;\n    }\n\n    ReturnStruct rs = {result};\n\n    return cast<To>(rs);\n}"}
{"file": "numeric\\float\\internal.pd", "nl": "Convert a floating-point value to an integer value. This generic function handles conversion both from `float32` and from `float64`.// This function is not meant to be called by the general public. It is a worker function called by the `to_int` functions in the `float32` and `float64` modules. Those functions are responsible for passing the proper template parameters", "code": "inline optional<To> float_to_int(From input)\n{\n    const auto int_width = bitsizeof(To);\n    const auto float_width = bitsizeof(From);\n\n    using float_as_uint_t = uint<float_width>;\n    using exponent_t = uint<ExponentWidth>;\n    using mantissa_t = uint<MantissaWidth>;\n\n    struct FromStruct\n    {\n        From from;\n    }\n\n    FromStruct f = {input};\n\n    float_as_uint_t float_as_uint = cast<float_as_uint_t>(f);\n\n    bool to_is_signed = (~cast<To>(0)) < 0;\n    uint1 sign = float_as_uint >> float_width - 1;\n    exponent_t exponent = (float_as_uint >> MantissaWidth) & ~cast<exponent_t>(0);\n    mantissa_t mantissa = float_as_uint & ~cast<mantissa_t>(0);\n\n    To result;\n    bool valid = true;\n    if (to_is_signed == false && sign == 1)\n    {\n        valid = false;\n    }\n    else if (exponent == ~cast<exponent_t>(0))\n    {\n        // input is NaN or infinity\n        valid = false;\n        result = 0;\n    }\n    else if (exponent == 0)\n    {\n        // Here either the mantissa is zero meaning the float value is zero,\n        // or the mantissa is non-zero meaning the float is denormalized\n        // in which case truncating the fraction results in zero.\n        result = 0;\n    }\n    else\n    {\n        int<bitsizeof(exponent_t)> unbiased_exponent = exponent - Bias;\n        uint<MantissaWidth + 1> full_mantissa = mantissa;\n        full_mantissa |= 1 << MantissaWidth;\n\n        if (unbiased_exponent >= int_width)\n        {\n            valid = false;\n        }\n        else\n        {\n            if (!(unbiased_exponent < (int_width - 1)))\n            {\n                if (to_is_signed)\n                {\n                    if (unbiased_exponent == (int_width - 1))\n                    {\n                        if (!(mantissa == 0 && sign == 1))\n                            valid = false;\n                    }\n                }\n            }\n        }\n\n        if (unbiased_exponent > MantissaWidth)\n        {\n            auto shift = unbiased_exponent - MantissaWidth;\n            result = full_mantissa << shift;\n\n            if (result < 0)\n            {\n                result = ~result;\n            }\n        }\n        else\n        {\n            auto shift = MantissaWidth - unbiased_exponent;\n            result = cast<decltype(result)>(full_mantissa >> shift);\n        }\n        if (sign == 1)\n            result = -result;\n    }\n\n    return make_optional<To>(valid, result);\n}"}
{"file": "numeric\\float\\internal.pd", "nl": "Return the smallest integer not less than x.", "code": "template <typename Type, auto MantissaWidth, auto ExponentWidth, auto Bias, Denorm DenormMode>\ninline Type ceil_internal(Type x)\n{\n    auto binary = cast<floatPackedFormat<MantissaWidth, ExponentWidth>>(x);\n    auto flags = getSpecialCases_internal<MantissaWidth, ExponentWidth, DenormMode>(binary);\n\n    const auto exponent = binary.exponent - Bias;\n    const auto fractionBit = MantissaWidth - exponent;\n\n    if (flags.finite && !flags.zero && fractionBit >= 0)\n    {\n        const auto mantissa = binary.mantissa | 1 << MantissaWidth;\n        const auto fraction = mantissa & ((1 << fractionBit) - 1);\n        const auto integral = (mantissa >> fractionBit) + ((binary.sign == 0 && fraction != 0) ? 1 : 0);\n\n        if (integral == 0)\n        {\n            binary.exponent = 0;\n            binary.mantissa = 0;\n        }\n        else if (integral == 1)\n        {\n            binary.exponent = Bias;\n            binary.mantissa = 0;\n        }\n        else\n        {\n            binary.exponent = binary.exponent + (((integral << fractionBit) >> (MantissaWidth + 1)) & 1);\n            binary.mantissa = cast<decltype(binary.mantissa)>(integral << fractionBit);\n        }\n    }\n\n    return cast<Type>(binary);\n}"}
{"file": "numeric\\float\\internal.pd", "nl": "Return the largest integer not greater than x.", "code": "template <typename Type, auto MantissaWidth, auto ExponentWidth, auto Bias, Denorm DenormMode>\ninline Type floor_internal(Type x)\n{\n    auto binary = cast<floatPackedFormat<MantissaWidth, ExponentWidth>>(x);\n    auto flags = getSpecialCases_internal<MantissaWidth, ExponentWidth, DenormMode>(binary);\n\n    const auto exponent = binary.exponent - Bias;\n    const auto fractionBit = MantissaWidth - exponent;\n\n    if (flags.finite && !flags.zero && fractionBit >= 0)\n    {\n        const auto mantissa = binary.mantissa | 1 << MantissaWidth;\n        const auto fraction = mantissa & ((1 << fractionBit) - 1);\n        const auto integral = (mantissa >> fractionBit) + ((binary.sign != 0 && fraction != 0) ? 1 : 0);\n\n        if (integral == 0)\n        {\n            binary.exponent = 0;\n            binary.mantissa = 0;\n        }\n        else if (integral == 1)\n        {\n            binary.exponent = Bias;\n            binary.mantissa = 0;\n        }\n        else\n        {\n            binary.exponent = binary.exponent + (((integral << fractionBit) >> (MantissaWidth + 1)) & 1);\n            binary.mantissa = cast<decltype(binary.mantissa)>(integral << fractionBit);\n        }\n    }\n\n    return cast<Type>(binary);\n}"}
{"file": "numeric\\float\\internal.pd", "nl": "Return the nearest integer to x, rounding halfway away from zero.", "code": "template <typename Type, auto MantissaWidth, auto ExponentWidth, auto Bias, Denorm DenormMode>\ninline Type round_internal(Type x)\n{\n    auto binary = cast<floatPackedFormat<MantissaWidth, ExponentWidth>>(x);\n    auto flags = getSpecialCases_internal<MantissaWidth, ExponentWidth, DenormMode>(binary);\n\n    const auto exponent = binary.exponent - Bias;\n    const auto fractionBit = MantissaWidth - exponent;\n\n    if (flags.finite && fractionBit >= 0)\n    {\n        const auto mantissa = binary.mantissa | 1 << MantissaWidth;\n        const auto fraction = mantissa & ((1 << fractionBit) - 1);\n        const auto integral = (mantissa >> fractionBit);\n\n        const auto roundedIntegral = integral + ((mantissa >> (fractionBit - 1)) & 1);\n\n        if (roundedIntegral == 0)\n        {\n            binary.exponent = 0;\n            binary.mantissa = 0;\n        }\n        else if (roundedIntegral == 1)\n        {\n            binary.exponent = Bias;\n            binary.mantissa = 0;\n        }\n        else\n        {\n            binary.exponent = binary.exponent + (((roundedIntegral << fractionBit) >> (MantissaWidth + 1)) & 1);\n            binary.mantissa = cast<decltype(binary.mantissa)>(roundedIntegral << fractionBit);\n        }\n    }\n\n    return cast<Type>(binary);\n}"}
{"file": "numeric\\float\\internal.pd", "nl": "Return the nearest integer not greater in magnitude than x.", "code": "template <typename Type, auto MantissaWidth, auto ExponentWidth, auto Bias, Denorm DenormMode>\ninline Type trunc_internal(Type x)\n{\n    auto binary = cast<floatPackedFormat<MantissaWidth, ExponentWidth>>(x);\n    const auto sign = binary.sign;\n\n    binary.sign = 0;\n    x = floor_internal<Type, MantissaWidth, ExponentWidth, Bias, DenormMode>(cast<Type>(binary));\n\n    binary = cast<floatPackedFormat<MantissaWidth, ExponentWidth>>(x);\n    binary.sign = sign;\n\n    return cast<Type>(binary);\n}"}
{"file": "codec\\compression\\lzcommon.pd", "nl": "Either a raw byte or a reference to a previously-produced byte.", "code": "template<auto WindowSize>\nunion compressed_byte_payload\n{\n    uint8 data;\n    count_t<WindowSize> offset;\n}"}
{"file": "codec\\compression\\lzcommon.pd", "nl": "A tag and either a raw byte or a reference to a previously-produced byte.", "code": "template<auto WindowSize>\nstruct compressed_byte\n{{\n    //| Indicate if the element is raw data or a reference to\n    // previously-produced data.\n    input_kind kind;\n    //| The raw data or reference.\n    compressed_byte_payload<WindowSize> payload;\n}"}
{"file": "codec\\compression\\lzcommon.pd", "nl": "A reference to a previously-produced sequence of output bytes.", "code": "template<auto WindowSize, auto MaxLength>\nstruct reference\n{\n    count_t<WindowSize> offset;\n    count_t<MaxLength> length;\n}"}
{"file": "codec\\compression\\lzcommon.pd", "nl": "Either a raw byte or a reference to a previously-produced sequence of output bytes.", "code": "template<auto WindowSize, auto MaxLength>\nunion data_or_reference\n{\n    uint8 data;\n    reference<WindowSize, MaxLength> reference;\n}"}
{"file": "codec\\compression\\lzcommon.pd", "nl": "A tag and either a raw byte or a reference to a previously-produced sequence of output bytes.", "code": "template<auto WindowSize, auto MaxLength>\nstruct token\n{\n    input_kind kind;\n    data_or_reference<WindowSize, MaxLength> payload;\n}"}
{"file": "codec\\compression\\lzcomp.pd", "nl": "Given a 2D `Width` by `DictAssociativity` array of dictionary entries (absolute pointers into the sliding window, which along with the `ptr` argument the relative offset can be computed) return a 1D array of pointers indicating the prioritised order in which they should matched to available window ports. Since the `DictAssociativity` dimension of the input array will be in FIFO (distance) order, this default function first prioritises them by ascending byte position (following a greedy approach to finding the most/longest matches) followed by ascending distance (since the `DEFLATE` specification uses fewer bits for shorter distances). A custom function could, for example, seek to reorder the entries using external state or could be used to avoid certain distances that are known to give poor decompression performance.", "code": "template <auto Width, auto WindowSize, auto DictAssociativity>\ninline PrioritizeDictCallbackOutput<Width, WindowSize, DictAssociativity>\n    default_prioritize_dict_callback(PrioritizeDictCallbackInput<Width, WindowSize, DictAssociativity> input)\n{\n    using T = dictPrioritizedOutput_t<WindowSize>;\n    optional<T>[Width * DictAssociativity] unpacked;\n    static for(const auto assoc : DictAssociativity)\n    {\n        static for(const auto pos : Width)\n        {\n            unpacked[static(assoc * Width + pos)] = input.entries[pos][assoc];\n        }\n    }\n\n    return gather_optionals<T>(unpacked);\n}"}
{"file": "codec\\compression\\lzcomp.pd", "nl": "Input type for the `ChooseMatchCallback` template function.", "code": "template<auto Width, auto MaxLength, auto WindowSize, auto DictAssociativity>\nstruct ChooseMatchCallbackInput\n{\n    //| 2D `Width` by `DictAssociativity` array of back-reference candidates.\n    optional<reference<WindowSize, MaxLength>>[Width][DictAssociativity] candidates;\n    //| Array of literal value at each byte position.\n    uint8[Width] literals;\n    //| Indicates that this is the last call for the current data block,\n    // allowing static state to be reset.\n    count_t<Width> size;};"}
{"file": "codec\\compression\\lzcomp.pd", "nl": "Given a 2D `Width` by `DictAssociativity` array of back-reference candidates, collapse this into a 1D array of non-overlapping tokens that covers the remainder (or more) of the word. This callback exhaustively considers all valid chains of references originating at each byte-position within `Width` and has `O(Width)` complexity. In addition, the last token of each match (which is the only token that is allowed to stretch into the next word) is held back on each cycle, so that it may be shortened in the following cycle in case it can lead to an even longer reference-chain. Note that in order to prevent this callback from being the bottleneck in the compressor pipeline, it must be capable of a one result every clock cycle throughput. This can be tricky since state that has to carry between words (e.g. `_lastMask` here) must be read-modified-written in an atomic block. For this reason, the best possible reference-chain for each byte-position in `Width` is pre-computed prior to entering this atomic block, at which point the right chain can be selected and any state updated.", "code": "template <auto Width, auto MaxLength, auto WindowSize, auto DictAssociativity>\ninline ChooseMatchCallbackOutput<Width, MaxLength, WindowSize>\n    default_choose_match_callback_linear(ChooseMatchCallbackInput<Width, MaxLength, WindowSize, DictAssociativity> input)\n{\n    const auto MaxTotalLength = Width - 1 + MaxLength;\n    struct referenceChain\n    {\n        count_t<MaxTotalLength> totalLength;\n        count_t<Width> newRefCount;\n        bool[Width] newRef;\n    };\n    referenceChain[Width] bestChains;\n\n    // Find the longest reference chain starting from the most-significant byte of the word\n    const auto MinChainLength = 1;\n    static for(const auto pos : Width)\n    {\n        const auto rpos = Width - 1 - pos;\n\n        // Find the longest candidate starting from this position\n        count_t<MaxLength>[DictAssociativity] lengths;\n        static for(const auto assoc : DictAssociativity)\n        {\n            auto candidate = input.candidates[rpos][assoc];\n            lengths[assoc] = (candidate.is_valid ? candidate.value.length : 1);\n        }\n        auto maxLength = maximum(lengths);\n        sim_assert(maxLength != 0);\n\n        // Consider all lengths of this back-reference up to maxLength or to the end\n        // of the word (length-1 is equivalent to a literal, length-2 is skipped)\n        referenceChain[Width] chains;\n        static for(const auto lengthMinusOne : Width)\n        {\n            const auto length = lengthMinusOne + 1;\n            if (static(rpos + length <= Width))\n            {\n                referenceChain chain;\n\n                // If considering a reference that takes us to the end of the word (thus no chaining)\n                // then consider using its whole length even if it spills into the next word\n                if (static(rpos + length == Width) && maxLength > length)\n                {\n                    chain.totalLength = maxLength;\n                    chain.newRef[rpos] = true;\n                }\n                else\n                {\n                    chain.totalLength = length;\n\n                    if (static(length == 1))\n                    {\n                        chain.newRef[rpos] = true;\n                    }\n                    else if (static(length >= 3))\n                    {\n                        chain.newRef[rpos] = (length <= maxLength);\n                    }\n                }\n\n                if (chain.newRef[rpos])\n                {\n                    chain.newRefCount = 1;\n\n                    // Do not consider chaining if already reached end of word\n                    const auto nextOffset = rpos + length;\n                    if (static(nextOffset < Width))\n                    {\n                        // This chain does not yet span the entire word. Combine it with the next chain so that it does.\n                        auto nextChain = bestChains[nextOffset];\n                        chain.totalLength += nextChain.totalLength;\n                        chain.newRefCount += nextChain.newRefCount;\n                        sim_assert(rpos + chain.totalLength >= Width);\n                        auto mask = mask_greater_equal<Width, index_t<Width>>(nextOffset);\n                        static for(const auto i : Width)\n                        {\n                            // Check that no new references started before offset, and also that no new\n                            // references exists after the end of the next chain\n                            if (static(i < rpos) || mask[i])\n                                sim_assert(!chain.newRef[i]);\n                            if (static(i >= rpos + MinChainLength))\n                            {\n                                if (mask[i])\n                                    chain.newRef[i] = nextChain.newRef[i];\n                            }\n                        }\n                    }\n                }\n\n                chains[lengthMinusOne] = chain;\n            }\n        }\n\n        // For the set of all reference lengths, find the best one according to\n        // default_choose_match_callback_linear_best()\n        auto best = reduce(default_choose_match_callback_linear_best<referenceChain>, chains);\n        sim_assert(best.totalLength != 0);\n        sim_assert(best.newRefCount != 0);\n        sim_assert(best.newRef[rpos]);\n        bestChains[rpos] = best;\n    }\n\n    // Precompute other state ahead of entering the atomic block\n    using token_t = token<WindowSize, MaxLength>;\n    index_t<MaxLength>[Width] nextMasks;\n    optional<token_t>[Width] nextTokens;\n    count_t<2>[Width] nextBlackout;\n    index_t<Width>[Width][3] shortenLastMaskTo;\n    using offset_t = count_t<WindowSize>;\n    static for(const auto pos : Width)\n    {\n        // Precompute the number of future bytes that will get masked as a result\n        // of the last reference stretching into the following word(s)\n        auto totalLength = bestChains[pos].totalLength;\n        auto nextMask = pos + totalLength - Width;\n        sim_assert(nextMask >= 0 && nextMask <= MaxLength);\n        nextMasks[pos] = nextMask;\n\n        // Find the last newRefCount in order to determine which token will get\n        // held back; also precompute any bytes that must be blacked out from\n        // being shorten-able since that would result in an illegal length-2\n        // reference\n        // (since it is the first one that stretches to totalLength)\n        auto h1 = highest_one(bestChains[pos].newRef);\n        sim_assert(h1.is_valid);\n        auto candidates = input.candidates[h1.value];\n        auto lastRefLength = pos + totalLength - h1.value;\n        sim_assert(lastRefLength <= MaxLength);\n        optional<offset_t>[DictAssociativity] offsets;\n        static for(const auto assoc : DictAssociativity)\n        {\n            offsets[assoc].is_valid = (candidates[assoc].value.length >= lastRefLength);\n            offsets[assoc].value = candidates[assoc].value.offset;\n        }\n        auto fv = first_valid<offset_t>(offsets);\n        optional<token_t> tok;\n        count_t<2> blackout;\n        tok.is_valid = true;\n        if (lastRefLength == 1)\n        {\n            tok.is_valid &&= (h1.value < input.size);\n            tok.value.kind = input_kind::data;\n            tok.value.payload.data = input.literals[h1.value];\n            blackout = 0;\n        }\n        else\n        {\n            sim_assert(lastRefLength >= 3);\n            sim_assert(fv.is_valid);\n\n            tok.value.kind = input_kind::reference;\n            tok.value.payload.reference = { fv.value, lastRefLength };\n\n            // Blackout the first xor second byte of the next word from being shorten-able because\n            // that would result in a length-2 reference\n            blackout = (h1.value == Width - 1) ? 2 :\n                       (h1.value == Width - 2) ? 1 :\n                       /* (h1.value < Width - 2) */ 0;\n        }\n\n        nextTokens[pos] = tok;\n        nextBlackout[pos] = blackout;\n\n        // Since the last token from a previous match has been held back, pre-compute the ability to\n        // shorten this last token in order to find a better match\n        if (pos == 0)\n        {\n            shortenLastMaskTo[pos][0] = pos;\n        }\n        else\n        {\n            struct referenceChainWithPos\n            {\n                index_t<Width> pos;\n                count_t<MaxTotalLength> totalLength;\n                count_t<Width> newRefCount;\n            };\n            referenceChainWithPos[Width] chains;\n\n            if (pos > 1)\n            {\n                if (pos > 2)\n                {\n                    // Find the best chain to use from positions [2,pos]\n                    static for(const auto shortenBy : Width)\n                    {\n                        if (static(shortenBy <= pos - 2))\n                        {\n                            referenceChainWithPos chain;\n                            const auto shortenTo = pos - shortenBy;\n                            chain.pos = shortenTo;\n                            sim_assert(bestChains[shortenTo].totalLength > shortenBy);\n                            chain.totalLength = bestChains[shortenTo].totalLength - shortenBy;  // Account for the fact we're\n                                                                                                // potentially shortening a\n                                                                                                // previous token to use this\n                                                                                                // chain\n                            chain.newRefCount = bestChains[shortenTo].newRefCount;\n\n                            // Ascending shortenBy order since default_choose_match_callback_linear_best() prefers LHS\n                            // over RHS when tied so put smaller values first\n                            chains[shortenBy] = chain;\n                        }\n                    }\n                    chains[0] = reduce(default_choose_match_callback_linear_best<referenceChainWithPos>, chains);\n                    sim_assert(chains[0].pos >= 2 && chains[0].pos <= pos);\n\n                    // When the second byte is blacked out (to prevent a length-2 reference), this does\n                    // not also mean the first byte is; consider the range {0, [2,pos]} here\n                    chains[1].pos = 0;\n                    chains[1].totalLength = bestChains[0].totalLength - pos;\n                    chains[1].newRefCount = bestChains[0].newRefCount;\n\n                    auto bestIncludingPos0 = default_choose_match_callback_linear_best<referenceChainWithPos>(chains[0], chains[1]);\n                    shortenLastMaskTo[pos][2] = bestIncludingPos0.pos;\n                }\n                else\n                {\n                    sim_assert(pos == 2);\n\n                    chains[0].pos = 2;\n                    chains[0].totalLength = bestChains[2].totalLength - (pos - 2);\n                    chains[0].newRefCount = bestChains[2].newRefCount;\n                    shortenLastMaskTo[pos][2] = 2;\n                }\n\n                chains[1].pos = 1;\n                chains[1].totalLength = bestChains[1].totalLength - (pos - 1);\n                chains[1].newRefCount = bestChains[1].newRefCount;\n\n                // Find the best chain to use from positions [1,pos]\n                chains[0] = default_choose_match_callback_linear_best<referenceChainWithPos>(chains[0], chains[1]);\n                sim_assert(chains[0].pos >= 1 && chains[0].pos <= pos);\n                shortenLastMaskTo[pos][1] = chains[0].pos;\n            }\n            else\n            {\n                sim_assert(pos == 1);\n\n                chains[0].pos = 1;\n                chains[0].totalLength = bestChains[1].totalLength - (pos - 1);\n                chains[0].newRefCount = bestChains[1].newRefCount;\n                shortenLastMaskTo[pos][1] = 1;\n            }\n\n            chains[1].pos = 0;\n            chains[1].totalLength = bestChains[0].totalLength - pos;\n            chains[1].newRefCount = bestChains[0].newRefCount;\n\n            // Find the best chain to use from positions [0,pos]\n            chains[0] = default_choose_match_callback_linear_best<referenceChainWithPos>(chains[0], chains[1]);\n            sim_assert(chains[0].pos <= pos);\n            shortenLastMaskTo[pos][0] = chains[0].pos;\n        }\n    }\n\n    optional<index_t<Width>> snappedLastMask;\n    optional<token_t> snappedLastToken;\n    auto last = (input.size == 0);\n    bool snappedLastMaskValid;\n    atomic\n    {\n        static index_t<MaxLength> _lastMask = 0;\n        static count_t<2> _lastBlackout = 0;\n        static optional<token_t> _lastToken = {};\n        static uint8 _lastLiteral = {};\n\n        snappedLastToken = _lastToken;\n        snappedLastMask.is_valid = (_lastMask < Width);\n        // Shorten previously-held-back token length by the allowable amount (accounting for\n        // possible blackout of the first xor second byte)\n        snappedLastMask.value = shortenLastMaskTo[_lastMask][_lastBlackout];\n\n        if (!_lastToken.is_valid || _lastToken.value.kind != input_kind::reference)\n            sim_assert(snappedLastMask.value == _lastMask);\n        else\n            sim_assert(snappedLastMask.value <= _lastMask);\n\n        if (last)\n        {\n            _lastMask = 0; // Reset to zero for next time round\n            _lastToken.is_valid = false;\n            _lastBlackout = 0;\n        }\n        else if (!snappedLastMask.is_valid)\n        {\n            _lastMask -= Width; // A reference from a prior word has masked out this entire word\n            _lastBlackout = 0;\n        }\n        else\n        {\n            // Shorten held-back token length by appropriate value\n            count_t<Width> shortenBy = (_lastMask - snappedLastMask.value);\n            snappedLastToken.value.payload.reference.length -= shortenBy;\n\n            if (snappedLastToken.value.kind == input_kind::reference)\n            {\n                // If it drops this token length to 1, convert it to a literal\n                if (snappedLastToken.value.payload.reference.length == 1)\n                {\n                    sim_assert(snappedLastMask.value == 0);\n                    snappedLastToken.value.kind = input_kind::data;\n                    snappedLastToken.value.payload.data = _lastLiteral;\n                }\n                else\n                    sim_assert(snappedLastToken.value.payload.reference.length >= 3);\n            }\n\n            _lastMask = nextMasks[snappedLastMask.value];\n            _lastBlackout = nextBlackout[snappedLastMask.value];\n            _lastToken = nextTokens[snappedLastMask.value];\n        }\n\n        _lastLiteral = input.literals[Width-1];\n    }\n\n    optional<token_t>[Width] result;\n\n    // Restore the previously held back token\n    result[0].is_valid = (snappedLastMask.is_valid && snappedLastToken.is_valid);\n    result[0].value = snappedLastToken.value;\n\n    auto bestChain = bestChains[snappedLastMask.value];\n\n    // Re-discover match lengths by counting how many times each reference appears in the prefix sum\n    auto newRefPrefixSum = prefix_sum<count_t<Width>>(cast<uint1[Width]>(bestChain.newRef));\n    count_t<Width>[Width] newRefLengths;\n    static for(const auto iref : Width)\n    {\n        bool[Width] refMatches;\n        const auto irefPlusOne = iref + 1;\n        static for(const auto pos : Width)\n        {\n            refMatches[pos] = (newRefPrefixSum[pos] == irefPlusOne);\n        }\n        newRefLengths[irefPlusOne % Width] = pop_count<bool[Width]>(refMatches);\n    }\n\n    // Now populate all but the last token\n    // (consider only up to but not including the last position, because any such last token there\n    // would be held back anyway)\n    auto mask = mask_less_than<Width>(input.size);\n    static for(const auto pos : Width - 1)\n    {\n        optional<token_t> tok;\n        // Valid reference only if not masked out by a previous word or by other references\n        // in this same word\n        tok.is_valid = (snappedLastMask.is_valid && bestChain.newRef[pos]);\n\n        // Ignore the last reference (since it is being held back)\n        tok.is_valid &&= (newRefPrefixSum[pos] != newRefPrefixSum[Width-1]);\n\n        auto iref = newRefPrefixSum[pos] % Width;\n        auto length = newRefLengths[iref];\n        if (tok.is_valid)\n            sim_assert(length != 0);\n\n        // Find the first candidate of at least this requested length\n        // (prefer lower-index candidates since they have a smaller offset)\n        optional<offset_t>[DictAssociativity] offsets;\n        static for(const auto assoc : DictAssociativity)\n        {\n            auto candidate = input.candidates[pos][assoc];\n            offsets[assoc].is_valid = (candidate.value.length >= length);\n            offsets[assoc].value = candidate.value.offset;\n        }\n        auto fv = first_valid<offset_t>(offsets);\n        auto newRefOffset = fv.value;\n        if (tok.is_valid && length != 1)\n            sim_assert(fv.is_valid);\n\n        if (length == 1)\n        {\n            tok.is_valid &&= mask[pos];\n            tok.value.kind = input_kind::data;\n            tok.value.payload.data = input.literals[pos];\n        }\n        else\n        {\n            tok.value.kind = input_kind::reference;\n            tok.value.payload.reference = {newRefOffset, length};\n        }\n\n        result[pos + 1] = tok;\n    }\n\n    return result;\n}"}
{"file": "codec\\compression\\lzcomp.pd", "nl": "Given a 2D `Width` by `DictAssociativity` array of back-reference candidates, collapse this into a 1D array of non-overlapping tokens that covers the remainder (or more) of the word. This callback uses a greedy heuristic to chain the longest sequence back-references (and literals) together with `O(log2(Width))` complexity. Note that in order to prevent this callback from being the bottleneck in the compressor pipeline, it must be capable of a one result every clock cycle throughput. This can be tricky since state that has to carry between words (e.g. `_lastMask` here) must be read-modified-written in an atomic block. For this reason, the best possible reference-chain for each byte-position in `Width` is pre-computed prior to entering this atomic block, at which point the right chain can be selected and any state updated.", "code": "template <auto Width, auto MaxLength, auto WindowSize, auto DictAssociativity>\ninline ChooseMatchCallbackOutput<Width, MaxLength, WindowSize>\n    default_choose_match_callback_log2(ChooseMatchCallbackInput<Width, MaxLength, WindowSize, DictAssociativity> input)\n{\n    using reference_t = reference<WindowSize, MaxLength>;\n\n    inline optional<reference_t> longest_reference(optional<reference_t> lhs, optional<reference_t> rhs)\n    {\n        optional<reference_t> r;\n        if (lhs.is_valid && rhs.is_valid)\n            r = (lhs.value.length >= rhs.value.length ? lhs : rhs);\n        else if (lhs.is_valid)\n            r = lhs;\n        else\n            r = rhs;\n        return r;\n    }\n\n    struct reference_chain\n    {\n        index_t<Width + MaxLength> totalLength;\n        bool[Width] newRef;\n    };\n    reference_chain[Width] referenceChains;\n\n    reference_t[Width] longest;\n    static for(const auto pos : Width)\n    {\n        // Extract the longest back reference out of all candidates at this position\n        auto l = reduce(longest_reference, input.candidates[pos]);\n        // If no back reference found, signal a literal with offset = 0 and length = 1\n        longest[pos] = (l.is_valid ? l.value : { 0 /* offset */ , 1 /* length */});\n\n        // Initialise the reference chains with this longest reference\n        referenceChains[pos].totalLength = longest[pos].length;\n        referenceChains[pos].newRef[pos] = true;\n    }\n\n    // Iteratively build up a chain of references (or literals represented by 1 byte refs)\n    // in a way that avoids data dependencies.\n    // Each pass through the outer loop combines existing references with those immediately\n    // after it until the entire word is covered.\n    // The inner loop has no loop carried dependencies.\n    const auto MinChainLength = 1;\n    static for (const auto iteration : clog2(Width))\n    {\n        auto newChains = referenceChains;\n\n        static for (const auto offset : Width)\n        {\n            auto newChain = referenceChains[offset];\n\n            auto nextOffset = offset + newChain.totalLength;\n            // References must have a non-zero length and thus those within the last\n            // (MinChainLength << iteration) bytes do not need to be considered for further chaining\n            if (static(offset < Width - (MinChainLength << iteration)) && nextOffset < Width)\n            {\n                // This chain does not yet span the entire word. Combine it with the next chain.\n\n                auto nextChain = referenceChains[nextOffset];\n                newChain.totalLength += nextChain.totalLength;\n                auto mask = mask_greater_equal<Width>(nextOffset);\n                static for(const auto i : Width)\n                {\n                    // Check that no new references started before offset, and also that no new\n                    // references exists after the end of the next chain\n                    if (static(i < offset) || mask[i])\n                        sim_assert(!newChain.newRef[i]);\n                    if (static(i >= offset + MinChainLength))\n                    {\n                        if (mask[i])\n                            newChain.newRef[i] = nextChain.newRef[i];\n                    }\n                }\n            }\n\n            newChains[offset] = newChain;\n        }\n\n        referenceChains = newChains;\n    }\n\n    index_t<MaxLength>[Width] nextMasks;\n    static for(const auto pos : Width)\n    {\n        auto totalLength = referenceChains[pos].totalLength;\n        auto nextMask = pos + totalLength - Width;\n        sim_assert(nextMask >= 0);\n        nextMasks[pos] = nextMask;\n    }\n\n    index_t<MaxLength> snappedLastMask;\n    auto last = (input.size == 0);\n    atomic\n    {\n        static index_t<MaxLength> _lastMask = 0;\n        snappedLastMask = _lastMask;\n        if (last)\n            _lastMask = 0; // Reset to zero for next time round\n        else if (_lastMask >= Width)\n            _lastMask -= Width; // A reference from a prior word has masked out this entire word\n        else\n            _lastMask = nextMasks[snappedLastMask];\n    }\n\n    auto chain = referenceChains[snappedLastMask];\n\n    using token_t = token<WindowSize, MaxLength>;\n    optional<token_t>[Width] result;\n    auto totalBytesFromStart = chain.totalLength + snappedLastMask;\n    auto mask = mask_less_than<Width>(input.size);\n    static for(const auto pos : Width)\n    {\n        // Valid reference only if not masked out by a previous word or by other references\n        // in this same word\n        result[pos].is_valid = (snappedLastMask < Width && chain.newRef[pos]);\n\n        if (longest[pos].length == 1)\n        {\n            result[pos].is_valid &&= mask[pos];\n            result[pos].value.kind = input_kind::data;\n            result[pos].value.payload.data = input.literals[pos];\n        }\n        else\n        {\n            result[pos].value.kind = input_kind::reference;\n            result[pos].value.payload.reference.offset = longest[pos].offset;\n            result[pos].value.payload.reference.length = longest[pos].length;\n        }\n    }\n\n    return result;\n}"}
{"file": "codec\\compression\\lzcomp.pd", "nl": "Adjust the maximum iterations that the compressor will stall to find a longer back-reference, if one is possible. Integer values from 0 to the `MaxStallCount` template parameter are accepted. Higher stall counts will improve compression ratio at the expense of throughput, and vice-versa.", "code": "inline void set_max_stall_count(count_t<(MaxStallCount == 0 ? 1 : MaxStallCount)> maxStallCount)\n    {\n        sim_assert(maxStallCount <= MaxStallCount);\n        _maxStallCount = maxStallCount;\n    }"}
{"file": "codec\\compression\\lzcomp.pd", "nl": "Push the given number of bytes into the compressor. It is illegal to call `push` with `size < Width` unless `last` is set. The `last` argument causes the compressor to flush after processing the current word.", "code": "template\n    < ( token_t[Width], count_t<Width>\n      , bool //< Indicate whether this will be the last call. Allows the\n             // consumer to flush if desired.\n      )->void WriteCallback\n      //< Callback function for supplying the next `Width` tokens.\n    , (PrioritizeDictCallbackInput_t)->PrioritizeDictCallbackOutput_t PrioritizeDictCallback\n      //< Callback function to determine the order in which dictionary hits\n      // should be assigned to available window ports. Input dictionary\n      // entries will be in FIFO (ascending distance) order. See\n      // `default_prioritize_dict_callback` for more information.\n    , (ChooseMatchCallbackInput_t)->ChooseMatchCallbackOutput_t ChooseMatchCallback\n      //< Callback function for collapsing the set of valid back-references\n      // (and literals) into a sequence of non-overlapping tokens that\n      // covers the remainder (or more) of the word. See\n      // `default_choose_match_callback_*` for more information.\n    >void push(uint8[Width] word, count_t<Width> size, [[last]] bool last)\n    {\n        push_pipeline<WriteCallback, PrioritizeDictCallback, ChooseMatchCallback>(1 + (last ? MaxWordsSpanned : 0), word, size);\n    }"}
{"file": "data\\buffer\\cyclic.pd", "nl": "Reset cyclic buffer. This is not thread-safe and should not be called while any other functions are running.", "code": "void reset()\n    {\n        // Free any entries in the buffer\n        atomic\n        {\n            auto freeCount = _freeCounter.count();\n            _freeCounter.add(Depth - freeCount);\n            // Ensure _freeCounter is full after reset\n            sim_assert(_freeCounter.count() == Depth);\n        }\n\n        _writeAddr = 0;\n        _freeAddr = 0;\n    }"}
{"file": "data\\buffer\\cyclic.pd", "nl": "Write one word. Maybe block until there is space in the buffer.", "code": "void write(T[WordSize] word)\n    {\n        // Wait for a free entry\n        inline bool entry_available()\n        {\n            bool result = (_freeCounter.count() != 0);\n            if (result)\n            {\n                _freeCounter.subtract(1);\n            }\n            return result;\n        }\n        wait_for(entry_available());\n\n        // Increment write pointer\n        addr_t localWriteAddr;\n        atomic\n        {\n            localWriteAddr = _writeAddr;\n            _writeAddr++;\n        }\n        // Write to memory\n        _cyclicBufferMem.write_aligned((localWriteAddr % Depth) * WordSize, word);\n    }"}
{"file": "data\\buffer\\cyclic.pd", "nl": "Free words up to, but not including, the specified address. Caller should ensure that this address is valid.", "code": "void free(addr_t addr /*< Element address.*/)\n    {\n        auto wordAddr = addr / WordSize;\n\n        count_t<TotalSize> count;\n        atomic\n        {\n            // Ensure not freeing past written entries\n            sim_assert(wordAddr <= _writeAddr);\n            // Ensure free pointer is not already past requested address\n            sim_assert(wordAddr >= _freeAddr);\n\n            // Determine number of entries to free\n            count = wordAddr - _freeAddr;\n            _freeAddr += count;\n        }\n        _freeCounter.add(count);\n    }"}
{"file": "data\\buffer\\cyclic.pd", "nl": "Block until a fully valid word has been written to the passed address.", "code": "void wait(addr_t addr /*< Element address.*/)\n    {\n        auto wordAddr = addr / WordSize;\n        if (WordSize > 1)\n        {\n            // Wait for the next word too if it spills over\n            wordAddr += cast<uint1>(cast<index_t<WordSize>>(addr) > WordSize - ReadWordSize);\n        }\n\n        wait_for(_writeAddr > wordAddr);\n    }"}
{"file": "data\\buffer\\cyclic.pd", "nl": "Wait for the entry at `addr` to be written and then read the value. The caller should ensure that this is not called for a free entry.", "code": "read_word_t read(addr_t addr /*< Element address.*/)\n    {\n        // Block if entry has not been written\n        wait(addr);\n\n        return nonblocking_read(addr);\n    }"}
{"file": "data\\buffer\\cyclic.pd", "nl": "Read the value at the specified address. This version of read does not block to wait for the entry to be written. It is also inline to reduce the cost of multiple callsites. The caller should ensure that the address is valid (written and not freed).", "code": "inline read_word_t nonblocking_read(addr_t addr /*< Element address.*/)\n    {\n        auto wordAddr = addr / WordSize;\n\n        // Check that read address has not been freed\n        sim_assert(wordAddr >= _freeAddr);\n        // Check that the read address has been written\n        // (Note: this assertion only checks the word from the first byte;\n        //  unaligned accesses can spill into the next word which may not have\n        //  been written)\n        sim_assert(_writeAddr > wordAddr);\n\n        // Read value from memory\n        return _cyclicBufferMem.read(addr % TotalSize);\n    }"}
{"file": "data\\buffer\\cyclic.pd", "nl": "Reset cyclic buffer. This is not thread-safe and should not be called while any other functions are running.", "code": "void reset()\n    {\n        _cyclicBuffer.reset();\n    }"}
{"file": "data\\buffer\\cyclic.pd", "nl": "Wait for a free entry and write one entry.", "code": "void write(T val)\n    {\n        _cyclicBuffer.write({val});\n    }"}
{"file": "data\\buffer\\cyclic.pd", "nl": "Free entries up to the specified address. Caller should ensure that  this address is valid.", "code": "void free(addr_t addr /*< Element address.*/)\n    {\n        _cyclicBuffer.free(addr);\n    }"}
{"file": "data\\buffer\\cyclic.pd", "nl": "Block until the passed address has been written to.", "code": "void wait(addr_t addr /*< Element address.*/)\n    {\n        _cyclicBuffer.wait(addr);\n    }"}
{"file": "data\\buffer\\cyclic.pd", "nl": "Wait for the entry at `addr` to be written and then read the value. The caller should ensure that this is not called for a free entry.", "code": "T read(addr_t addr /*< Element address.*/)\n    {\n        auto value = _cyclicBuffer.read(addr);\n        return value[0];\n    }"}
{"file": "data\\buffer\\cyclic.pd", "nl": "Read the value at the specified address. This version of read does not block to wait for the entry to be written. It is also inline to reduce the cost of multiple callsites. The caller should ensure that the address is valid (written and not freed).", "code": "inline T nonblocking_read(addr_t addr /*< Element address.*/)\n    {\n        auto value = _cyclicBuffer.nonblocking_read(addr);\n        return value[0];\n    }"}
{"file": "codec\\crypto\\aes.pd", "nl": "The output of this function is equivalent to Mult(X, Y). It uses Karatsuba's algorithm to perform this using 3 `HalfInputType x HalfInputType` Mults instead of 2 `InputType x InputType` Mults or 4 `HalfInputType x HalfInputType` Mults. `HalfInputType` is expected to be half the width of `InputType`. For more details: <https://en.wikipedia.org/wiki/Karatsuba_algorithm#Basic_step> From the above link, we have: z_2 = x_1 * y_1 z_0 = x_0 * y_0 z_1 = (x_0 - x_1) * (y_1 - y_0) + z_2 + z_0 x * y = z_2 << (bitsizeof(InputType)) + z_1 << (bitsizeof(HalfInputType)) + z_0 Template parameters `Mult`, `Add`, and `Sub` implement `*`, `+`, and `-` respectively.", "code": "template<typename OutputType,\n         typename InputType,\n         typename HalfInputType>\ninline OutputType karatsuba_mult(\n    (HalfInputType, HalfInputType) -> InputType Mult,\n    (OutputType, OutputType) -> OutputType Add,\n    (HalfInputType, HalfInputType) -> HalfInputType Sub,\n    InputType X,\n    InputType Y)\n{\n    const auto input_bits = bitsizeof(InputType);\n    const auto half_input_bits = bitsizeof(HalfInputType);\n    static assert(input_bits % 2 == 0 && input_bits / 2 == half_input_bits);\n\n    // Break inputs into two halves\n    HalfInputType x0 = cast<HalfInputType>(X);\n    HalfInputType x1 = cast<HalfInputType>(X >> half_input_bits);\n    HalfInputType y0 = cast<HalfInputType>(Y);\n    HalfInputType y1 = cast<HalfInputType>(Y >> half_input_bits);\n\n    // Multiplies\n    InputType z2 = Mult(x1, y1);\n    InputType z0 = Mult(x0, y0);\n    InputType z1 = Add(Add(Mult(Sub(x1, x0), Sub(y1, y0)), z0), z2);\n\n    OutputType result = Add(concat(z2, z0), z1 << half_input_bits);\n    return result;\n}"}
{"file": "codec\\crypto\\aes.pd", "nl": "Take in one or more plaintexts and return the encrypted ciphertexts. If `store_key` is true, then store and use the passed key. If `use_new_key` is true (but not `store_key`), then use the passed key but do not store it. If `store_key` and `use_new_key` are both false, use the stored key.", "code": "template<typename T>\n    T encrypt(T plaintext, bool use_new_key, bool store_key, key_t new_key)\n    {\n        static assert(bitsizeof(T) >= bitsizeof(text_t));\n        static assert(bitsizeof(T) % bitsizeof(text_t) == 0);\n        const auto N = bitsizeof(T) / bitsizeof(text_t);\n\n        // Save key\n        key_t snapped_key = new_key;\n        atomic\n        {\n            static key_t key;\n            if (store_key)\n            {\n                key = new_key;\n            }\n            if (!use_new_key && !store_key)\n            {\n                // Use stored key\n                snapped_key = key;\n            }\n        }\n\n        // Generate new round keys\n        auto expanded_keys = _expand_keys(snapped_key);\n        // Peform encryption\n        text_t[N] plaintext_array = cast<text_t[N]>(plaintext);\n        text_t[N] ciphertext;\n        static for (const auto i : N)\n        {\n            ciphertext[i] = _encrypt_with_expanded_keys(plaintext_array[i], expanded_keys);\n        }\n        return cast<T>(ciphertext);\n    }"}
{"file": "codec\\crypto\\aes.pd", "nl": "Take in one or more ciphertexts and return the decrypted plaintexts. If `store_key` is true, then store and use the passed key. If `use_new_key` is true (but not `store_key`), then use the passed key but do not store it. If `store_key` and `use_new_key` are both false, use the stored key.", "code": "template<typename T>\n    T decrypt(T ciphertext, bool use_new_key, bool store_key, key_t new_key)\n    {\n        static assert(bitsizeof(T) >= bitsizeof(text_t));\n        static assert(bitsizeof(T) % bitsizeof(text_t) == 0);\n        const auto N = bitsizeof(T) / bitsizeof(text_t);\n\n        key_t snapped_key = new_key;\n        atomic\n        {\n            static key_t key;\n            if (store_key)\n            {\n                key = new_key;\n            }\n            if (!use_new_key && !store_key)\n            {\n                // Use stored key\n                snapped_key = key;\n            }\n        }\n\n        // Generate new round keys\n        auto expanded_keys = _expand_keys(snapped_key);\n        // Perform decryption\n        text_t[N] ciphertext_array = cast<text_t[N]>(ciphertext);\n        text_t[N] plaintext;\n        static for (const auto i : N)\n        {\n            plaintext[i] = _decrypt_with_expanded_keys(ciphertext_array[i], expanded_keys);\n        }\n        return cast<T>(plaintext);\n    }"}
{"file": "codec\\crypto\\aes.pd", "nl": "AES encryption running in counter (CTR) mode. Inputs (keys, initialization vectors, and plaintexts) and outputs (ciphertexts) are interpreted as big endian. For example, for the string 0x0a0b0c0d, byte[0] = 0x0a and byte[3] = 0x0d. The initialization vector for encryption is a 96-bit user input that is concatenated with a 32-bit incrementing counter. The counter for the first plaintext is 2 to match the behavior of AES-GCM. // Concatenate counter and user supplied initialization vector to create initialization vector for encryption. Increment the counter for the next plaintext", "code": "iv_counter_t _get_and_increment_iv(bool initialize, iv_t new_iv)\n    {\n        iv_counter_t result;\n\n        atomic\n        {\n            static iv_t iv;\n            if (initialize)\n            {\n                iv = new_iv;\n            }\n            result.iv = iv;\n        }\n\n        atomic\n        {\n            static counter_t counter;\n            counter = initialize ? 1 : counter + 1;\n            result.counter = counter;\n        }\n\n        return result;\n    }"}
{"file": "codec\\crypto\\aes.pd", "nl": "If `key.is_valid` is true, then store the passed `key` and `iv` to use for  encryption. Return is 0. If `key.is_valid` is false, then encrypt the passed `plaintext` and return the ciphertext.", "code": "text_t run(text_t plaintext, optional<key_t> key, iv_t iv)\n    {\n        // Get initialization vector\n        text_t initialization_vector = cast<text_t>(_get_and_increment_iv(key.is_valid, iv));\n        // Encrypt initialization vector\n        text_t encrypted_iv = _aes_ecb.encrypt(initialization_vector, false, key.is_valid, key.value);\n        // XOR with plaintext\n        text_t ciphertext = plaintext ^ encrypted_iv;\n\n        return key.is_valid ? 0 : ciphertext;\n    }"}
{"file": "codec\\crypto\\aes.pd", "nl": "AES encryption running in Galois/Counter Mode (GCM). Inputs (keys, initialization vectors, and plaintexts) and outputs (ciphertexts) are interpreted as big endian. For example, for the string 0x0a0b0c0d, byte[0] = 0x0a and byte[3] = 0x0d. The implementation is based on the following NIST spec with a 256-bit encryption key: [NIST Special Publication 800-38D](https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-38d.pdf). AAD is not supported. The full plaintext length must be a multiple of 128 bits. When the template parameter Encrypt is true, plaintext is input and ciphertext is output. When Encrypt is false, ciphertext is input and plaintext is output. In both cases, the hash is calculated based on the ciphertext. This implementation is used for debugging purposes. It is functionally correct but does not produce performant hardware.", "code": "template<AES_GCM_CryptoMode Mode>\nclass AES_GCM_Functional\n{\nprivate:\n    AES_ECB _aes_ecb;\n    iv_t _iv;\n    counter_t _counter;\n    text_t _stored_hash;\n    text_t _hash_key; // H = E_k(0)\n    text_t _encrypted_iv0; // E_k(iv_0)\n    uint32 _aad_length; // bytes\n    uint32 _crypto_length; // bytes\n\n    // Concatenate counter and user supplied initialization vector to create\n    // initialization vector for encryption. Increment the counter for the next\n    // plaintext\n    inline text_t _get_and_increment_iv()\n    {\n        counter_t snapped_counter;\n        atomic\n        {\n            snapped_counter = _counter;\n            _counter++;\n        }\n\n        return concat(_iv, snapped_counter);\n    }\n\n    // Add (xor in Galois field) X and Y and then multiply by the hash key\n    inline text_t _gf_add_mult(text_t X, text_t Y)\n    {\n        text_t add = X ^ Y;\n        text_t key = _hash_key;\n        text_t mult = gf_mult(add, key);\n        return mult;\n    }\n\n    // Add the passed data to the stored hash and multiply by the hash key.\n    // Store the result back.\n    void _update_hash(text_t data)\n    {\n        // Update hash\n        atomic\n        {\n            text_t hash = _stored_hash;\n            hash = _gf_add_mult(hash, data);\n            _stored_hash = hash;\n        }\n    }\n\npublic:\n    void write_key(key_t key)\n    {\n        // Calculate hash key (encrypt 0)\n        _hash_key = _aes_ecb.encrypt(cast<text_t>(0), false, true, key);\n    }\n\n    void write_iv(iv_t iv)\n    {\n        _iv = iv;\n        _aad_length = 0;\n        _crypto_length = 0;\n        _counter = 1;\n        _stored_hash = 0;\n\n        // Store encrypted starting iv\n        text_t iv_counter = _get_and_increment_iv();\n        text_t encrypted_iv = _aes_ecb.encrypt(iv_counter, false, false, 0);\n        _encrypted_iv0 = encrypted_iv;\n    }"}
{"file": "codec\\crypto\\aes.pd", "nl": "Pass data for additional authenticated data (AAD) which updates the hash.", "code": "void authenticate\n( text_t data    \n, index_t<16> num_bytes //< Indicate the number of valid bytes. A value    \n                        // of 0 indicates that all 16 bytes are valid.    \n)\n{\n    _update_hash(mask_bytes(data, num_bytes));\n    atomic\n    {\n        _aad_length += (num_bytes == 0 ? 16 : num_bytes);\n    }\n}"}
{"file": "codec\\crypto\\aes.pd", "nl": "Run encryption/decryption on passed plaintext and update hash.", "code": "text_t crypto\n        ( text_t data\n        , index_t<16> num_bytes //< Indicate the number of valid bytes. A value\n                                // of 0 indicates that all 16 bytes are valid.\n        )\n    {\n        // Encrypt the IV counter\n        text_t iv_counter = _get_and_increment_iv();\n        auto encrypted_iv = _aes_ecb.encrypt(iv_counter, false, false, 0);\n        // Encrypt/decrypt data\n        text_t crypto_data = encrypted_iv ^ data;\n        // Mask invalid bytes\n        crypto_data = mask_bytes(crypto_data, num_bytes);\n        // Update hash with ciphertext\n        if (Mode == AES_GCM_CryptoMode::Encrypt)\n        {\n            _update_hash(crypto_data);\n        }\n        else\n        {\n            // In Decrypt mode, the input data is the ciphertext\n            _update_hash(mask_bytes(data, num_bytes));\n        }\n        atomic\n        {\n            _crypto_length += (num_bytes == 0 ? 16 : num_bytes);\n        }\n        return crypto_data;\n    }"}
{"file": "codec\\crypto\\aes.pd", "nl": "Finalize and return hash.", "code": "text_t read_hash()\n    {\n        text_t hash = _stored_hash;\n\n        // Include lengths in hash\n        text_t lengths = concat(cast<uint64>(_aad_length * 8), cast<uint64>(_crypto_length * 8));\n        hash = _gf_add_mult(hash, lengths);\n\n        // XOR with E_k(iv_0)\n        hash ^= _encrypted_iv0;\n\n        return hash;\n    }"}
{"file": "codec\\crypto\\aes.pd", "nl": "Input an expected hash and check that it matches the generated hash.", "code": "bool check_hash(text_t expected_hash)\n    {\n        auto generated_hash = read_hash();\n        return (generated_hash == expected_hash);\n    }"}
{"file": "codec\\crypto\\aes.pd", "nl": "AES encryption running in Galois/Counter Mode (GCM). Inputs (keys, initialization vectors, and plaintexts) and outputs (ciphertexts) are\n// interpreted as big endian. For example, for the string 0x0a0b0c0d,\n// byte[0] = 0x0a and byte[3] = 0x0d. The implementation is based on the\n// following NIST spec with a 256-bit encryption key:\n// [NIST Special Publication 800-38D](https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-38d.pdf).\n// AAD is not supported. The full plaintext length must be a multiple of 128\n// bits.\n// When the template parameter Encrypt is true, plaintext is input and\n// ciphertext is output. When Encrypt is false, ciphertext is input and\n// plaintext is output. In both cases, the hash is calculated based on the ciphertext. This implementation is used for debugging purposes. It is functionally correct but does not produce performant hardware.", "code": "template<AES_GCM_CryptoMode Mode>\nclass AES_GCM_Functional\n{\nprivate:\n    AES_ECB _aes_ecb;\n    iv_t _iv;\n    counter_t _counter;\n    text_t _stored_hash;\n    text_t _hash_key; // H = E_k(0)\n    text_t _encrypted_iv0; // E_k(iv_0)\n    uint32 _aad_length; // bytes\n    uint32 _crypto_length; // bytes\n    // Concatenate counter and user supplied initialization vector to create\n    // initialization vector for encryption. Increment the counter for the next\n    // plaintext\n    inline text_t _get_and_increment_iv()\n    {\n        counter_t snapped_counter;\n        atomic {\n            snapped_counter = _counter;\n            _counter++; }\n        return concat(_iv, snapped_counter); }"}
{"file": "codec\\crypto\\aes.pd", "nl": "Update stored hash. This is done in a 4-phase manner with 4 different hash accumulators. This allows the Galois field add and multiply to have a pipeline depth of 4 cycles. The aggregated hash is returned.", "code": "    text_t _update_hash(text_t data, text_t hash_key, bool[4] firsts){\n bool first4 = firsts[0] || firsts[1] || firsts[2] || firsts[3];\n // Advance hash phase\n index_t<4> snapped_hash_phase;\n atomic {\n     static index_t<4> hash_phase = 0;\n     snapped_hash_phase = hash_phase;\n     hash_phase = modular::increment(hash_phase); }\n// Decompose for Karatsuba multiplication\nuint128 Y = reverse(hash_key);\nuint64[3] y0 = karatsuba_decompose<uint64>(Y);\nuint32[3][3] y1;\nstatic for (const auto i : 3) {\n    y1[i] = karatsuba_decompose<uint32>(y0[i]); }\n// Calculate Galois field add and multiply\ntext_t prev_hash;\ntext_t new_hash;\n[[schedule(4)]] {\n    static text_t[4] stored_hash;\n     // First four inputs use a previous hash value of 0, otherwise read\n     // previous hash\n     prev_hash = first4 ? 0 : stored_hash[snapped_hash_phase];\n     // Add\n     new_hash = prev_hash ^ data;\n      // Decompose for Karatsuba multiplication\n      uint128 X = reverse(new_hash);\n     uint64[3] x0= karatsuba_decompose<uint64>(X);\n      uint32[3][3] x1;\n     static for (const auto i : 3) {\n          x1[i] = karatsuba_decompose<uint32>(x0[i]);\n      }\n      // Multiplication of decomposed terms\n      uint63[3][3] z1;\n      static for (const auto i : 3) {\n          static for (const auto j : 3)\n          {\n              z1[i][j] = carryless_mult<uint63, uint32>(x1[i][j], y1[i][j]);\n          }\n      }\n            // Combine terms\n      uint127[3] z0;\n      static for (const auto i : 3)\n      {\n          z0[i] = karatsuba_combine<uint127>(z1[i]);\n      }\n      uint255 Z = karatsuba_combine<uint255>(z0);\n      // Galois field reduction\n      new_hash = reverse(gf_reduce(cast<uint256>(Z)));\n      // Writeback hash\n      stored_hash[snapped_hash_phase] = new_hash;\n  }"}
{"file": "codec\\crypto\\aes.pd", "nl": "Recursively apply Karatsuba multiply RecurseDepth times and then use a carryless multiply.", "code": "template<auto RecurseDepth, typename OutputType, typename InputType>\ninline OutputType _recursive_karatsuba(\n    InputType X,\n    InputType Y) {\n    OutputType result;\n    static if (RecurseDepth == 0) {\n        // Use carryless multiplier\n        result = carryless_mult<OutputType, InputType>(X, Y);\n    }\n    else {\n        const auto input_bits = bitsizeof(InputType);\n        // Check for power-of-2 input bits\n        static assert((input_bits & (input_bits - 1)) == 0);\n        using HalfInputType = uint<input_bits / 2>;\n        // Use Karatsuba multiplier\n        result = karatsuba_mult<OutputType>(_recursive_karatsuba<RecurseDepth - 1, InputType, HalfInputType>, xor, xor, X, Y); }\n    return result; }"}
{"file": "tutorials\\complete\\histogram.pd", "nl": "Sets all elements of the histogram to 0", "code": "void clear_histogram()\n{\n    pipelined_for(bucket_count, [](sample_t i)\n    {\n        _histogram[i] = 0;\n    });\n}"}
{"file": "tutorials\\complete\\histogram.pd", "nl": "Computes a histogram (stored in the variable: _histogram) _histogram is a memory with 16 elements _histogram[i] is defined to be set to the number of input elements with value = i Input elements are stored as 4-wide vectors, but this first example does not do computation with vectors", "code": "void histogram_mutex()\n{\n    clear_histogram();\n    pipelined_for(batch_count, [](vector_index_t i)\n    {\n        batch_t batch = _batches[i];\n        pipelined_for_each(batch, [](index_t<vector_width> unused_index, sample_t sample)\n        {\n            static mutex _mutex;\n            _mutex.lock();\n            _histogram[sample] = _histogram[sample] + 1;\n            _mutex.unlock();\n        });\n    });\n}"}
{"file": "tutorials\\complete\\histogram.pd", "nl": "Compute a histogram, at a rate of vector_width (4) input elements per cycle. Feel free to add more member variables to this class to hold intermediate data", "code": "void histogram_vectorized()\n{\n    clear_histogram();\n    pipelined_for(bucket_count, [](sample_t i)\n    {\n        static for (const auto j : 4)\n        {\n            _partial_histograms[j][i] = 0;\n        }\n    });\n    pipelined_for(batch_count, [](vector_index_t i)\n    {\n        batch_t batch = _batches[i];\n        atomic\n        {\n            static for (const auto j : 4)\n            {\n                auto sample = batch[j];\n                _partial_histograms[j][sample] = _partial_histograms[j][sample] + 1;\n            }\n        }\n    });\n    pipelined_for(bucket_count, [](sample_t i)\n    {\n        uint32 sum = 0;\n        static for (const auto j : 4)\n        {\n            sum += _partial_histograms[j][i];\n        }\n        _histogram[i] = sum;\n    });\n}"}
{"file": "tutorials\\complete\\histogram.pd", "nl": "Compute a histogram, at a rate of 1 input element per cycle. Do not use a mutex.", "code": "void histogram_no_mutex()\n{\n    clear_histogram();\n    pipelined_for(batch_count, [](vector_index_t i)\n    {\n        batch_t batch = _batches[i];\n        pipelined_for_each(batch, [](index_t<vector_width> unused_index, sample_t sample)\n        {\n            atomic\n            {\n                _histogram[sample] = _histogram[sample] + 1;\n            }\n        });\n    });\n}"}
{"file": "text\\unicode.pd", "nl": "A single unicode code point.", "code": "using unicode_code_point_t = uint21;\ntemplate<typename T>\nstruct code_point_stream_to_int_context_impl\n{\n    uint<bitsizeof(T)> accumulator;\n    bool negative;\n    bool has_content;\n}"}
{"file": "text\\unicode.pd", "nl": "Context used by `code_point_stream_to_int`.", "code": "template<typename T>\nstruct code_point_stream_to_int_context\n{\n    //| The deserialized value.\n    T value;\n    //| True if an error has been encountered.\n    bool error;\n    //| Implementation details.\n    code_point_stream_to_int_context_impl<T> impl;}"}
{"file": "text\\unicode.pd", "nl": "Convert a series of unicode code points into an integer, 1 code point at a time. Note that the output context from 1 call must be passed as the input context to the next call. It is OK to wrap the entire call in an atomic block.", "code": "template<typename T>\ninline code_point_stream_to_int_context<T> code_point_stream_to_int\n    ( unicode_code_point_t code_point             //< Input code point.\n    , code_point_stream_to_int_context<T> context //< Used to return the result\n                                                  // and track deserialzation state.\n    , bool start                                  //< Set to true on the first\n                                                  // code point of a string.\n    )\n{\n    const bool is_dash = (code_point == 0x2D);\n    const bool is_digit = (code_point >= 0x30) && (code_point <= 0x39);\n\n    // 4 bits is enough to represent [0,10]\n    uint4 value = code_point - 0x30;\n\n    // reset context to initial values if necessary\n    code_point_stream_to_int_context<T> empty_context = {};\n    context = start ? empty_context : context;\n\n    // handle leading negative sign\n    if (is_dash)\n    {\n        if (context.impl.has_content)\n        {\n            // Dash detected anywhere but the first character\n            context.error = true;\n        }\n        else\n        {\n            context.impl.negative = true;\n        }\n    }\n    else if (is_digit)\n    {\n        // Shift the accumulator and add the new value in\n        const auto new_accumulator = (context.impl.accumulator * 10) + value;\n\n        // Narrowing cast back into the accumlator\n        const auto max_value = (1 << bitsizeof(T)) - 1;\n\n        context.impl.accumulator = cast<uint<bitsizeof(T)>>(new_accumulator);\n\n        if (new_accumulator > max_value)\n        {\n            context.error = true;\n        }\n    }\n    else\n    {\n        // Invalid character\n        context.error = true;\n    }\n\n    // Record that the first character has been seen\n    context.impl.has_content = true;\n\n    // Cast from accumulator to the return value\n    const auto max_value_before_invert = context.impl.negative ? (1 << (bitsizeof(T) - 1)) : (1 << (bitsizeof(T) - 1)) - 1;\n\n    if (context.impl.accumulator > max_value_before_invert)\n    {\n        context.error = true;\n    }\n\n    context.value = cast<decltype(context.value)>(context.impl.negative ? -context.impl.accumulator : context.impl.accumulator);\n\n    return context;\n}"}
{"file": "test\\internal\\assert.pd", "nl": "Fail test with the specified tag when the condition is false. Test failure triggers `sim_assert`, prints information about failing test, and sets global status to the test tag.", "code": "inline void assert(tag_t tag, bool cond)\n{\n    if (!cond)\n    {\n        print_failure(tag);\n        sim_assert(false);\n    }\n}"}
{"file": "test\\internal\\assert.pd", "nl": "Fail test with the specified tag when the condition is false. Test failure triggers `sim_assert`, prints information about failing test and the supplied message, and sets global status to the test tag.", "code": "inline void assert_string(tag_t tag, bool cond, const string message)\n{\n    if (!cond)\n    {\n        println(message);\n        print_failure(tag);\n        sim_assert(false);\n    }\n}"}
{"file": "test\\internal\\assert.pd", "nl": "Fail test with the specified tag when the arguments are not equal. Test failure triggers `sim_assert`, prints information about failing test, and sets global status to the test tag.", "code": "template <typename T, typename U>\ninline void assert_equal\n    ( tag_t tag     //< Test tag\n    , T expected    //< Expected value\n    , U actual      //< Actual value\n    )\n{\n    if (reinterpret_cast<uint<bitsizeof T>>(expected) != reinterpret_cast<uint<bitsizeof U>>(actual))\n    {\n        println(\"Expected:\", expected, \"actual:\", actual);\n        print_failure(tag);\n        sim_assert(false);\n    }\n}"}
{"file": "base\\system.pd", "nl": "Return cycle count.", "code": "inline uint64 cycles()\n{\n    return __cycles();\n}"}
{"file": "base\\system.pd", "nl": "Inject `N` stages into the generated hardware pipeline.", "code": "template <auto N>\ninline void stages()\n{\n    static assert(N >= 0);\n\n    static for (const auto i : N) barrier;\n}"}
{"file": "codec\\compression\\gzip.pd", "nl": "Reset state of lzcomp and gzcomp in preparation for compressing new data from scratch. See `gzcomp::reset` for further details on `updateInterval` and `reuseLastCode` arguments.", "code": "void reset(uint32 updateInterval, bool reuseLastCode)\n{\n    _mode = compressor_mode::DEFLATE;\n    _tokenBufferSize = 0;\n    _crc.compute(0, {}, 0, true);\n    _lzcomp.reset();\n    _gzcomp.reset(updateInterval, reuseLastCode);\n}"}
{"file": "codec\\compression\\gzip.pd", "nl": "Set operating mode to either DEFLATE-only or TRAIN_THEN_DEFLATE which pushes uncompressed data through lzcomp then both saving this result into `_tokenBuffer` as well as pushing it straight into gzcomp for `TRAIN`-ing the optimal Huffman code. Once the `_tokenBuffer` is full, the same data is re-sent to gzcomp this time in `DEFLATE` mode, using the optimal Huffman code computed in the first pass. `TRAIN_THEN_DEFLATE` is only supported if the `EnableTraining` template argument is true..", "code": "inline void set_mode(compressor_mode mode)\n{\n    if (EnableTraining)\n        _mode = mode;\n    else\n        sim_assert(mode == compressor_mode::DEFLATE);\n}"}
{"file": "codec\\compression\\gzip.pd", "nl": "Set the maximum number of times that lzcomp will stall in order to attempt to find a longer reference.", "code": "inline void set_max_stall_count(count_t<MaxStallCount == 0 ? 1 : MaxStallCount> maxStallCount)\n{\n    _lzcomp.set_max_stall_count(maxStallCount);\n}"}
{"file": "codec\\compression\\gzip.pd", "nl": "Accept up to Width bytes of uncompressed data for compression. It is illegal to call `push` with `size < Width` unless `last` is set. The `last` argument causes the compressor to terminate the GZIP member after processing the current word and flush the result via `WriteCallback` with its last argument also set.", "code": "template<(tokens_t, count_t<Width>, bool)->void LzToGzCallback,\n         (PrioritizeDictCallbackInput_t) -> PrioritizeDictCallbackOutput_t PrioritizeDictCallback,\n         (ChooseMatchCallbackInput_t) -> ChooseMatchCallbackOutput_t ChooseMatchCallback>\nvoid push(uint8[Width] word, count_t<Width> size, [[last]] bool last)\n{\n    _crc32 = _crc.compute(0, word, size, false);\n    _lzcomp.push<LzToGzCallback, PrioritizeDictCallback, ChooseMatchCallback>(word, size, last);\n}"}
{"file": "codec\\compression\\gzip.pd", "nl": " //| This method is the bridge between lzcomp (substring compression into tokens) and gzcomp (token compression) and forms lzcomp's `WriteCallback` template argument to be invoked every time it has accumulated `Width` tokens. In `DEFLATE` mode, this function spawns a single thread for every `Width` tokens within which these tokens are passed onto gzcomp, spawning an extra thread on the last callback to handle flushing duties. In `TRAIN_THEN_DEFLATE` mode, this function also spawns a single thread for every Width tokens that is not just passed onto gzcomp(for `TRAIN`-ing) but also accumulated inside `_tokenBuffer`. Once `TokenBufferDepth * Width` tokens have been accumulated or the `last` argument is set, enough additional threads are spawned to drain the `_tokenBuffer` over a second `DEFLATE` pass. Currently, a compiler limitation requires that template arguments be non-method functions, thus it is not possible to pass this method as lzcomp's `WriteCallback` argument. As a workaround, it is beholden on the user to create and pass a global function, inside of which simply calls this method, as a template argument to `push`. ", "code": "void lz_to_gz(tokens_t data, count_t<Width> size, bool last)\n{\n    if (!last)\n        sim_assert(size == Width);\n    else if (size == 0)\n        sim_assert(last);\n\n    index_t<TokenBufferDepth> snappedTokenBufferDepth;\n    bool tokenBufferFull;\n    count_t<TokenBufferDepth + 3> numThreads = 1;\n\n    if (_mode == compressor_mode::TRAIN_THEN_DEFLATE)\n    {\n        atomic\n        {\n            snappedTokenBufferDepth = _tokenBufferSize;\n            tokenBufferFull = (snappedTokenBufferDepth == TokenBufferDepth - 1);\n            _tokenBufferSize = (tokenBufferFull || last ? 0 : snappedTokenBufferDepth + 1);\n        }\n\n        if (tokenBufferFull || last)\n        {\n            numThreads += cast<uint1>(size != 0) + (snappedTokenBufferDepth + cast<uint1>(size != 0));\n        }\n    }\n    else\n    {\n        sim_assert(_mode == compressor_mode::DEFLATE);\n    }\n\n    count_t<TokenBufferDepth + 3> lastTid = numThreads;\n    if (tokenBufferFull || last)\n    {\n        if (size == 0 && (_mode == compressor_mode::DEFLATE || (_mode == compressor_mode::TRAIN_THEN_DEFLATE && snappedTokenBufferDepth == 0)))\n        {\n            sim_assert(numThreads == 1);\n            lastTid = 0;\n        }\n        else\n        {\n            numThreads++;\n        }\n    }\n    lz_to_gz_pipeline(numThreads, data, size, last, snappedTokenBufferDepth, lastTid);\n}"}
{"file": "tutorials\\complete\\harness.pd", "code": "inline void run_scalar_test(()->T test_fn, T expected, const string name)\n{\nconst uint64 start_cycle = cycles();\nconst T actual = test_fn();\nconst uint64 total_cycles = cycles() - start_cycle;\n\nprintln(\"Test:\", name, \"Cycles:\", total_cycles);\n\nif (actual != expected)\n{\nprintln(\"Incorrect result returned.  Actual:\", actual, \"expected:\", expected);\n}\n}"}
{"file": "tutorials\\complete\\harness.pd", "code": "inline void run_vector_test(()->void test_fn, (index_t<result_count>)->T actual_fn, (index_t<result_count>)->T expected_fn, const string name)\n{\nconst uint64 start_cycle = cycles();\n\n// Execute the test\ntest_fn();\n\nconst uint64 total_cycles = cycles() - start_cycle;\n\nprintln(\"Test:\", name, \"Cycles:\", total_cycles);\n\n// Check return values\npipelined_for(result_count, [actual_fn, expected_fn](index_t<result_count> i)\n{\nT actual = actual_fn(i);\nT expected = expected_fn(i);\n\nif (actual != expected)\n{\nprintln(\"Incorrect result returned for element:\", i, \"actual:\", actual, \"expected:\", expected);\n}\n});\n}"}
{"file": "test\\internal\\status.pd", "nl": "Copyright (c), Microsoft Corporation. All rights reserved.", "code": "tag_t update_status(optional<tag_t> new)\n{\n    return second(atomically([new](tag_t old)\n    {\n        sim_assert(!(new.is_valid && new.value.unwrap == 0));\n        return new.is_valid ? new.value : old;\n    }));\n}"}
{"file": "test\\internal\\status.pd", "nl": "Return global test status. Any value other than 0 indicates a test failure", "code": "tag_t update_status(optional<tag_t> new) {\n    return second(atomically([new](tag_t old) {\n        sim_assert(!(new.is_valid && new.value.unwrap == 0));\n        return new.is_valid ? new.value : old;}));}inline auto status()\n{\n    return unwrap_newtype(update_status({}));\n}"}
{"file": "test\\internal\\status.pd", "nl": "Record global test status. The first call with value other an zero sets the global test status", "code": "inline void set_status(tag_t tag)\n{\n    update_status({true, tag});\n}"}
{"file": "processor\\risc_v\\trace.pd", "nl": "Print hexadecimal integer", "code": "inline void print_hex(auto n)\n{\n    const auto digits = (3 + bitsizeof n) / 4;\n\n    static for(const auto i : digits)\n    {\n        const auto digit = cast<index_t<16>>(n >> (4 * (digits - i - 1)));\n\n        switch (digit)\n        {\n            case 0x0: print(\"0\"); break;\n            case 0x1: print(\"1\"); break;\n            case 0x2: print(\"2\"); break;\n            case 0x3: print(\"3\"); break;\n            case 0x4: print(\"4\"); break;\n            case 0x5: print(\"5\"); break;\n            case 0x6: print(\"6\"); break;\n            case 0x7: print(\"7\"); break;\n            case 0x8: print(\"8\"); break;\n            case 0x9: print(\"9\"); break;\n            case 0xa: print(\"a\"); break;\n            case 0xb: print(\"b\"); break;\n            case 0xc: print(\"c\"); break;\n            case 0xd: print(\"d\"); break;\n            case 0xe: print(\"e\"); break;\n            case 0xf: print(\"f\"); break;\n        }\n    }\n}"}
{"file": "processor\\risc_v\\trace.pd", "nl": "Print instruction mnemonic", "code": "inline void print_instr( Instruction instr //< Disassembled instruction mnemonic, usually returned by `disasm`){switch (instr)\n    {\n        case Instruction::LUI:       print(\"lui\"); break;\n        case Instruction::AUIPC:     print(\"auipc\"); break;\n        case Instruction::JAL:       print(\"jal\"); break;\n        case Instruction::JALR:      print(\"jalr\"); break;\n        case Instruction::BEQ:       print(\"beq\"); break;\n        case Instruction::BNE:       print(\"bne\"); break;\n        case Instruction::BLT:       print(\"blt\"); break;\n        case Instruction::BGE:       print(\"bge\"); break;\n        case Instruction::BLTU:      print(\"bltu\"); break;\n        case Instruction::BGEU:      print(\"bgeu\"); break;\n        case Instruction::LB:        print(\"lb\"); break;\n        case Instruction::LH:        print(\"lh\"); break;\n        case Instruction::LW:        print(\"lw\"); break;\n        case Instruction::LBU:       print(\"lbu\"); break;\n        case Instruction::LHU:       print(\"lhu\"); break;\n        case Instruction::SB:        print(\"sb\"); break;\n        case Instruction::SH:        print(\"sh\"); break;\n        case Instruction::SW:        print(\"sw\"); break;\n        case Instruction::ADDI:      print(\"addi\"); break;\n        case Instruction::SLTI:      print(\"slti\"); break;\n        case Instruction::SLTIU:     print(\"sltiu\"); break;\n        case Instruction::XORI:      print(\"xori\"); break;\n        case Instruction::ORI:       print(\"ori\"); break;\n        case Instruction::ANDI:      print(\"andi\"); break;\n        case Instruction::SLLI:      print(\"slli\"); break;\n        case Instruction::SRLI:      print(\"srli\"); break;\n        case Instruction::SRAI:      print(\"srai\"); break;\n        case Instruction::ADD:       print(\"add\"); break;\n        case Instruction::SUB:       print(\"sub\"); break;\n        case Instruction::SLL:       print(\"sll\"); break;\n        case Instruction::SLT:       print(\"slt\"); break;\n        case Instruction::SLTU:      print(\"sltu\"); break;\n        case Instruction::XOR:       print(\"xor\"); break;\n        case Instruction::SRL:       print(\"srl\"); break;\n        case Instruction::SRA:       print(\"sra\"); break;\n        case Instruction::OR:        print(\"or\"); break;\n        case Instruction::AND:       print(\"and\"); break;\n        case Instruction::FENCE:     print(\"fence\"); break;\n        case Instruction::ECALL:     print(\"ecall\"); break;\n        case Instruction::EBREAK:    print(\"ebreak\"); break;\n        case Instruction::MUL:       print(\"mul\"); break;\n        case Instruction::MULH:      print(\"mulh\"); break;\n        case Instruction::MULHSU:    print(\"mulhsu\"); break;\n        case Instruction::MULHU:     print(\"mulhu\"); break;\n        case Instruction::CSRR:      print(\"csrr\"); break;\n        case Instruction::RDCYCLE:   print(\"rdcycle\"); break;\n        case Instruction::RDCYCLEH:  print(\"rdcycleh\"); break;\n        case Instruction::RDTIME:    print(\"rdtime\"); break;\n        case Instruction::RDTIMEH:   print(\"rdtimeh\"); break;\n        case Instruction::RDINSTRET: print(\"rdinstret\"); break;\n        case Instruction::RET:       print(\"ret\"); break;\n        case Instruction::J:         print(\"j\"); break;\n        case Instruction::JR:        print(\"jr\"); break;\n        case Instruction::LI:        print(\"li\"); break;\n        case Instruction::NOP:       print(\"nop\"); break;\n        case Instruction::MV:        print(\"mv\"); break;\n        case Instruction::UNKNOWN:   print(\"unknown\"); break;\n    }"}
{"file": "processor\\risc_v\\trace.pd", "nl": "Print register name", "code": "inline void print_reg(Reg reg)\n{\n    static assert (bitsizeof reg == bitsizeof ABI);\n\n    switch (cast<ABI>(reg))\n    {\n        case ABI::zero: print(\"zero\"); break;\n        case ABI::ra:   print(\"ra\"); break;\n        case ABI::sp:   print(\"sp\"); break;\n        case ABI::gp:   print(\"gp\"); break;\n        case ABI::tp:   print(\"tp\"); break;\n        case ABI::t0:   print(\"t0\"); break;\n        case ABI::t1:   print(\"t1\"); break;\n        case ABI::t2:   print(\"t2\"); break;\n        case ABI::s0:   print(\"s0\"); break;\n        case ABI::s1:   print(\"s1\"); break;\n        case ABI::a0:   print(\"a0\"); break;\n        case ABI::a1:   print(\"a1\"); break;\n        case ABI::a2:   print(\"a2\"); break;\n        case ABI::a3:   print(\"a3\"); break;\n        case ABI::a4:   print(\"a4\"); break;\n        case ABI::a5:   print(\"a5\"); break;\n        case ABI::a6:   print(\"a6\"); break;\n        case ABI::a7:   print(\"a7\"); break;\n        case ABI::s2:   print(\"s2\"); break;\n        case ABI::s3:   print(\"s3\"); break;\n        case ABI::s4:   print(\"s4\"); break;\n        case ABI::s5:   print(\"s5\"); break;\n        case ABI::s6:   print(\"s6\"); break;\n        case ABI::s7:   print(\"s7\"); break;\n        case ABI::s8:   print(\"s8\"); break;\n        case ABI::s9:   print(\"s9\"); break;\n        case ABI::s10:  print(\"s10\"); break;\n        case ABI::s11:  print(\"s11\"); break;\n        case ABI::t3:   print(\"t3\"); break;\n        case ABI::t4:   print(\"t4\"); break;\n        case ABI::t5:   print(\"t5\"); break;\n        case ABI::t6:   print(\"t6\"); break;\n    }\n}"}
{"file": "processor\\risc_v\\trace.pd", "nl": "Print disassembled instruction", "code": "inline void print_disasm(uint32 addr, uint32 binary, Decoded decoded)\n{\n    const auto instr = disasm(decoded);\n    const auto format = disasm_format(instr);\n\n    if (instr != Instruction::UNKNOWN)\n    {\n        print_instr(instr);\n        print(\"\\t\");\n    }\n    else\n    {\n        print(\"0x\");\n        print_hex(binary);\n    }\n\n    switch (format)\n    {\n        case DisasmFormat::rd:\n            print_reg(decoded.format.rd.value);\n            break;\n        case DisasmFormat::rd_imm:\n            print_reg(decoded.format.rd.value);\n            print(\",\");\n            print_imm(decoded.format.imm);\n            break;\n        case DisasmFormat::rd_csr:\n            print_reg(decoded.format.rd.value);\n            print(\",\");\n            switch (cast<uint12>(decoded.format.imm))\n            {\n                case 0xF14:\n                    print(\"mhartid\");\n                    break;\n\n                default:\n                    print_imm(cast<uint12>(decoded.format.imm));\n                    break;\n            }\n            break;\n        case DisasmFormat::rd_upper_imm:\n            print_reg(decoded.format.rd.value);\n            print(\",\");\n            print_imm(decoded.format.imm >> 12);\n            break;\n        case DisasmFormat::rd_imm_pc:\n            print_reg(decoded.format.rd.value);\n            print(\",\");\n            print(addr + decoded.format.imm);\n            break;\n        case DisasmFormat::imm_pc:\n            print(addr + decoded.format.imm);\n            break;\n        case DisasmFormat::rd_rs1_rs2:\n            print_reg(decoded.format.rd.value);\n            print(\",\");\n            print_reg(decoded.format.rs1.value);\n            print(\",\");\n            print_reg(decoded.format.rs2.value);\n            break;\n        case DisasmFormat::rd_rs1:\n            print_reg(decoded.format.rd.value);\n            print(\",\");\n            print_reg(decoded.format.rs1.value);\n            break;\n        case DisasmFormat::rd_rs1_imm:\n            print_reg(decoded.format.rd.value);\n            print(\",\");\n            print_reg(decoded.format.rs1.value);\n            print(\",\");\n            print_imm(decoded.format.imm);\n            break;\n        case DisasmFormat::rd_imm_rs1:\n            print_reg(decoded.format.rd.value);\n            print(\",\");\n            print_imm(decoded.format.imm);\n            print(\"(\");\n            print_reg(decoded.format.rs1.value);\n            print(\")\");\n            break;\n        case DisasmFormat::rs1:\n            print_reg(decoded.format.rs1.value);\n            break;\n        case DisasmFormat::rs1_rs2_imm:\n            print_reg(decoded.format.rs1.value);\n            print(\",\");\n            print_reg(decoded.format.rs2.value);\n            print(\",\");\n            print(addr + decoded.format.imm);\n            break;\n        case DisasmFormat::rs2_imm_rs1:\n            print_reg(decoded.format.rs2.value);\n            print(\",\");\n            print_imm(decoded.format.imm);\n            print(\"(\");\n            print_reg(decoded.format.rs1.value);\n            print(\")\");\n            break;\n    }\n}"}
{"file": "processor\\risc_v\\trace.pd", "nl": "Print dynamic instruction trace. Can be used as `trace` handler.", "code": "inline void print_trace(auto hid, auto pc, auto instr, Decoded decoded, optional<int32> value)\n{\n    atomic\n    {\n        print(hid, \"0x\");\n        print_hex(cast<uint32>(pc << 2));\n        print(\":\\t\");\n        print_hex(instr);\n        print(\"\\t\");\n        print_disasm(cast<uint32>(pc << 2), instr, decoded);\n        if (value.is_valid)\n        {\n            if (decoded.format.rd.is_valid)\n            {\n                print(\"\\t\");\n                print_reg(decoded.format.rd.value);\n                print(\" <-\", value.value);\n            }\n            else if (decoded.store)\n            {\n                print(\"\\tmem <-\", value.value);\n            }\n        }\n        print(\"\\n\");\n    }\n}"}
{"file": "processor\\risc_v\\trace.pd", "nl": "Print a diagram of memory map. Usually this function is called indirectly via `print_memory_map` method of `RISC_V` class which passes appropriate template arguments.", "code": "inline void print_memory_map()\n{\n    const auto IMEM_ORIGIN = IMEM_ORIGIN_WORDS << 2;\n    const auto IMEM_LENGTH = IMEM_LENGTH_WORDS << 2;\n    const auto IMEM_TCM_SIZE = IMEM_TCM_SIZE_WORDS << 2;\n\n    sort<IMEM_ORIGIN, DMEM_ORIGIN, MMIO_ORIGIN>(\n        [](optional<uint32> next)\n        {\n            static if (IMEM_TCM_SIZE != IMEM_LENGTH)\n            {\n                box(IMEM_ORIGIN, IMEM_TCM_SIZE, {true, IMEM_ORIGIN + IMEM_TCM_SIZE}, \"IMEM TCM\");\n                box(IMEM_ORIGIN + IMEM_TCM_SIZE, IMEM_LENGTH - IMEM_TCM_SIZE, next, \"IMEM EXT\");\n            }\n            else\n            {\n                box(IMEM_ORIGIN, IMEM_LENGTH, next, \"  IMEM  \");\n            }\n        },\n        [](optional<uint32> next)\n        {\n            box(DMEM_ORIGIN, DMEM_LENGTH, next, \"  DMEM  \");\n        },\n        [](optional<uint32> next)\n        {\n            box(MMIO_ORIGIN, MMIO_LENGTH, next, \"  MMIO  \");\n        });\n}"}
{"file": "text\\nfa.pd", "nl": "Process up to `InputWidth` more inputs. Returns the state of the NFA after processing those inputs.", "code": "state_t advance( vector<T, InputWidth> input           //< Inputs.\n, optional<state_t> initial_state       //< If valid, then the state to start from.  If invalid, then the state from the previous call is used.\n, index_t<TableDepth> table_base_addr   //< Base address in the table which describes the NFA.\n                                        // This is useful for the case when multiple NFAs are stored in the table concurrently.\n                                        // For example, the table could have storage for two NFAs, one of which is currently read during input processing,\n                                        // concurrent with the other NFA is being written.){sim_assert(input.size > 0);\n\n        // Read from the table to determine how input\n        // affects NFA state (current state is unknown at this point)\n        table_element_t[InputWidth] table_elements = map_indices([table_base_addr, input](index_t<InputWidth> i)\n        {\n            auto table_index = checked_cast<index_t<TableDepth>>(table_base_addr + input.data[i]);\n\n            table_element_t table_element = _table[table_index];\n\n            // Assert that parameters are respected\n            static for (const auto state_index : StateCount)\n            {\n                out_edges_t edges = table_element[state_index];\n\n                sim_assert(edges.size <= MaxOutDegree);\n\n                sim_assert(V::all([state_index](vertex_t dest_state)\n                {\n                    return dest_state < state_index ? (state_index - dest_state) <= MaxBackwardJump\n                                                    : (dest_state - state_index) <= MaxForwardJump;\n                },\n                edges));\n            }\n\n            return table_element;\n        });"}
{"file": "text\\nfa.pd", "nl": "Write one element to the NFA data.", "code": "void write_table( index_t<TableDepth> addr  //< The address of the element to write.\n, table_element_t element   //< The element to write.\n) {\n    sim_assert(addr < TableDepth);\n    _table[addr] = element;}"}
{"file": "numeric\\int\\divider\\signed.pd", "nl": "Calculate the quotient and remainder by dividing signed integers. The return value is an array with the first element being the quotient and the second element being the remainder.", "code": "template< typename NumeratorType, typename DenominatorType    \n, auto UnrollingFactor     //< Chunks of numerator bits of this size are processed in parallel,    \n                           // meaning the outer loop only has to execute    \n                           // `bitsizeof(NumeratorType)/UnrollingFactor` iterations.    \n>\ninline NumeratorType[2] divide(NumeratorType numerator, DenominatorType denominator)\n{sim_assert(denominator != 0);\n\n    const auto NumeratorWidth = bitsizeof(NumeratorType);\n    const auto DenominatorWidth = bitsizeof(NumeratorType);\n\n    bool num_is_neg = numerator < 0;\n    bool denom_is_neg = denominator < 0;\n\n    uint<NumeratorWidth> num_abs = num_is_neg ? -numerator : numerator;\n    uint<DenominatorWidth> denom_abs = denom_is_neg ? -denominator : denominator;\n\n    auto result = cast<NumeratorType[2]>(U::divide<uint<NumeratorWidth>, uint<DenominatorWidth>, UnrollingFactor>(num_abs, denom_abs));\n\n    if (num_is_neg != denom_is_neg)\n    {\n        result[0] = cast<NumeratorType>(-result[0]);\n    }\nif (num_is_neg) {\n    result[1] = cast<NumeratorType>(-result[1]); }\nreturn result;}"}
{"file": "data\\closure\\core.pd", "nl": "Type representing closure", "code": "template <typename FunctionType, FunctionType fn, typename Capture>\nstruct Closure\n{\n    Capture capture;\n}"}
{"file": "data\\closure\\core.pd", "nl": "Create a closure", "code": "template <typename FunctionType, FunctionType fn, typename Capture>\ninline Closure<FunctionType, fn, Capture> make_closure(Capture capture)\n{\n    return {capture};\n}"}
{"file": "data\\buffer\\packet_reorderer.pd", "nl": "A front-end queue for packet reordering. It provides an enqueue function to keep track of related metadata. This class itself does not store flits but should be called every time a new flit is enqueued into a buffer (e.g. FIFO) alongside this module. The stored metadata are used by `packet_reorderer_back` to properly read out and reorder packets.", "code": "template\n    < auto METADATA_MEM_DEPTH //< Size of the internal table for tracking\n                              // packet metadata.>\nclass packet_reorderer_front {\nprivate:\n    using addr_t = index_t<METADATA_MEM_DEPTH>;\n    memory<packet_reorderer_metadata_entry_t, METADATA_MEM_DEPTH> _metadata_mem;\n    addr_t _write_addr;\n    addr_t _read_addr;\n    uint32 _current_flits_written;\n    semaphore<METADATA_MEM_DEPTH, METADATA_MEM_DEPTH, true> _write_semaphore;\npublic:\n    //| Reset object to initial state. This should only be called when\n    // no packets are in flight.\n    void reset() {\n        sim_assert(_write_semaphore.count() == METADATA_MEM_DEPTH);\n        _write_addr = 0;\n        _read_addr = 0;\n        _current_flits_written = 0;\n        // Invalidate metadata entries\n        reset_memory(METADATA_MEM_DEPTH);\n    }"}
{"file": "data\\buffer\\packet_reorderer.pd", "nl": "Pipelined function to invalidate metadata memory. It should be called with `METADATA_MEM_DEPTH` threads.", "code": "[[pipelined]] void reset_memory(uint32 thread_index) {\n    packet_reorderer_metadata_entry_t invalid_metadata;\n    invalid_metadata.valid = false;\n    _metadata_mem[thread_index] = invalid_metadata;}"}
{"file": "data\\buffer\\packet_reorderer.pd", "nl": "Enqueue a flit to channel `input_index`. The caller must also specify some metadata about the flit.", "code": "void enqueue\n      ( uint32 packet_number //< An ID for the packet used for reordering.\n                              // These must be sequential starting at 0.\n       , bool end_of_packet   //< Last flit of the packet.\n       ) {\n       // Track number of flits written for this packet\n        uint32 flits_written;\n        atomic {\n           _current_flits_written++;\n           flits_written = _current_flits_written;\n            // Reset for next packet\n            if (end_of_packet) {\n                _current_flits_written = 0; } }\n        // Create metadata entry\n        packet_reorderer_metadata_entry_t entry;\n        entry.packet_number = packet_number;\n        entry.flits_written = flits_written;\n        entry.write_done = end_of_packet;\n        entry.valid = true;\n        // Write to metadata memory\n        _metadata_mem[_write_addr] = entry;\n        // If end of packet, advance write pointer\n        if (end_of_packet)\n        {\n            _write_addr = modular::increment(_write_addr);\n            // Block overwriting metadata that has not been read\n            _write_semaphore.wait();\n        }\n    }"}
{"file": "data\\buffer\\packet_reorderer.pd", "nl": "Read one entry from the metadata table.", "code": "packet_reorderer_metadata_entry_t read_metadata()\n    {\n        return _metadata_mem[_read_addr];\n    }"}
{"file": "data\\buffer\\packet_reorderer.pd", "nl": "Increment metadata table read pointer.", "code": "void increment_read_addr()\n    {\n        _read_addr = modular::increment(_read_addr);\n        _write_semaphore.post();\n    }"}
{"file": "data\\buffer\\packet_reorderer.pd", "nl": "Reset to initial state. Start `_transfer_loop` if this is the first call. This should only be called when no packets are in flight.", "code": "void reset()\n    {\n        // map-reduce functions use uint8 for index\n        sim_assert(clog2(NUM_INPUTS) <= 8);\n\n        _reset_flag = true;\n\n        if (!_initializer.check())\n        {\n            _transfer_loop();\n        }\n\n        wait_for(!_reset_flag);\n    }"}
{"file": "data\\buffer\\packet_reorderer.pd", "nl": "Read out one (reordered) flit.", "code": "T dequeue()\n    {\n        return _fifo.dequeue();\n    }"}
{"file": "data\\buffer\\packet_reorderer.pd", "nl": "// Function: map_fn// Map function used by map_reduce in back", "code": "inline map_result_t map_fn(map_input_t x){\n    map_result_t output;\n    // Find if this input has the correct packet number\n    output.found = (x.packet_number == x.curr_packet + x.schedule_i && x.valid);\n    output.done = x.write_done;\n    output.input_index = x.input_index;\n    return output;\n}"}
{"file": "data\\buffer\\packet_reorderer.pd", "nl": "Function: reduce_fn// Reduce function used by map_reduce in back", "code": "inline map_result_t reduce_fn(map_result_t x, map_result_t y){\n    map_result_t output;\n    // Propagate the input_index and done flag based on where the match is found\n    output.done = x.found ? x.done : y.done;\n    output.input_index = x.found ? x.input_index : y.input_index;\n    output.found = x.found || y.found;\n    return output;\n}"}
{"file": "data\\buffer\\packet_reorderer.pd", "nl": "// Function: done_reduce_fn// Reduce function for finding done schedule entries. Each iteration// returns the number of leading done entries and whether all entries// captured by the reduce node are done.", "code": "inline done_t done_reduce_fn(done_t x, done_t y){\n    done_t output;\n    if (x.full)\n    {\n        // Add the number of done entries from y to x\n        output.count = x.count + y.count;\n    }\n    else {\n        // x is not full so cannot take entries from y\n        output.count = x.count; }\n    // Output is only full if both x and y are full\n    output.full = x.full && y.full;\n    return output;}"}
{"file": "data\\buffer\\packet_reorderer.pd", "nl": "// Function: _create_schedule. Use metadata information from frontends to create a schedule of the next inputs and number of flits from each to read into the output fifo.", "code": "schedule_t _create_schedule()\n{\n    packet_reorderer_metadata_entry_t[NUM_INPUTS] entries = ReadMetadataFn();\n    uint32[NUM_INPUTS] flits_left;\n    static for (const auto i : NUM_INPUTS)\n    {\n        sim_assert(entries[i].flits_written >= _flits_read[i]);\n        flits_left[i] = entries[i].flits_written - _flits_read[i];\n    }\n\n    map_result_t[SCHEDULE_WIDTH] search_results;\n    static for (const auto schedule_i : SCHEDULE_WIDTH)\n    {\n        map_input_t[NUM_INPUTS] map_input;\n        static for (const auto i : NUM_INPUTS)\n        {\n            map_input[i].input_index = i;\n            map_input[i].curr_packet = _curr_packet;\n            map_input[i].schedule_i = schedule_i;\n            map_input[i].packet_number = entries[i].packet_number;\n            map_input[i].write_done = entries[i].write_done;\n            map_input[i].valid = entries[i].valid;\n        }\n        search_results[schedule_i] = map_reduce(map_fn, reduce_fn, map_input);\n    }\n\n    schedule_t schedule;\n    static for (const auto i : SCHEDULE_WIDTH)\n    {\n        input_index_t input_index = search_results[i].input_index;\n        schedule[i].input_index = input_index;\n        schedule[i].num_flits = flits_left[input_index];\n        schedule[i].valid = search_results[i].found;\n    }\n\n    done_t[SCHEDULE_WIDTH] done_input;\n    static for (const auto i : SCHEDULE_WIDTH)\n    {\n        done_input[i].full = schedule[i].valid && search_results[i].done;\n        done_input[i].count = done_input[i].full ? 1 : 0;\n    }\n\n    done_t done_entries = reduce(done_reduce_fn, done_input);\n\n    static for (const auto i : SCHEDULE_WIDTH)\n    {\n        if (i < done_entries.count)\n        {\n            schedule[i].valid = true;\n        }\n        else if (i > done_entries.count)\n        {\n            schedule[i].valid = false;\n        }\n    }\n\n    bool[NUM_INPUTS] inc_read_addr_valids;\n    static for (const auto i : NUM_INPUTS)\n    {\n        inc_read_addr_valids[i] = false;\n        if (entries[i].valid)\n        {\n            if (cast<uint32>(entries[i].packet_number - _curr_packet) < done_entries.count)\n            {\n                _flits_read[i] = 0;\n                inc_read_addr_valids[i] = true;\n            }\n            else if (entries[i].packet_number - _curr_packet == done_entries.count && done_entries.count < SCHEDULE_WIDTH && schedule[done_entries.count].valid)\n            {\n                _flits_read[i] += flits_left[i];\n            }\n        }\n    }\n    IncReadAddrFn(inc_read_addr_valids);\n    _curr_packet += done_entries.count;\n    return schedule;\n}"}
{"file": "data\\buffer\\packet_reorderer.pd", "nl": "// Function: _execute_schedule. Pipelined function to execute the passed schedule. Each thread handles one schedule entry. With a full schedule, this should be called with SCHEDULE_WIDTH threads.", "code": "[[pipelined]] void _execute_schedule(uint32 thread_index, schedule_t schedule){\n    schedule_entry_t schedule_entry = schedule[thread_index];\n    if (schedule_entry.valid) {\n        _transfer_flits(schedule_entry.num_flits, schedule_entry.input_index);\n    }\n}"}
{"file": "data\\buffer\\packet_reorderer.pd", "nl": "Function: _transfer_flits// Pipelined function to transfer one flit from frontend [input_index] to output FIFO", "code": "[[pipelined]] void _transfer_flits(uint32 thread_index, input_index_t input_index) {\n    T entry = DequeueFn(input_index);\n    _fifo.enqueue(entry);\n}"}
{"file": "data\\buffer\\packet_reorderer.pd", "nl": "// Function: _transfer_loop// Infinite loop to create schedule and transfer flits from frontends to output FIFO", "code": " [[async]] void _transfer_loop() {\n    do\n     {\n         // Handle reset\n         if (_reset_flag)\n         {\n             static for (const auto i : NUM_INPUTS)\n             {\n                 _flits_read[i] = 0;\n             }\n             _curr_packet = 0;\n             _reset_flag = false;\n         }\n         schedule_t schedule = _create_schedule();\n         _execute_schedule(SCHEDULE_WIDTH, schedule);\n     } while (true);\n }"}
{"file": "data\\cache\\read_only.pd", "nl": "The callback function to invoke when a `get` call causes a cache miss.", "code": "cache_tags<Key, LUtime, Associativity, Depth> _tags;\n\n    pipelined_memory<Value, Depth, Banks> _data;\n\npublic:\n    using set_index_t = index_t<_setCount>;"}
{"file": "data\\cache\\read_only.pd", "nl": "Initialize or re-initialize a cache object.", "code": "void initialize()\n    {\n        _tags.initialize();\n    }"}
{"file": "data\\cache\\read_only.pd", "nl": "Get a value from the cache.", "code": "    Value get( Key key               //< The key to lookup.\n        , set_index_t set_index //< The hashed value of the key.\n        )\n    {\n        auto getResult = _tags.get(key, set_index, false);\n         Value val;\n         if (!getResult.hit)\n         {\n             val = load(key);\n         }\n         auto dataIndex = set_index * Associativity + getResult.idx;\n         bool hit = getResult.hit;\n         auto result = _data.atomically(dataIndex, [val, hit](Value prev)\n         {   \n             Value next = prev;\n             if (!hit)\n             {\n                 // Update data in the cache\n                 next = val;\n             }\n             return next;\n         });\n         return result.second;\n    }"}
{"file": "data\\text\\nfa.pd", "nl": "Write one element to the NFA data.", "code": "void write_table\n    ( index_t<TableDepth> addr  //< The address of the element to write.\n    , table_element_t element   //< The element to write.\n    ) {\n    sim_assert(addr < TableDepth);\n    _table[addr] = element;}"}
{"file": "data\\text\\nfa.pd", "nl": "Speculatively precompute how the vector of inputs will affect NFA state, given all possible current NFA states. `updates[i]` describes how to update the NFA state if the current NFA state has state `i` enabled.", "code": "\nstate_t[StateCount] updates = speculate_updates([input, table_elements](index_t<StateCount> vertex_id)\n        {\n            // Determine how the inputs will affect state\n            // if the NFA state before processing those inputs\n            // has `vertex_id` enabled.\n           state_t curr_state = binary_to_one_hot<StateCount>(vertex_id);\n           static for (const auto input_element_index : InputWidth)\n           {\n               if (input_element_index < input.size) {\n                state_t updated_state = {};\n                table_element_t table_element = table_elements[input_element_index];\n                static for (const auto src_vertex : StateCount)\n                {\n                    if (curr_state[src_vertex]) \n                    { \n                        out_edges_t out_edges = table_element[src_vertex];\n                        static for (const auto dst_vertex : StateCount)\n                        {\n                            // Reduce resource consumption by only checking \n                            // updates which are deemed possible by the MaxBackwardJump and MaxForwardJump parameters \n                            if (static((dst_vertex == src_vertex) || \n                                       ((dst_vertex < src_vertex) && ((src_vertex - dst_vertex) <= (MaxBackwardJump * (input_element_index + 1)))) || \n                                       ((dst_vertex > src_vertex) && ((dst_vertex - src_vertex) <= (MaxForwardJump * (input_element_index + 1)))))) \n                            { \n                                static for (const auto out_edge_index : MaxOutDegree) \n                                { \n                                    if (out_edge_index < out_edges.size) \n                                    { \n                                        vertex_t out_vertex = out_edges.data[out_edge_index];\n                                        if (out_vertex == dst_vertex) {\n                                            updated_state[dst_vertex] = true;  \n                                        } } } } } } }  \n                curr_state = updated_state; } }\n        return curr_state;    },\n    {});"}
{"file": "data\\text\\nfa.pd", "nl": "Atomically update state", "code": "return second(atomically(apply_update(\n    [initial_state](state_t[StateCount] updates, state_t prev)\n    {\n        // If initial_state is valid, then ignore prev and use initial_state instead\n        prev = O::from_optional(prev, initial_state);\n        // If bit `i` is set in prev, then all bits set in `updates[i]` will be set in the result\n        return A::reduce(\n            bitwise_or<state_t>,\n            A::zip_with(\n                [](state_t new, bool prev) {\n                    return prev ? new : {};\n                },\n                updates, prev));\n    },\n    [](state_t update, state_t prev) {return update;},\n    updates\n)));\n}"}
{"file": "data\\cache\\write_only.pd", "nl": "Function used to write to the backing store.", "code": " (Key key, optional<Word>[WordCount] data) -> void store;\n const auto SetCount = Depth / Associativity;\n // An integer that represents a single set of `Associativity` values in the cache.\n using set_index_t = index_t<SetCount>;cache_tags<Key, LUtime, Associativity, Depth> _tags;\n\n    pipelined_memory<optional<Word>[WordCount], Depth, Banks, memory_norep> _data;\n\n    inline index_t<Depth> get_data_index(set_index_t set_index, index_t<Associativity> way_index)\n    {\n        return (set_index * Associativity) + way_index;\n    }"}
{"file": "data\\cache\\write_only.pd", "nl": "Initialize the cache. This must be called before using the cache. The caller must ensure that `intialize` is not called concurrently with other methods.", "code": "void initialize()\n    {\n        _tags.initialize();\n    }"}
{"file": "data\\cache\\write_only.pd", "nl": "Write any unwritten data out of the cache. The caller must ensure that `flush` is not called concurrently with other methods.", "code": "void flush()\n    {\n        // For each tag\n        pipelined_for (Depth, [](index_t<Depth> tid)\n        {\n            auto decomposed = div_mod(tid, Associativity);\n\n            optional<Key> key = _tags.get_and_clear_unwritten_key(decomposed.first, decomposed.second);\n\n            if (key.is_valid)\n            {\n                auto data_index = get_data_index(decomposed.first, decomposed.second);\n\n                optional<Word>[WordCount] value_and_enable = _data.read(data_index);\n\n                store(key.value, value_and_enable);\n            }\n        });\n    }"}
{"file": "data\\cache\\write_only.pd", "nl": "Write an array of words into the cache.", "code": "    void write\n    ( Key key                           //< Key to lookup.\n    , set_index_t set_index             //< Hashed value of `key`.\n    , optional<Word>[WordCount] words   //< Values to store.\n    ) {\n    // Tag lookup\n    auto tag_result = _tags.get(key, set_index, true);\n    auto data_index = get_data_index(set_index, tag_result.idx);\n    bool hit = tag_result.hit;\n    // Data read-modify-write\n    auto prev = first(_data.atomically(data_index,\n        [words, hit](optional<Word>[WordCount] prev) {\n            return zip_with(\n               [hit](optional<Word> prev, optional<Word> word)\n               {\n                    return make_optional(word.is_valid || (prev.is_valid && hit), word.is_valid ? word.value : prev.value);\n               },\n                prev,\n                 words);\n        }));\n     // Write out evicted cache line\n     if (tag_result.key_to_write.is_valid)\n     {\n          store(tag_result.key_to_write.value, prev);\n     }\n }"}
{"file": "tutorials\\complete\\header_insertion.pd", "nl": "Function to insert a network header at the start of each packet in a serialized manner, ensuring only one thread executes at a time.// input_data: Up to 4 bytes of payload\n// valid_count: Number of valid payload bytes\n// head: head.is_valid is set to true on the first call to \n//       insert_header_serialized for each packet.  head.value\n//       should be inserted before the payload data.\n// end_of_packet: set to true on the last call to insert_header_serialized for a\n//                given packet\n// output_cb: function to call with output data accepts:\n//            4 bytes of payload\n//            count of number of valid payload bytes\n//            end_of_packet flag", "code": "inline void insert_header_serialized(\n    uint8[bytes_per_cycle] input_data, \n    count_t<bytes_per_cycle> valid_count,\n    optional<header> head,\n    bool end_of_packet,\n    (uint8[bytes_per_cycle], count_t<bytes_per_cycle>, bool)->void output_cb)\n{\n    static mutex _mutex;\n    _mutex.lock();\n\n    if (head.is_valid)\n    {\n        output_cb(\n            cast<uint8[4]>(head.value.ip),\n            bytesizeof(head.value.ip),\n            false);\n\n        output_cb(\n            reinterpret_cast<uint8[4]>(head.value.port),\n            bytesizeof(head.value.port),\n            false);\n    }\n    output_cb(input_data, valid_count, end_of_packet);\n    _mutex.unlock();\n}"}
{"file": "tutorials\\complete\\header_insertion.pd", "nl": "Concurrent function to insert a network header at the start of each packet using pipelining.", "code": "inline void insert_header_concurrent(\n    uint8[bytes_per_cycle] input_data, \n    count_t<bytes_per_cycle> valid_count,\n    optional<header> head,\n    bool end_of_packet,\n    (uint8[bytes_per_cycle], count_t<bytes_per_cycle>, bool)->void output_cb)\n{\n    const auto max_bytes_per_call = bytes_per_cycle + bytesizeof(header);\n    count_t<max_bytes_per_call> total_bytes = valid_count;\n    if (head.is_valid)\n    {\n        total_bytes += bytesizeof(header);\n    }\n    const auto max_threads_per_call = (max_bytes_per_call + max_bytes_per_call - 1) / bytes_per_cycle;\n    count_t<max_threads_per_call> num_threads = (total_bytes + bytes_per_cycle - 1) / bytes_per_cycle;\n\n    pipelined_for(num_threads, [input_data, valid_count, head, end_of_packet, output_cb](index_t<max_threads_per_call> tid)\n    {\n        uint8[bytes_per_cycle] data_to_send;\n        count_t<bytes_per_cycle> byte_count_to_send;\n        bool eop;\n\n        if (head.is_valid && (tid < 2))\n        {\n            switch (tid)\n            {\n            case 0:\n                data_to_send = reinterpret_cast<uint8[bytes_per_cycle]>(head.value.ip);\n                byte_count_to_send = bytesizeof(head.value.ip);\n                break;\n\n            case 1:\n                data_to_send = reinterpret_cast<uint8[bytes_per_cycle]>(head.value.port);\n                byte_count_to_send = bytesizeof(head.value.port);\n                break;\n            }\n            eop = false;\n        }\n        else\n        {\n            data_to_send = input_data;\n            byte_count_to_send = valid_count;\n            eop = end_of_packet;\n        }\n        output_cb(data_to_send, byte_count_to_send, eop);\n    });\n}"}
{"file": "tutorials\\complete\\synchronization_bugs.pd", "nl": "read-modify-write to a memory", "code": "pipelined_for(512, [](index_t<512> tid){ // begin_strip\n            // atomic block needed to synchronize access to the memory\n            atomic\n            {\n            // end_strip\n            uint32 previous = _mem4[tid % 4];\n            uint32 new = previous * 1234 + tid;\n            _mem4[tid % 4] = new;\n\n            // begin_strip\n            }\n            // end_strip }"}
{"file": "tutorials\\complete\\synchronization_bugs.pd", "nl": "compute a sum in the inner-most loop", "code": "uint32 nested_sum(){\n_sum = 0;\npipelined_for(16, [](index_t<16> i){\n_i = i;\n    pipelined_for (16, [i](index_t<16> j)\n    { atomic\n                {\n                    auto amount_to_add = _i + j;\n\n                    // begin_strip\n                    // There is no synchronization that pevents _i from being overwritten\n                    // Use the local \"i\" variable insead\n                    amount_to_add = i + j;\n                    // end_strip\n\n                    _sum += amount_to_add;\n                } });}); return _sum;}"}
{"file": "tutorials\\complete\\synchronization_bugs.pd", "nl": "Launch 2 threads. Each thread increments an integer. Wait for threads, then return the value of that integer.", "code": "bool fork() {\n   _finished_count = 0;\n    // begin_strip\n   _finished_count1 = 0;\n    _finished_count2 = 0;\n    // end_strip\n    // Launch fork_outer_thread_count threads\n    pipelined_for(fork_outer_thread_count, [](index_t<fork_outer_thread_count> tid)\n    {\n        // Launch 2 threads\n        async_exec([]()\n        {\n            atomic\n            {\n                _finished_count++;\n                // begin_strip\n                _finished_count1++;\n                // end_strip\n            }\n        });\n        async_exec([]() {\n            atomic {\n                _finished_count++;\n                // begin_strip\n                _finished_count2++;\n                // end_strip\n            } }); });\n    // Wait for all threads calls to complete\n    // A timeout is used to ensure the program doesn't hang, even if there\n    // is a bug\n    bool result = wait_with_timeout(1000, []() { \n        bool result = _finished_count == (fork_outer_thread_count * 2);\n       // begin_strip\n        // There is a data race when threads write to _finished_count\n        // Instead, use separate variables to be written by each call to async_exec\n        result = (_finished_count1 + _finished_count2) == (fork_outer_thread_count * 2);\n        // end_strip\n        return result;\n    });\n    return result;\n}"}
{"file": "tutorials\\complete\\waiting.pd", "nl": "member variables and methods here", "code": "bool _locked = false;\nlock_internal(){ bool result = !_locked;\n\n        if (result)\n        {\n            _locked = true;\n        }\n\n        return result; }"}
{"file": "tutorials\\complete\\waiting.pd", "nl": "/ Block the calling thread until the mutex is no longer locked", "code": "void lock()\n{\n// begin_strip\nwait_for(lock_internal());\n// end_strip\n}"}
{"file": "tutorials\\complete\\waiting.pd", "nl": "// Allow a new thread to acquire the lock", "code": "void unlock()\n{\n// begin_strip\n_locked = false;\n// end_strip\n}"}
{"file": "tutorials\\complete\\waiting.pd", "nl": "// A reader-writer lock that is in one of 2 states: 1) locked for writing     - 1 writer thread in flight, no readers in flight 2) not locked for writing - up to MaxReaders reader threads in flight. Caller ensures no more than MaxReaders readers in flight at a time", "code": "template<auto MaxReaders>\nclass rwlock\n{\nprivate:\n    // member variables and methods here\n    // begin_strip\n    bool _writer_in_flight = false;\n    counter<MaxReaders, 0> _readers_in_flight;\n    inline bool lock_internal(bool is_writer)\n    {\n        bool result = false;\n        if (is_writer)\n        {\n            // Only allow a new writer if there is no in-flight reads or writers\n            result = !_writer_in_flight && (0 == _readers_in_flight.count());\n        }\n        else\n        {\n            // Allow a reader if there is no writer in-flight\n            result = !_writer_in_flight;\n        }\n        if (result)\n        {\n            if (is_writer)\n            {\n                _writer_in_flight = true;\n            }\n            else\n            {\n                _readers_in_flight.add(1);\n            }\n        }\n        return result;\n    }\n    // end_strip"}
{"file": "tutorials\\complete\\waiting.pd", "nl": "// Create 512 threads and test mutexes", "code": "// Create 512 threads\npipelined_for(512, [](index_t<512> id) {\n    static mutex _mutex;\n    _mutex.lock();\n    // This counter is used for testing, verifies that \n    // only 1 thread is between lock/unlock\n    // The counter is initialized to 0\n    static counter<512, 0> _counter;\n    // Increment the counter to 1\n    _counter.increment();\n    // Extend the pipeline depth to enable many threads\n    // in between lock/unlock if there is a bug in the mutex\n    stages<10>();\n    // There should only be 1 thread in between lock/unlock\n    if (1 != _counter.count()) {\n        atomic {\n            _errorCount++;\n        }\n    }\n    _counter.decrement();\n    _mutex.unlock();\n});"}
{"file": "data\\fifo\\multi.pd", "nl": "Write one entry to a FIFO. Block if the FIFO is full and `EnqueueBlocking` is true.", "code": "void enqueue(fifo_idx_t which, T value)\n    {\n        // Block until the FIFO is no longer full\n        _writeSemaphore.wait(which, true);\n\n        // Get the value of the write pointer, and increment the write pointer\n        pointer_t snappedProducerIndex;\n\n        atomic\n        {\n            snappedProducerIndex = _producerIndex[which];\n            _producerIndex[which] = modular::increment(snappedProducerIndex);\n        }\n\n        // Store the value into the memory\n        _dataMem[Size * which + snappedProducerIndex] = value;\n\n        // Allow 1 more thread to get a value out\n        _readSemaphore.post(which);\n    }"}
{"file": "data\\fifo\\multi.pd", "nl": "Read one entry from a FIFO. Block if the FIFO is empty and `DequeueBlocking` is true.", "code": "T dequeue(fifo_idx_t which, bool pop)\n    {\n        // Block the calling thread until an entry is available\n        _readSemaphore.wait(which, pop);\n\n        // Get the value of the read pointer, and optionally increment the read pointer\n        pointer_t snappedConsumerIndex;\n\n        atomic\n        {\n            snappedConsumerIndex = _consumerIndex[which];\n\n            _consumerIndex[which] = modular::increment_if(snappedConsumerIndex, pop);\n        }\n\n        // Read the value from the data memory\n        T result = _dataMem[Size * which + snappedConsumerIndex];\n\n        // Now that the read has occured, allow another thread to overwrite the data\n        if (pop)\n        {\n            _writeSemaphore.post(which);\n        }\n\n        return result;\n    }"}
{"file": "data\\fifo\\multi.pd", "nl": "Return the number of elements that have been written and not read. Note that this can be out of date the instant it is read due to other threads reading or writing to the FIFO. This cannot be used for checking empty or full for non-blocking versions of the FIFO.", "code": "inline count_t<Size> count(fifo_idx_t which)\n    {\n        return _readSemaphore.count(which);\n    }"}
{"file": "data\\fifo\\multi.pd", "nl": "This class implements a set of FIFOs that use a single, statically partitioned block of memory. Note that when using the blocking version, a call for one of the FIFO instances that blocks will also block subsequent calls for other FIFO instances, even if those calls would otherwise not block. In other words, there is head of line blocking across FIFOs.", "code": "template\n< typename T                  //< Type of each entry in the FIFO.\n, auto Size                   //< Maximum number of entries that can be stored in each FIFO.\n, auto N                      //< Number of FIFOs.\n, bool EnqueueBlocking = true //< Block on enqueue if the FIFO is full until an entry\n                              // frees up. By default this is true. Otherwise,\n                              // the caller must ensure that the FIFO is not full.\n, bool DequeueBlocking = true //< Block on dequeue if the FIFO is empty until an entry\n                              // arrives. By default, this is true. Otherwise,\n                              // the caller must ensure that the FIFO is not empty.\n>\nclass multi_fifo{\npublic:\nusing pointer_t = index_t<Size>;\nusing fifo_idx_t = index_t<N>;\nprivate:\npointer_t[N] _producerIndex = {};\npointer_t[N] _consumerIndex = {};\n// Memory that holds the raw data\nmemory<T, N*Size> _dataMem;\n\n    // Used to block reads while fifo is empty\n    multi_semaphore<N, Size, 0, DequeueBlocking> _readSemaphore;\n\n    // Used to block writes while the fifo is full\n    multi_semaphore<N, Size, Size, EnqueueBlocking> _writeSemaphore;"}
{"file": "numeric\\int\\divider\\unsigned.pd", "nl": "Calculate the quotient and remainder from dividing unsigned integers.", "code": "template\n  < typename NumeratorType\n  , typename DenominatorType\n  , auto UnrollingFactor     //< Chunks of numerator bits of this size are processed in parallel,\n                             // meaning the outer loop only has to execute\n                             // `bitsizeof(NumeratorType)/UnrollingFactor` iterations.\n  >inline NumeratorType[2] divide(NumeratorType numerator, DenominatorType denominator) \n{\n  sim_assert(denominator != 0);\n   const auto NumeratorWidth = bitsizeof(NumeratorType);\n  const auto DenominatorWidth = bitsizeof(DenominatorType);\n   uint<DenominatorWidth+1> remainder;\n   NumeratorType quotient;\n   uint1[NumeratorWidth] numerator_as_bits = cast<uint1[NumeratorWidth]>(numerator);\n   static assert(NumeratorWidth == (NumeratorWidth / UnrollingFactor) * UnrollingFactor);\n   uint<NumeratorWidth+1> i = 0;\n    do {\n        static for(const auto j : UnrollingFactor) {\n            remainder = (remainder << 1) | numerator_as_bits[NumeratorWidth - (i+j) - 1];\n            if (remainder < denominator) // underflow to upper bit => remainder < denominator {\n                quotient = (quotient << 1);\n            }\n            else {\n                quotient = (quotient << 1) | 1;\n                remainder -= denominator;\n            }\n        }\n        i += UnrollingFactor;\n    }\n    while (i < NumeratorWidth);\n    return {quotient, remainder};}"}
{"file": "sync\\atomic.pd", "nl": "Atomically apply user specified function to internal state of type `T`, returning both old and new state value. Note that a state is maintained per each call site of this inline function.", "code": "inline pair<T, T> atomically((T) -> T modify)\n{\n    pair<T, T> result;\n\n    atomic\n    {\n        static T state = InitialValue;\n\n        result = {state, modify(state)};\n        state = result.second;\n    }\n\n    return result;\n}"}
{"file": "sync\\atomic.pd", "nl": "Atomically interleave updates among multiple threads to internal state of type `T[N]`. Return both old and new element value. A state is maintained per each call site of this inline function.", "code": "template\n< auto N              //< Size of state array. Must be between 2 and 8 inclusive.\n, typename T          //< Type of the internal state.\n, T InitialValue = {} //< Initial value.>inline pair<T, T> atomically_one_of(index_t<N> i, (T) -> T modify)\n{\n    static assert(N >= 2 && N <= 8);\n\n    pair<T, T> result;\n\n    [[schedule(N)]]\n    {\n        // TODO: fix when generic initializer syntax is available\n        static if (N == 2)\n        {\n            static T[N] state = {InitialValue, InitialValue};\n        }\n        else static if (N == 3)\n        {\n            static T[N] state = {InitialValue, InitialValue, InitialValue};\n        }\n        else static if (N == 4)\n        {\n            static T[N] state = {InitialValue, InitialValue, InitialValue, InitialValue};\n        }\n        else static if (N == 5)\n        {\n            static T[N] state = {InitialValue, InitialValue, InitialValue, InitialValue, InitialValue};\n        }\n        else static if (N == 6)\n        {\n            static T[N] state = {InitialValue, InitialValue, InitialValue, InitialValue, InitialValue, InitialValue};\n        }\n        else static if (N == 7)\n        {\n            static T[N] state = {InitialValue, InitialValue, InitialValue, InitialValue, InitialValue, InitialValue, InitialValue};\n        }\n        else static if (N == 8)\n        {\n            static T[N] state = {InitialValue, InitialValue, InitialValue, InitialValue, InitialValue, InitialValue, InitialValue, InitialValue};\n        }\n\n        result = {state[i], modify(state[i])};\n        state[i] = result.second;\n    }\n\n    return result;\n}"}
{"file": "sync\\atomic.pd", "nl": "Holds a boolean state which is initially set to `false` and flipped to `true` by the fist call to `check` method. The first call returns `false` and all subsequent calls return `true`.", "code": "bool check()\n    {\n        return first(atomically(constant(true)));\n    }"}
{"file": "sync\\atomic.pd", "nl": "Amortize the cost of initializing a set of variables by assigning a generation ID to each variable.  A variable is considered uninitialized if the associated generation ID does not match the current generation ID. Per-variable generation IDs only need to be initialized when the current generation ID overflows. The returned `pair` `first` field is true if the generation ID has overflowed and an explicit initialization to a generation ID of 0 is required. The returned `pair` `second` field is the generation ID to compare against. `reset` must be true on the first call to this function.", "code": "inline pair<bool, uint<Width>> init_generational(bool reset)\n{\n    using generation_id_t = uint<Width>;\n\n    pair<bool, uint<Width>> result;\n\n    result.second = second(atomically([reset](generation_id_t prev)\n    {\n        const generation_id_t highest_id = (1 << Width) - 1;\n\n        // reset must be true on the first call to this function\n        // That is the only time when prev will be 0\n        sim_assert(reset || (prev != 0));\n\n        generation_id_t new = prev;\n\n        if (reset)\n        {\n            // Never return 0, skip from highest_id to 1\n            new = (prev == highest_id) ? 1 : prev + 1;\n        }\n\n        return new;\n    }));\n\n    // Initialization to 0 is required when reset is true\n    // and the new generation is 1.\n    // This occurs when either wrapping from highest_id\n    // or when incrementing from the default value of 0\n    result.first = reset && (result.second == 1);\n\n    return result;\n}"}
{"file": "numeric\\int\\divider\\signed\\iterative.pd", "nl": "Fully iterative divider for signed integers. This type of divider will", "code": "template <typename NumeratorType, typename DenominatorType>\ninline NumeratorType[2] divide(NumeratorType numerator, DenominatorType denominator)\n{\n    return DS::divide<NumeratorType, DenominatorType, 1>(numerator, denominator);\n}"}
{"file": "numeric\\int\\divider\\signed\\unrolled.pd", "nl": "Fully unrolled divider for signed integers. This type of divider will consume the most area, but has the lowest latency.", "code": "template <typename NumeratorType, typename DenominatorType>\ninline NumeratorType[2] divide(NumeratorType numerator, DenominatorType denominator)\n{\n    return DS::divide<NumeratorType, DenominatorType, bitsizeof(NumeratorType)>(numerator, denominator);\n}"}
{"file": "numeric\\int\\divider\\unsigned\\iterative.pd", "nl": "Fully iterative divider for unsigned integers. This type of divider will consume the lowest area, but has the highest latency. Latency increases linearly with the number of bits in the Numerator.", "code": "template <typename NumeratorType, typename DenominatorType>\ninline NumeratorType[2] divide(NumeratorType numerator, DenominatorType denominator)\n{\n    return DU::divide<NumeratorType, DenominatorType, 1>(numerator, denominator);\n}"}
{"file": "numeric\\int\\divider\\unsigned\\unrolled.pd", "nl": "Fully unrolled divider for unsigned integers. This type of divider will consume the most area, but has the lowest latency.", "code": "template <typename NumeratorType, typename DenominatorType>\ninline NumeratorType[2] divide(NumeratorType numerator, DenominatorType denominator)\n{\n    return DU::divide<NumeratorType, DenominatorType, bitsizeof(NumeratorType)>(numerator, denominator);\n}"}
{"file": "processor\\risc_v.pd", "nl": "Print a diagram of memory address space configuration.", "code": "inline void print_memory_map()\n    {\n        T::print_memory_map<\n            IMEM_LENGTH,\n            DMEM_LENGTH,\n            MMIO_LENGTH,\n            IMEM_ORIGIN,\n            DMEM_ORIGIN,\n            MMIO_ORIGIN,\n            IMEM_TCM_SIZE>();\n    }"}
{"file": "processor\\risc_v.pd", "nl": "Request the core to stop. Note that the method doesn't block until the  core has finished running. Use `is_running` method to wait for the core to stop.", "code": "inline void stop()\n    {\n        atomic\n        {\n            if (running)\n            {\n                sim_assert(!exit);\n                exit = true;\n            }\n        }\n    }"}
{"file": "processor\\risc_v.pd", "nl": "Returns `true` if the core is running. Can be used to wait for the core to finish running after stop request.", "code": "inline bool is_running()\n    {\n        return running;\n    }"}
{"file": "processor\\risc_v.pd", "nl": "Complete asynchronous external instruction fetch.", "code": "inline void external_fetch_result\n( hart_index_t hid  //< Index of the hart that performed the fetch.\n, uint_t addr       //< Address of 32-bit instruction word that was fetched.\n, uint_t value      //< 32-bit instruction word.\n){\n    core.external_fetch_result(hid, checked_cast<imem_addr_t>(addr), value);\n}"}
{"file": "processor\\risc_v.pd", "nl": "Complete asynchronous load from memory mapped IO.", "code": "inline void mmio_load_result\n( hart_index_t hid  //< Index of the hart that performed the asynchronous load\n                    // from memory mapped IO.\n, int_t value       //< Result of memory mapped IO load.\n){\n    core.mmio_load_result(hid, value);}"}
{"file": "processor\\risc_v.pd", "nl": "Complete asynchronous store to memory mapped IO.", "code": "inline void mmio_store_completed\n ( hart_index_t hid  //< Index of the hart that performed the asynchronous store\n                    // to memory mapped IO.\n) {\n    core.mmio_store_completed(hid);\n}"}
{"file": "processor\\risc_v.pd", "nl": "Write 32-bit word to tightly coupled instruction memory.// The method is safe to call only when the core is not running.", "code": "inline void imem_write\n( uint_t addr //< Address of 32-bit word in instruction TCM to write.\n, int_t value //< 32-bit instruction word.\n) {\n    core.imem_write(checked_cast<imem_addr_t>(addr), value);}"}
{"file": "processor\\risc_v.pd", "nl": "Read a 32-bit word from hart's data memory.", "code": "inline int_t dmem_read\n ( hart_index_t hid  //< Hart index.\n , uint_t addr       //< DMEM byte address to read from.\n ) {\n    return core.dmem_read(hid, checked_cast<dmem_addr_t>(addr));}"}
{"file": "processor\\risc_v.pd", "nl": "//| Write specified number of bytes to hart's data memory.", "code": "inline void dmem_write\n( hart_index_t hid  //< Hart index.\n, uint_t addr       //< DMEM byte address to write to.\n, int_t value       //< Value to write.\n, count_t<4> size   //< Number of bytes of `value` to write.\n) {\n    core.dmem_write(hid, checked_cast<dmem_addr_t>(addr), value, size);\n}"}
{"file": "processor\\risc_v.pd", "nl": "Read a 32-bit word from hart's data memory at a 32-bit aligned address.// More resource efficient than `dmem_read` when unaligned address support is not required.", "code": "inline int_t dmem_read_aligned\n( hart_index_t hid  //< Hart index.\n, uint_t addr       //< DMEM byte address to read from.\n                    // Must be 32-bit aligned.\n) {\n    return core.dmem_read_aligned(hid, checked_cast<dmem_addr_t>(addr));}"}
{"file": "processor\\risc_v.pd", "nl": "Write a 32-bit word to hart's data memory at a 32-bit aligned address. More resource efficient than `dmem_write` when unaligned address support is not required.", "code": "inline void dmem_write_aligned\n( hart_index_t hid  //< Hart index.\n , uint_t addr       //< DMEM byte address to write to. \n                     // Must be 32-bit aligned.\n , int_t value       //< 32-bit value to write.\n ) {\n   core.dmem_write_aligned(hid, checked_cast<dmem_addr_t>(addr), value);}"}
{"file": "processor\\risc_v.pd", "nl": "Initialize stack pointers. Not necessary if the firmware startup code performs the initialization. When the option `Option::HartsShareDMEM` is set then each hart is allocated its own stack of the specified size, with the stack for hart 0 starting at the specified address, and stacks for remaining harts following below it in DMEM address space.", "code": "inline void init_stack_pointers\n     ( uint_t stack_start //< Start address of the stack. Must be 16 byte aligned.\n                          // Since the stack grows down, the starting address usually\n                           // is set to `DMEM_ORIGIN + DMEM_LENGTH - 0x10`\n      , uint_t stack_size  //< Size of the stack for each hart.\n       ) {\n     sim_assert(running == false);\n      static for(const auto hid : HARTS) {\n          // By ABI calling convention stack pointer should be 16 bytes aligned.\n          sim_assert((stack_start & 0xf) == 0);\n          // Don't generate invalid stack pointers\n          sim_assert(stack_start - stack_size >= DMEM_ORIGIN && stack_start < DMEM_ORIGIN + DMEM_LENGTH ||\n                     stack_start - stack_size >= MMIO_ORIGIN && stack_start < MMIO_ORIGIN + MMIO_LENGTH);\n           core.register_set(hid, ABI::sp, cast<int_t>(stack_start));\n           static if ((CONFIG & Option::HartsShareDMEM) == Option::HartsShareDMEM)\n           {\n               // Set a different stack pointer for each hart.\n               stack_start -= stack_size;\n           }\n       }\n    }"}
{"file": "processor\\risc_v.pd", "nl": "Start the core.", "code": "inline void start\n  ( uint_t[HARTS] pc //< Array of initial program counters for each hart.\n ) {\n bool start = false;\n atomic{\n     if (!running) {\n         start = true;\n        running = true; } }\nif (start) {\ncore.initialize(pc);\nasync_pipelined_do<threads>(\n[]() {\n    core.pipeline();\n    return !exit;\n},\n[]() {\n    atomic {\n        sim_assert(exit);\n        sim_assert(running);\n        exit = false;\n        running = false;\n    } }\n        );\n    }}"}
{"file": "processor\\risc_v\\internal\\core.pd", "nl": "Check if a given address is within a specified memory range.", "code": "template<auto ORIGIN, auto LENGTH>\ninline bool addr_in_range(auto addr)\n{\n    static if (LENGTH == 0)\n    {\n        return false;\n    }\n    else\n    {\n        return addr >= ORIGIN && addr < ORIGIN + LENGTH;\n    }\n}"}
{"file": "processor\\risc_v\\internal\\core.pd", "nl": "Get the high order bit of a given value.", "code": "inline auto high_order_bit(auto x) { return cast<uint1>(x >> (bitsizeof x - 1)); }"}
{"file": "processor\\risc_v\\internal\\core.pd", "nl": "Decode the fetched instruction.", "code": "inline Decoded decode(Current current) { return decode_instr<EXTENSIONS, CONFIG>(current.instr.value, custom_decode); }"}
{"file": "processor\\risc_v\\internal\\core.pd", "nl": "Fetch the next instruction to be executed in the pipeline.", "code": "    inline Current fetch(){\nstatic imem_addr_t fetch_pc;\nCurrent current = {};\ntid_t current_tid;\natomic {\n static tid_t tid = 0;\n bool try_predict = true;\n btb_index_t btb_index_nxt;\n current_tid = tid;\n  tid = modular::increment(tid);\n  static if (HARTS != 1)\n  {\n      current.hid = hid;\n      static assert((HARTS & (HARTS - 1)) == 0);\n\n      hid = modular::increment(hid);\n      btb_index_nxt = cast<decltype(btb_index_nxt)>(hart[hid].pc);\n   }\n   else\n   { \n       current.hid = 0; \n   }\n  fetch_pc = hart[current.hid].pc;\n  if (static(USE_MICRO_OPS) && hart[current.hid].micro_op.next_pc.is_valid) \n {\n      fetch_pc = hart[current.hid].micro_op.next_pc.value;\n      hart[current.hid].micro_op.next_pc.is_valid = current_tid != hart[current.hid].micro_op.end_tid; \n      try_predict = false;\n  }\n  if (static(EXTERNAL_FETCH) && hart[current.hid].external_fetch_pc.is_valid)\n  {\n      fetch_pc = hart[current.hid].external_fetch_pc.value; \n      hart[current.hid].external_fetch_pc.is_valid = !hart[current.hid].external_fetch_result.is_valid;\n     try_predict = false;\n     current.received_pending_fetch = hart[current.hid].external_fetch_result.is_valid;\n }\n sim_assert(!hart[current.hid].mmio_pending || hart[current.hid].pipeline_flush_pc.is_valid);\n sim_assert(!hart[current.hid].trap || hart[current.hid].pipeline_flush_pc.is_valid);\n if (hart[current.hid].pipeline_flush_pc.is_valid)\n {\n     // Recover after pipeline flush (e.g. after branch misprediction, mmio or trap)\n     if (!(hart[current.hid].mmio_pending && !hart[current.hid].mmio_completed) &&\n         !hart[current.hid].trap) \n     { \n\n         current.recovered_from_pipeline_flush = true; \n     } \n     fetch_pc = hart[current.hid].pipeline_flush_pc.value;\n    hart[current.hid].pipeline_flush_pc.is_valid = !current.recovered_from_pipeline_flush;\n    if (static(USE_MICRO_OPS) && hart[current.hid].micro_op.next_pc.is_valid)\n    {\n        hart[current.hid].micro_op.next_pc.is_valid = false;\n    }\n    if (static(EXTERNAL_FETCH) && hart[current.hid].external_fetch_pc.is_valid)\n     {\n         hart[current.hid].external_fetch_pc.is_valid = false;\n     }\n     try_predict = false;\n     if (hart[current.hid].mmio_pending)\n     { \n         hart[current.hid].mmio_pending = !current.recovered_from_pipeline_flush;\n     }\n }\n static if (OPTIMIZE_FMAX) {\n     current.pc = fetch_pc;\n   }\n   current.next_pc = modular::increment(fetch_pc);\n   current.predicted_pc = try_predict ? predict(current) : current.next_pc;\n   hart[current.hid].pc = current.predicted_pc;\n    static if (HARTS == 1)\n    {\n        btb_index_nxt = cast<decltype(btb_index_nxt)>(current.predicted_pc);\n    }\n     btb_index = btb_index_nxt; } \n atomic\n { \n if (current.recovered_from_pipeline_flush) \n { \n     sim_assert(!hart[current.hid].commit); \n     sim_assert(!hart[current.hid].external_fetch_pc.is_valid); \n     sim_assert(!hart[current.hid].micro_op.next_pc.is_valid); \n    hart[current.hid].fetch_enable = true;\n     hart[current.hid].external_fetch_pending = false; \n     hart[current.hid].micro_op.pending = false;\n }\n current.instr.is_valid = true;\n static if (OPTIMIZE_FMAX) {\n     if (hart[current.hid].fetch_enable)\n     {\n         current.instr.value = imem[current.pc];    }}\n else if (static(USE_MICRO_OPS) && hart[current.hid].micro_op.pending) {\n     sim_assert(!hart[current.hid].external_fetch_pending);\n    current.instr.value = hart[current.hid].micro_op.instr;\n     current.pc = hart[current.hid].micro_op.pc; \n     current.next_pc = hart[current.hid].micro_op.next_pc.value;\n     current.predicted_pc = current.next_pc; }\nelse if (static(EXTERNAL_FETCH) && hart[current.hid].external_fetch_pending) {\n  sim_assert(hart[current.hid].external_fetch_result.is_valid || !current.received_pending_fetch);\n   hart[current.hid].external_fetch_pending = !current.received_pending_fetch;\n    current.instr = make_optional(\n            current.received_pending_fetch && hart[current.hid].fetch_enable,\n           hart[current.hid].external_fetch_result.value);\n    current.pc = fetch_pc; }\nelse if (static(EXTERNAL_FETCH) && (static(IMEM_TCM_SIZE == 0) || (fetch_pc & (~(IMEM_TCM_SIZE - 1))) != 0)) {\n    bool external_fetch_pending = false;\n    if (hart[current.hid].fetch_enable) { \n        current.instr = reinterpret_cast<optional<Instr>>(external_fetch(current.hid, fetch_pc));\nexternal_fetch_pending = !current.instr.is_valid; \n    } \n    sim_assert(!hart[current.hid].external_fetch_pc.is_valid);\n    hart[current.hid].external_fetch_pc = make_optional(external_fetch_pending, fetch_pc);\n    hart[current.hid].external_fetch_pending = external_fetch_pending; \n    hart[current.hid].external_fetch_result.is_valid = false; \n    current.pc = fetch_pc; \n }\nelse static if (IMEM_TCM_SIZE > 0) {\n    if (hart[current.hid].fetch_enable) {\n        current.instr.value = imem[fetch_pc]; }\n    current.pc = fetch_pc; }\nstatic if (USE_MICRO_OPS) {\nif (!hart[current.hid].micro_op.pending) {\n   const bool mul = static(MICRO_OP_MUL) && current.instr.value.r.opcode.opcode == RVG::OP && current.instr.value.r.funct7 == 0b_0000001;\n    const bool load = static(MICRO_OP_LOAD) &&\n        current.instr.value.r.opcode.opcode == RVG::LOAD;\n    if ((load || mul) && hart[current.hid].fetch_enable) {\n        hart[current.hid].micro_op.pending = current.instr.is_valid;\n    }\n    sim_assert(!hart[current.hid].micro_op.next_pc.is_valid);\n    hart[current.hid].micro_op.next_pc = make_optional(hart[current.hid].micro_op.pending, current.next_pc);\n    hart[current.hid].micro_op.pc = current.pc;\n    hart[current.hid].micro_op.instr = current.instr.value;\n    hart[current.hid].micro_op.end_tid = cast<tid_t>(mul\n        ? current_tid + MUL_MICRO_OPS * HARTS\n        : current_tid + LOAD_MICRO_OPS * HARTS);}\nelse{\n   const auto next_tid = cast<tid_t>(current_tid + HARTS);   \n hart[current.hid].micro_op.pending = next_tid != hart[current.hid].micro_op.end_tid;    } } \n    current.last_micro_op = !hart[current.hid].micro_op.pending; }\n    return current;\n}"}
{"file": "processor\\risc_v\\internal\\core.pd", "nl": "Read operand values from the register file.", "code": "inline Operands read(Current current, Decoded decoded) { Operands operands; operands.op1 = register_get(current.hid, decoded.format.rs1.value); operands.rs2 = register_get(current.hid, decoded.format.rs2.value); operands.op2 = decoded.format.rs2.is_valid ? operands.rs2 : decoded.format.imm; return operands; }"}
{"file": "processor\\risc_v\\internal\\core.pd", "nl": "Perform memory load operation.", "code": "inline int_t load(Current current, Decoded decoded, uint_t addr){\nconst auto value = dmem_read(current.hid, cast<dmem_addr_t>(addr));\nint_t b;\n int_t hw;\nint_t w = value;\n if (decoded.instr.mem.sign_extend) {\n    b = sign_extend(cast<uint8>(value));\n    hw = sign_extend(cast<uint16>(value));\n}\nelse\n{\n    b = cast<uint8>(value);\n    hw = cast<uint16>(value);\n}\n const auto dont_care = w;\nreturn mux(decoded.instr.mem.size, b, hw, w, dont_care);}"}
{"file": "processor\\risc_v\\internal\\core.pd", "nl": "Perform memory store operation.", "code": "inline void store(Current current, Decoded decoded, Operands in, Results results) { if (decoded.store && !results.mmio) {\n    sim_assert(!decoded.illegal);\n    sim_assert(addr_in_range<DMEM_ORIGIN, DMEM_LENGTH>(results.addr));\n    const auto bytes = checked_cast<dmem_t::byte_count_t>(1 << decoded.instr.mem.size);\n    dmem_write(current.hid, cast<dmem_addr_t>(results.addr), in.rs2, bytes);\n}\n}"}
{"file": "processor\\risc_v\\internal\\core.pd", "nl": "Write back result to the register file.", "code": "inline int_t write(Current current, Decoded decoded, int_t loaded, Results results) {\n    const int_t value = decoded.mul\n       ? MICRO_OP_MUL\n            ? hart[current.hid].micro_op.mul\n            : results.mul\n        : mux(decoded.kind,\n            results.compute,                                   // Compute\n             cast<int_t>((current.next_pc | IMEM_ORIGIN) << 2), // Control\n            loaded,                                            // Memory\n            results.csr);                                      // System\n  if (decoded.format.rd.is_valid) {\n    sim_assert(!decoded.illegal);\n    register_set(current.hid, decoded.format.rd.value, value);\n }\n  return value; }"}
{"file": "test\\unit.pd", "nl": "Add a test case that returns `true` for success and `false` for failure.", "code": "inline void check(() -> bool fn /*< Test case function */)\n{\n    static assert(Test == cast<id_t>(Test));\n    static assert(Group == cast<group_t>(Group));\n    static assert(Flags == cast<flags_t>(Flags));\n\n    test_case<Test, Group, Flags>([fn](tag_t tag)\n    {\n        return fn();\n    });\n}"}
{"file": "test\\unit.pd", "nl": "Add a test case that takes tag argument and uses the assert helpers to indicate failures.", "code": "inline void test((tag_t) -> void fn /*< Test case function */)\n{\n    static assert(Test == cast<id_t>(Test));\n    static assert(Group == cast<group_t>(Group));\n    static assert(Flags == cast<flags_t>(Flags));\n\n    test_case<Test, Group, Flags>([fn](tag_t tag)\n    {\n        return fn(tag);\n    });\n}"}
{"file": "test\\unit.pd", "nl": "Use the specified `Fixture` class to implement a test. A fixture used with `test` function must implement a public method `void run(tag_t tag)` and use asserts to indicate test failure. A fixture used with `check` must implement a public method `bool run()` that returns `true` for success and `false` for failure.", "code": "inline auto fixture()\n{\n    static if (decltype(Fixture::run) == () -> bool)\n    {\n        return []()\n        {\n            static Fixture test;\n            return test.run();\n        };\n    }\n    else\n    {\n        return [](tag_t tag)\n        {\n            static Fixture test;\n            test.run(tag);\n        };\n    }\n}"}
{"file": "test\\unit.pd", "nl": "The simple unit test framework allows defining test cases that can be conditionally included at compile time. Test cases are identified by tags and can be selected to be built/executed using two values specified via compiler `--define` option:  - tag - identifies a specific test to be included - mask - specifies a bit mask of tests to be included  A test is included in the build/execution if its tag is equal to specified tag, or if its tag is included in the bit mask. If both tag and mask are zero, which is the default, all tests are included.  Test tags are constructed from three parts:  - 12 bit test identifier - 4 bit group identifier - 16 bit flags  Only the test identifier is required. Group identifier and flags are optional and set to 0 by default.  Typical usage scenarios are:  - isolate a specific test to build/execute:  `--define tag=5`  - build/execute tests from a specific group, for example to make build/simulation smaller:  `--define mask=0x2FFF`  - build/execute a cross section of all tests with specified flag(s):  `--define mask=0x4FFFF`  Verbosity of the test framework output is controlled by boolean value `verbose` that can be defined via compiler `--define` command line option. With verbose output the framework prints information about all skipped and executed test cases. By default only information about failed test case(s) is printed.", "code": "template <id_t Test, group_t Group = 0, flags_t Flags = 0, typename TestResult>\ninline void test_case((tag_t) -> TestResult fn)\n{\n    static assert(Test != 0);\n\n    const auto T = Flags << (bitsizeof id_t + bitsizeof group_t);\n    const auto A = Group << (bitsizeof id_t);\n    const auto G = Test;\n\n    const uint32 tag = T | A | G;\n\n    sim_assert(tag == concat(cast<flags_t>(Flags), cast<group_t>(Group), cast<id_t>(Test)));\n\n    static if (((tag & Params::mask) == tag) || tag == Params::tag || (Params::tag == 0 && Params::mask == 0))\n    {\n        static if (Params::verbose)\n        {\n            println(\"Running test case\", tag);\n            barrier;\n        }\n\n        bool succeeded;\n\n        static if (TestResult == void)\n        {\n            fn({tag});\n            succeeded = true;\n        }\n        else\n        {\n            succeeded = fn({tag});\n\n            if (!succeeded)\n            {\n                print_failure({tag});\n                set_status({tag});\n            }\n        }\n\n        if (static(Params::verbose) && succeeded)\n        {\n            println(\"Test case\", tag, \"succeeded\");\n        }\n    }\n    else static if (Params::verbose)\n    {\n        println(\"Skipping disabled test case\", tag);\n    }\n\n    barrier;\n}"}
{"file": "test\\runner.pd", "nl": " The module is intended for running unit test in interpreter. It defines an entry point `main` which is called at reset and calls user defined function called `test_main`. `test_main` should return 0 if test succeeded or a non-zero error code on failure.  Verbosity of the test framework output is controlled by boolean value `verbose` that can be defined via compiler `--define` command line option. With verbose output the framework prints information about all executed tests. By default only information about failed test case(s) is printed.", "code": "[[reset, max_threads(1)]] void main(){\n auto result = test_main();\nif (result != 0) {\n    println(\"test_main() failed with error \", result);\n}\nelse if (Params::verbose) {\n    println(\"test_main() succeeded\");\n}\nbarrier;\nsim_assert(result == 0);}"}
{"file": "sync\\lock.pd", "nl": "Mutex: mutually exclusive lock. Call `lock` to acquire the mutex and `unlock` to release it. You would typically use this class in instances where you have code that implements a read-modify-write pattern on some variable(s) which takes multiple cycles to complete. In cases where this operation could be completed within a single clock cycle, you may consider instead putting the code in a function which internally uses the `atomic` keyword to encapsulate the read-modify-write.", "code": "bool _locked = false; // true means locked\ninline bool test_set()\n    {\n        bool result = false;\n\n        if (!_locked)\n        {\n            _locked = true;\n            result = true;\n        }\n\n        return result;\n    }"}
{"file": "sync\\lock.pd", "nl": "Atomically acquire the lock if it is not already acquired, or block waiting on the lock to be released.", "code": "void lock()\n    {\n        wait_for(test_set());\n    }"}
{"file": "sync\\lock.pd", "nl": "Release the lock.", "code": "void unlock()\n    {\n        sim_assert(_locked);\n        atomic\n        {\n            _locked = false;\n        }\n    }"}
{"file": "sync\\lock.pd", "nl": "Reader-Writer lock is a synchronization primitive that allows multiple threads to acquire a read-lock, but only one thread may have (any) lock if that thread has the write lock.", "code": "counter<MaxThreads, 0> _read_lock_counter;\n    bool _write_locked = false;\n\n    inline bool check_lock(bool is_reader)\n    {\n        bool result = false;\n        auto rlocks_used = _read_lock_counter.count();\n\n        if (is_reader)\n        {\n            result = !_write_locked && (rlocks_used < MaxThreads);\n        }\n        else\n        {\n            result = !_write_locked && (rlocks_used == 0);\n        }\n\n        // Update lock state\n        _read_lock_counter.add(cast<uint1>(result && is_reader));\n        _write_locked = (result && !is_reader);\n\n        return result;\n    }"}
{"file": "sync\\lock.pd", "nl": "Decrement the counter if the current count is greater or equal than `val`. This function is not inherently threadsafe and must be called from inside an `atomic` or `wait_for`.", "code": "inline bool test_and_decrement(sem_ctr_t val)\n    {\n        bool result = (_counter.count() >= val);\n        if (result)\n        {\n            _counter.subtract(val);\n        }\n\n        return result;\n    }"}
{"file": "sync\\lock.pd", "nl": "Decrement the semaphore count by 1 if it is nonzero otherwise block.", "code": "void wait()\n    {\n        wait_multiple(1);\n    }"}
{"file": "sync\\lock.pd", "nl": "Decrement the semaphore count by `val` if it is nonzero otherwise block.", "code": "void wait_multiple(sem_ctr_t val)\n    {\n        if (Blocking)\n        {\n            wait_for(test_and_decrement(val));\n        }\n        else\n        {\n            bool result;\n            atomic\n            {\n                result = test_and_decrement(val);\n            }\n            // Check for underflow\n            sim_assert(result);\n        }\n    }"}
{"file": "sync\\lock.pd", "nl": "Increment the semaphore count by 1, potentially waking a thread.", "code": "inline void post()\n    {\n        _counter.increment();\n    }"}
{"file": "sync\\lock.pd", "nl": "Return current value of semaphore. Provided primarily for debug/diagnostic purposes.", "code": "inline sem_ctr_t count()\n    {\n        return _counter.count();\n    }"}
{"file": "sync\\lock.pd", "nl": "Increment the semaphore count by the specified `amount`, potentially waking one or more threads.", "code": "void post_multiple(sem_ctr_t amount)\n    {\n        sim_assert((cast<sem_ctr_t>(_counter.count()) + amount) <= M);\n        _counter.add(amount);\n    }"}
{"file": "codec\\crypto\\aes_Intel.pd", "nl": "Carryless multiplier using Intel DSPs.", "code": "inline uint128 carryless_mult_dsp_64x64(uint64 a, uint64 b)\n{\n    return karatsuba_mult<uint128>(carryless_mult_dsp_32x32, xor, xor, a, b);\n}"}
{"file": "data\\buffer\\accumulating.pd", "nl": "Wrapper around array/memory with a configurable way to initial container contents.", "code": "template\n< typename T                                    //< Element type.\n, auto Size                                     //< Number of elements.\n, template <typename, auto> typename Container  //< Template used to store elements.\n, bool ResetWithInitialValues                   //< Reset the container with initial values.\n                                                // If false, then the container will be reset with a `[[reset]]` function.\n>\nclass ContainerWrapper {\nprivate:\nstatic if (ResetWithInitialValues) {\n    Container<T, Size> _container = {}; }\nelse {\nContainer<T, Size> _container;\n[[reset]] void reset() {\npipelined_for (Size, [](index_t<Size> i) {\n    _container[i] = {}; \n});    }}}}"}
{"file": "data\\fifo\\array.pd", "nl": "Dequeue a value from specified FIFO.", "code": "template\n< fifo_index_t FifoIndex //< The index of the FIFO to store into.\n>T dequeue_one()\n    {\n        // Validate the index (in case of a non-power of two ArraySize)\n        static assert(FifoIndex < ArraySize);\n\n        return _fifos[FifoIndex].dequeue();\n    }"}
{"file": "data\\fifo\\array.pd", "nl": "Enqueue a value into specified FIFO.", "code": "template\n< fifo_index_t FifoIndex //< The index of the FIFO to store into.\n>\nvoid enqueue_one\n( T value //< Value to store into the selected FIFO.\n) {\n// Validate the index (in case of a non-power of two ArraySize)\nstatic assert(FifoIndex < ArraySize);\n_fifos[FifoIndex].enqueue(value);\n}"}
{"file": "data\\fifo\\array.pd", "nl": "Enqueue zero or one values into each FIFO.", "code": "void enqueue_many\n ( optional<T>[ArraySize] values //< Array of values to store.  `is_valid` indicates if value should be stored.\n ) {\n  static for (const auto i : ArraySize)  {\n    if (values[i].is_valid) {\n       _fifos[i].enqueue(values[i].value);\n   }\n}}"}
{"file": "data\\fifo\\array.pd", "nl": "Enqueue one value into each FIFO.", "code": "void enqueue_all\n( T[ArraySize] values //< Array of values to store.\n) {\nstatic for (const auto i : ArraySize) {\n    _fifos[i].enqueue(values[i]);\n}\n}"}
{"file": "data\\fifo\\array.pd", "nl": "Dequeue zero or one values from each FIFO.", "code": "optional<T>[ArraySize] dequeue_many\n        ( bool[ArraySize] mask //< An array of boolean values, one per FIFO.\n                               // If `mask[i] == true`, then an element will be dequeued from FIFO `i`\n                               // and stored in the result array at index `i`.\n                               // If `mask[i] == false`, then element `i` in the result is undefined.\n        )\n    {\n        optional<T>[ArraySize] result = {};\n\n        static for (const auto i : ArraySize)\n        {\n            if (mask[i])\n            {\n                result[i] = make_optional(true, _fifos[i].dequeue());\n            }\n        }\n\n        return result;\n    }"}
{"file": "data\\fifo\\array.pd", "nl": "Dequeue one values from each FIFO.", "code": "T[ArraySize] dequeue_all() {\n T[ArraySize] result = {};\n static for (const auto i : ArraySize) {\n    result[i] = _fifos[i].dequeue(); }\nreturn result;}"}
{"file": "data\\random\\lfsr.pd", "nl": "A Linear Feedback Shift Register, which is a simple type of pseudo-random number generator. `lfsr_random` uses this function to generate successive pseudo-random numbers: pass any non-zero seed value into the initial call to the `lfsr` method, and then pass the returned value back in as the new seed on successive calls. The polynomial used for this LFSR will visit every value except zero. Never use zero as a seed, the LFSR will always return zero for a zero input. If you are looking for a traditional random number generator, this may not be a good choice because the LFSR will not revisit a value until it has visited all other $2^N-2$ values.", "code": "template <auto Width /*< The bit-width of the LFSR. Widths from 2 to 32 inclusive are supported.*/>\ninline uint<Width> lfsr(uint<Width> seed)\n{\n    static assert(Width >= 2 && Width <= 32);\n    sim_assert(seed != 0);\n\n    uint1[Width] bits = cast<uint1[Width]>(seed);\n    uint<Width-1> right = cast<uint<Width-1>>(seed);\n\n    uint<Width> result;\n\n    if (Width ==  2)\n    {\n        result = concat(right, bits[ 1] ^ bits[ 0]);\n    }\n    else if (Width ==  3)\n    {\n        result = concat(right, bits[ 2] ^ bits[ 1]);\n    }\n    else if (Width ==  4)\n    {\n        result = concat(right, bits[ 3] ^ bits[ 2]);\n    }\n    else if (Width ==  5)\n    {\n        result = concat(right, bits[ 4] ^ bits[ 2]);\n    }\n    else if (Width ==  6)\n    {\n        result = concat(right, bits[ 5] ^ bits[ 4]);\n    }\n    else if (Width ==  7)\n    {\n        result = concat(right, bits[ 6] ^ bits[ 5]);\n    }\n    else if (Width ==  8)\n    {\n        result = concat(right, bits[ 7] ^ bits[ 5] ^ bits[ 4] ^ bits[ 3]);\n    }\n    else if (Width ==  9)\n    {\n        result = concat(right, bits[ 8] ^ bits[ 4]);\n    }\n    else if (Width == 10)\n    {\n        result = concat(right, bits[ 9] ^ bits[ 6]);\n    }\n    else if (Width == 11)\n    {\n        result = concat(right, bits[10] ^ bits[ 8]);\n    }\n    else if (Width == 12)\n    {\n        result = concat(right, bits[11] ^ bits[ 5] ^ bits[ 3] ^ bits[ 0]);\n    }\n    else if (Width == 13)\n    {\n        result = concat(right, bits[12] ^ bits[ 3] ^ bits[ 2] ^ bits[ 0]);\n    }\n    else if (Width == 14)\n    {\n        result = concat(right, bits[13] ^ bits[ 4] ^ bits[ 2] ^ bits[ 0]);\n    }\n    else if (Width == 15)\n    {\n        result = concat(right, bits[14] ^ bits[13]);\n    }\n    else if (Width == 16)\n    {\n        result = concat(right, bits[15] ^ bits[14] ^ bits[12] ^ bits[ 3]);\n    }\n    else if (Width == 17)\n    {\n        result = concat(right, bits[16] ^ bits[13]);\n    }\n    else if (Width == 18)\n    {\n        result = concat(right, bits[17] ^ bits[10]);\n    }\n    else if (Width == 19)\n    {\n        result = concat(right, bits[18] ^ bits[ 5] ^ bits[ 1] ^ bits[ 0]);\n    }\n    else if (Width == 20)\n    {\n        result = concat(right, bits[19] ^ bits[16]);\n    }\n    else if (Width == 21)\n    {\n        result = concat(right, bits[20] ^ bits[18]);\n    }\n    else if (Width == 22)\n    {\n        result = concat(right, bits[21] ^ bits[20]);\n    }\n    else if (Width == 23)\n    {\n        result = concat(right, bits[22] ^ bits[17]);\n    }\n    else if (Width == 24)\n    {\n        result = concat(right, bits[23] ^ bits[22] ^ bits[21] ^ bits[16]);\n    }\n    else if (Width == 25)\n    {\n        result = concat(right, bits[24] ^ bits[21]);\n    }\n    else if (Width == 26)\n    {\n        result = concat(right, bits[25] ^ bits[ 5] ^ bits[ 1] ^ bits[ 0]);\n    }\n    else if (Width == 27)\n    {\n        result = concat(right, bits[26] ^ bits[ 4] ^ bits[ 1] ^ bits[ 0]);\n    }\n    else if (Width == 28)\n    {\n        result = concat(right, bits[27] ^ bits[24]);\n    }\n    else if (Width == 29)\n    {\n        result = concat(right, bits[28] ^ bits[26]);\n    }\n    else if (Width == 30)\n    {\n        result = concat(right, bits[29] ^ bits[ 5] ^ bits[ 3] ^ bits[ 0]);\n    }\n    else if (Width == 31)\n    {\n        result = concat(right, bits[30] ^ bits[27]);\n    }\n    else if (Width == 32)\n    {\n        result = concat(right, bits[31] ^ bits[21] ^ bits[ 1] ^ bits[ 0]);\n    }\n    else\n    {\n        sim_assert(false);\n    }\n\n    sim_assert(result != 0);\n\n    return result;\n}"}
{"file": "data\\random\\lfsr.pd", "nl": "Get the next random number in the sequence, optionally seeding the random number generator first. Do not use zero for the seed value.", "code": "value_t next(optional<uint<SeedWidth>> seed /*< If `is_valid` then seed the generator, otherwise ignore.*/)\n    {\n        sim_assert(!(seed.is_valid && (seed.value == 0)));\n\n        value_t new_value;\n\n        atomic\n        {\n            new_value = lfsr(from_optional(_value, seed));\n            _value = new_value;\n        }\n\n        return new_value;\n    }"}
{"file": "codec\\compression\\huffman.pd", "nl": "Given symbol frequencies in `_freqs[]`, compute the optimal Huffman code to be stored in `_codebook[]`. Return false if a new Huffman code could not be computed due to one or more codes exceeding `maxCodeLength`.", "code": "inline bool compute\n( count_t<NumSymbols> numSymbols\n, codeLength_t maxCodeLength\n, bool universal                 //< Flag indicating whether a code\n                                 // should be assigned to all symbols,\n                                 // even if they had zero frequency.\n                                 // Its utility is to allow a codebook\n                                 // to be computed that is able to\n                                 // handle all possible symbols, even\n                                 // those that were not originally\n                                 // observed, and is implemented by\n                                 // forcing all symbols to have a\n                                 // minimum frequency of one.\n) {\n_validTag = 0;\n// Build the Huffman tree\ntreeBuilder.build(max(numSymbols, maxCodeLength), numSymbols, maxCodeLength, universal);\nbool failed = treeBuilder.get_failed();\n// Assign each symbol its code according to RFC1951\ncompute_next_code_and_assign(!failed ? maxCodeLength + numSymbols : 0, maxCodeLength);\nreturn failed;}"}
{"file": "codec\\compression\\huffman.pd", "nl": "Unsigned integer type for counting the frequency a particular code length occurs. The worst case would be if all symbols had the same code length.", "code": "using codeLengthFreq_t = count_t<NumSymbols>;\n[[pipelined]] void reset(index_t<NumSymbols> tid) {\n    static assert(NumSymbols > MaxCodeLength);\n    _codebook[tid] = {0, 0};\n    _freqs[tid] = {};\n}"}
{"file": "codec\\compression\\huffman.pd", "nl": "Given symbol frequencies in `_freqs[]`, compute the optimal Huffman code to be stored in `_codebook[]`. Should the Huffman computation fail (e.g. if a code is found to exceed `maxCodeLength`) then the frequency of all symbols should be halved (passed through `max(1, old_freq >> 1)`) before retrying.", "code": "inline bool compute_with_retry\n( count_t<NumSymbols> numSymbols\n, codeLength_t maxCodeLength\n, bool universal                 //< Flag indicating whether a code\n                             // should be assigned to all symbols,\n                              // even if they had zero frequency.\n                              // Its utility is to allow a codebook\n                               // to be computed that is able to\n                              // handle all possible symbols, even\n                               // those that were not originally\n                                // observed, and is implemented by\n                                // forcing all symbols to have a\n                                 // minimum frequency of one.\n) {\n_validTag = 0;\n// Build the Huffman tree\nbool failed;\ndo {\n   treeBuilder.build(max(numSymbols, maxCodeLength), numSymbols, maxCodeLength, universal);\n   _validTag = ~_validTag;\n    failed = treeBuilder.get_failed();\n } while (failed);\n// Assign each symbol its code according to RFC1951\n compute_next_code_and_assign(!failed ? maxCodeLength + numSymbols : 0, maxCodeLength);\n return failed;}"}
{"file": "codec\\compression\\huffman.pd", "nl": "Number of codewords with given length. This memory is read in mutually exclusive fashion by treeBuilder_t::compute_code_lengths() and compute_next_code_and_assign()", "code": "memory_norep<codeLengthFreq_t, MaxCodeLength + 1> _codeLengthFreq;\nmemory<codeBits_t, MaxCodeLength + 1> _nextCode;\n[[pipelined]] void compute_next_code_and_assign(index_t<MaxCodeLength + NumSymbols> tid, codeLength_t maxCodeLength) {\n    auto nextCodeLength = tid + 1;\n    auto nextCodeLengthFreq = _codeLengthFreq[tid];\n    auto tid_minus_maxCodeLength = tid - maxCodeLength;\n    symbol_t assignCodeSym = tid_minus_maxCodeLength;\n    auto assignCode = code(assignCodeSym);\n    if (tid == 0) {\n        sim_assert(nextCodeLengthFreq == 0);\n        _nextCode[0] = 0; }\n    atomic {\n        auto readAddr = (tid_minus_maxCodeLength < 0) ? tid : assignCode.length;\n        auto snappedNextCode = _nextCode[readAddr];\n        index_t<MaxCodeLength + 1> writeAddr;\n        codeBits_t writeValue;\n        if (tid_minus_maxCodeLength < 0) {\n            // ADAPTED FROM https://www.ietf.org/rfc/rfc1951.txt\n            // 2)  Find the numerical value of the smallest code for each\n            //     code length.\n            writeAddr = nextCodeLength;\n            writeValue = (snappedNextCode + nextCodeLengthFreq) << 1; }\n        else if (assignCode.length != 0) {\n            // ADAPTED FROM https://www.ietf.org/rfc/rfc1951.txt\n            // 3)  Assign numerical values to all codes, using consecutive\n            //     values for all codes of the same length with the base\n            //     values determined at step 2. Codes that are never used\n            //     (which have a bit length of zero) must not be assigned a\n            //     value.\n             assignCode.code = snappedNextCode;\n            writeAddr = assignCode.length;\n             writeValue = snappedNextCode + 1;\n         }\n         _nextCode[writeAddr] = writeValue;\n     }\n     if (tid_minus_maxCodeLength >= 0 && assignCode.length != 0)\n         _codebook[assignCodeSym] = assignCode;\n }"}
{"file": "codec\\compression\\huffman.pd", "nl": "An asynchronous worker that iterates over parent<>._freqs[] to find the smallest \"SorterWidth\" symbols to  be used as leaves", "code": " [[async, pipelined, max_threads(1)]] void sort_leaves_async(index_t<MaxSorterPasses> tid,\n                                                            count_t<NumSymbols> numSymbols,\n                                                            bool universal)\n//                  ^^^^^^^^^^^^^^ Necessary to enforce dependency between subsequent invocations of\n//                                 sort_leaves_pipeline() each thread of which must complete (and invalidate\n//                                 the smallest values found) before the next can begin {\nstatic bool done;\nif (tid == 0) {\n    sim_assert(_sortedLeaves.count() == 0);\n    done = false;\n}\nif (!done) {\n    sort_leaves_pipeline(numSymbols + SorterWidth + 2, numSymbols, universal);\n    done = !_smallestLeaves[SorterWidth - 1].is_valid;\n}}"}
{"file": "codec\\compression\\huffman.pd", "nl": "A pipeline of \"SorterWidth\" (atomic) stages, each of which does a compare-and-swap if the current symbol is smaller than the smallest one seen so far. After scanning all symbols, enqueue the smallest ones into the _sortedLeaves FIFO.", "code": "[[pipelined]] void sort_leaves_pipeline(index_t<NumSymbols + SorterWidth + 2> tid, count_t<NumSymbols> numSymbols, bool universal){\n    if (tid < numSymbols) {\n        auto is_first = (tid == 0);\n        auto is_last = (tid == numSymbols - 1);\n        auto freq = _freqs[tid];\n        auto validTag = _validTag;\n        node_t leaf = {tid, (freq.tag == validTag) ? (freq.value != 0) ? freq.value\n                                                                       : (universal) ? 1 : InvalidLeafFreq\n                                                   : InvalidLeafFreq};\n        auto result = partial_sort<SorterWidth>(leaf,\n                                                [](node_t lhs, node_t rhs) { return lhs.freq < rhs.freq; },\n                                                is_last);\n        static for(const auto i : SorterWidth) {\n            _smallestLeaves[i].is_valid = result[i].is_valid && (result[i].value.freq != InvalidLeafFreq);\n            _smallestLeaves[i].value = result[i].value;\n        }\n        barrier;\n    }\n    else {\n        // After all symbols have been scanned, use the last SorterWidth + 2 threads for enqueue-ing\n        auto localTid = tid - numSymbols;\n        sim_assert(localTid < SorterWidth + 2);\n        // Saturate at the last leaf\n        auto leaf = _smallestLeaves[localTid < SorterWidth ? localTid : SorterWidth - 1];\n        if ((localTid < SorterWidth && leaf.is_valid) ||  // Enqueue leaves as normal\n            (localTid >= SorterWidth && !leaf.is_valid))  // For the last two threads, enqueue the last\n                                                          // leaf only if it is invalid {\n            _sortedLeaves.enqueue(leaf.value);\n            auto invalidTag = ~_validTag;\n            // Remember to invalidate any processed valid leaves so that they don't get picked up again\n            // (also writuing back the divided-in-half frequency for potential retries)\n            if (leaf.is_valid)\n                _freqs[leaf.value.ptr] = { invalidTag, max(1, leaf.value.freq >> 1) };\n        }\n    }\n}"}
{"file": "codec\\compression\\huffman.pd", "nl": "// Merge both leaf symbols into a new interior node", "code": "inline treeNode_t merge_leaf_leaf() {\n    sim_assert(_leaf[0].is_valid && _leaf[0].value.freq != InvalidLeafFreq);\n    sim_assert(_leaf[1].is_valid && _leaf[1].value.freq != InvalidLeafFreq);\n    sim_assert(_leaf[0].value.freq + _leaf[1].value.freq <= MaxTreeNodeFreq);\n    treeNode_t t;\n    t.left = _leaf[0].value.ptr;\n    t.leftIsLeaf = true;\n    t.right = _leaf[1].value.ptr;\n    t.rightIsLeaf = true;\n    t.freq = _leaf[0].value.freq + _leaf[1].value.freq;\n    _leaf[0].is_valid = false;\n    _leaf[1].is_valid = false;\n    return t;}"}
{"file": "codec\\compression\\huffman.pd", "nl": "Merge both interior nodes into a new interior node", "code": "inline treeNode_t merge_interior_interior() {\nsim_assert(_interior[0].freq != InvalidInteriorFreq);\nsim_assert(_interior[1].freq != InvalidInteriorFreq);\nsim_assert(_interior[0].freq + _interior[1].freq <= MaxTreeNodeFreq);\ntreeNode_t t;\nt.left = _interior[0].ptr;\nt.leftIsLeaf = false;\nt.right = _interior[1].ptr;\nt.rightIsLeaf = false;\nt.freq = _interior[0].freq + _interior[1].freq;\n// Pop both interior nodes by invalidating them\n// (will get updated by the outer function)\n_interior[0].freq = InvalidInteriorFreq;\n_interior[1].freq = InvalidInteriorFreq;\nreturn t;}"}
{"file": "codec\\compression\\huffman.pd", "nl": "Merge one leaf and one tree node into a new interior node", "code": "inline treeNode_t merge_leaf_interior() {\n    sim_assert(_leaf[0].is_valid && _leaf[0].value.freq != InvalidLeafFreq);\n    sim_assert(_interior[0].freq != InvalidInteriorFreq);\n    sim_assert(_leaf[0].value.freq + _interior[0].freq <= MaxTreeNodeFreq);\n    treeNode_t t;\n    t.left = _leaf[0].value.ptr;\n    t.leftIsLeaf = true;\n    t.right = _interior[0].ptr;\n    t.rightIsLeaf = false;\n    t.freq = _leaf[0].value.freq + _interior[0].freq;\n    // Back node is now front; invalidate back so that it gets updated\n    sim_assert(_leaf[1].is_valid);\n    _leaf[0] = _leaf[1];\n    _leaf[1].is_valid = false;\n    // Back node is now front; invalidate back so that it gets updated\n    _interior[0] = _interior[1];\n    _interior[1].freq = InvalidInteriorFreq;\n    return t;}"}
{"file": "data\\fifo\\transpose.pd", "nl": "Write one row into the FIFO. Block if FIFO is full and `EnqueueBlocking` is true.", "code": "void enqueue(array_t values)\n    {\n        // Block until there is room for one more array\n        _write_semaphore.wait();\n\n        // Get the value of the write pointer, and increment the write pointer\n        decomposed_addr producer_index = increment_address(1);\n\n        // Store the values into the memories\n        static for (const auto i : ArraySize)\n        {\n            index_t<ArraySize> select = i - producer_index.index_within_square;\n\n            _data_memories[i][producer_index.square_base + select] = values[select];\n        }\n\n        if (producer_index.index_within_square == (ArraySize - 1))\n        {\n            // Allow an entire square to be dequeued\n            _read_semaphore.post_multiple(ArraySize);\n        }\n    }"}
{"file": "data\\fifo\\transpose.pd", "nl": "Read one column from FIFO. Block if FIFO is empty and `DequeueBlocking` is true.", "code": "array_t dequeue()\n    {\n        return dequeue_and_discard(0);\n    }"}
{"file": "data\\fifo\\transpose.pd", "nl": "Read one column from FIFO and discard `discard_column_count` subsequent columns from the same square.", "code": "array_t dequeue_and_discard(index_t<ArraySize> discard_column_count)\n    {\n        count_t<ArraySize> total_column_count = discard_column_count + 1;\n\n        // Block the calling thread until the containing square is available\n        _read_semaphore.wait_multiple(total_column_count);\n\n        // Get the value of the read pointer, and increment the read pointer\n        decomposed_addr consumer_index = increment_address(total_column_count);\n\n        // Read one element from each memory\n        array_t result;\n\n        static for (const auto i : ArraySize)\n        {\n           result[i] = _data_memories[i][consumer_index.array_index];\n        }\n\n        // The memory addressing and muxing that occurs during a write gets the data\n        // in almost the desired form.  Each element of the output array is in 1 memory\n        // but output element 'i' might be in memory 'j'.  A rotation addresses this.\n        result = rotate_array_right<ArraySize>(result, consumer_index.index_within_square);\n\n        auto array_end = consumer_index.index_within_square + total_column_count;\n\n        // discard_count can only be used to discard values within the same square\n        sim_assert(array_end <= ArraySize);\n\n        if (array_end == ArraySize)\n        {\n            // An entire square has been dequeued\n            _write_semaphore.post_multiple(ArraySize);\n        }\n\n        return result;\n    }"}
{"file": "data\\fifo\\transpose.pd", "nl": "ArraySize must be a power of 2", "code": "static assert(0 == (ArraySize & (ArraySize - 1)));"}
{"file": "data\\fifo\\transpose.pd", "nl": "ArrayDepth must be a power of 2", "code": "static assert(0 == (ArrayDepth & (ArrayDepth - 1)));"}
{"file": "data\\memory\\byte_addressable.pd", "nl": "Read a word from a word aligned address", "code": "inline word_t read_aligned(addr_t addr)\n    {\n        return cast<word_t>(mem.read_aligned(addr));\n    }"}
{"file": "data\\memory\\byte_addressable.pd", "nl": "Read a word from N-byte aligned address", "code": "template <auto N = 1>\n    inline word_t read(addr_t addr)\n    {\n        return cast<word_t>(mem.read<N>(addr));\n    }"}
{"file": "data\\memory\\byte_addressable.pd", "nl": "Write a word to a word aligned address", "code": "inline void write_aligned(addr_t addr, word_t word)\n    {\n        mem.write_aligned(addr, cast<uint8[BytesPerWord]>(word));\n    }"}
{"file": "data\\memory\\byte_addressable.pd", "nl": "Write specified number of bytes to an N-byte unaligned address. The `size` must be a multiple of `N` and no greater than `bytesizeof T`.", "code": "template <auto N = 1>\n    inline void write(addr_t addr, word_t value, byte_count_t size)\n    {\n        mem.write<N>(addr, cast<uint8[BytesPerWord]>(value), size);\n    }"}
{"file": "data\\fifo\\wide_to_narrow.pd", "nl": "Write one entry to the FIFO. Block if FIFO is full and `EnqueueBlocking` is true.", "code": "void enqueue(array_t values)\n    {\n        // Block until there is room for an entire array\n        _write_semaphore.wait_multiple(ArraySize);\n\n        // Get the value of the write pointer, and increment the write pointer\n        array_pointer_t snapped_producer_index;\n\n        atomic\n        {\n            static array_pointer_t _producer_index = 0;\n            snapped_producer_index = _producer_index;\n            _producer_index = modular::increment(_producer_index);\n        }\n\n        // Store the values into the memory\n        _data_mem[snapped_producer_index] = values;\n\n        // Allow ArraySize more calls to dequeue\n        _read_semaphore.post_multiple(ArraySize);\n    }"}
{"file": "data\\fifo\\wide_to_narrow.pd", "nl": "Read one entry from FIFO. Block if FIFO is empty and `DequeueBlocking` is true.", "code": "T dequeue()\n    {\n        return dequeue_and_discard(0);\n    }"}
{"file": "data\\fifo\\wide_to_narrow.pd", "nl": "Read one entry from FIFO and discard `discard_count` subsequent entries. Block if FIFO is empty and `DequeueBlocking` is true.", "code": "T dequeue_and_discard(index_t<ArraySize> discard_count)\n    {\n        count_t<ArraySize> total_count = discard_count + 1;\n\n        // Block the calling thread until an entry is available\n        _read_semaphore.wait_multiple(total_count);\n\n        // Get the value of the read pointer, and increment the read pointer\n        scalar_pointer_t snapped_consumer_index;\n\n        atomic\n        {\n            static scalar_pointer_t _consumer_index = 0;\n            snapped_consumer_index = _consumer_index;\n            _consumer_index = modular::add(_consumer_index, total_count);\n        }\n\n        // Decompose snapped_consumer_index into\n        // 1) index into _data_mem\n        // 2) index into resulting array\n        index_t<ArrayDepth> index_into_mem = snapped_consumer_index / ArraySize;\n\n        index_t<ArraySize> index_within_array = snapped_consumer_index;\n\n        // Read an array from the memory\n        array_t results = _data_mem[index_into_mem];\n\n        // Select 1 element from the array\n        T result = results[index_within_array];\n\n        // Now that the read has occured, allow another thread to overwrite the data\n        _write_semaphore.post_multiple(total_count);\n\n        return result;\n    }"}
{"file": "numeric\\int\\limits.pd", "nl": "Numeric limit constants for integer types", "code": "template<typename T>\nclass limits\n{\npublic://| Indicates whether the type is signed\nconst bool is_signed = cast<T>(-1) < 0;\n//| Smallest value of the type\nconst T min = is_signed ? 1 << (bitsizeof T - 1) : 0;\n//| Largest value of the type\nconst T max = cast<T>(min - 1);}"}
{"file": "numeric\\complex.pd", "nl": "Complex number", "code": "template<typename T> \nstruct complex\n{\n\tT real_part;\n\tT imag_part;\n}"}
{"file": "data\\memory\\multi_port.pd", "nl": "Read from the memory at the address index. The value most recently  written among all ports will be read back.", "code": "inline T read(element_index_t index)\n    {\n        // Read from all memory banks\n        T[WritePorts] read_results;\n\n        static for (const auto i : WritePorts)\n        {\n            read_results[i] = _memories[i][index];\n        }\n\n        // The value in the most recently written bank gets returned.\n        port_index_t which_port = _which_port[index];\n\n        return read_results[which_port];\n    }"}
{"file": "data\\memory\\multi_port.pd", "nl": "Write a value into the memory at address index using port `port_index`.", "code": "template<port_index_t port_index>\n    inline void write(element_index_t index, T data)\n    {\n        //Writes on port N go into memory bank N.  The _which_port array tracks which\n        // bank has the most recent value for each address.\n        _memories[port_index][index] = data;\n        _which_port[index] = port_index;\n    }"}
{"file": "data\\memory\\multi_port.pd", "nl": "Memory with multiple write ports that can support concurrent writes to different addresses. The caller must synchronize to ensure there are not concurrent writes to the same address. This differs from memories generated by the compiler, which can support concurrent reads but not concurrent writes, i.e. if concurrent writes are attempted, even to different addresses, all but one is dropped.", "code": "Memory<T, Depth>[WritePorts] _memories;\n    // Track which bank has the most recently written value for each address\n    port_index_t[Depth] _which_port;\n\npublic:\n    using element_index_t = index_t<Depth>;"}
{"file": "data\\counter\\saturating.pd", "nl": "Increment-only counter that will saturate rather than overflow.", "code": "template<auto Width>\nclass saturating_counter\n{\npublic:\n    using count_t=uint<Width>;\n\nprivate:\n    count_t _count = 0;\n\npublic:"}
{"file": "data\\counter\\saturating.pd", "nl": "Increment the counter with an optional clear before increment. Return the value _before_ the increment/clear. Returning the value before clear is useful when offloading the value to some external store, for example periodic sampling of performance counters.", "code": "count_t increment(count_t inc_amount, bool clear_before_inc)\n    {\n        uint<Width+1> new_value;\n        count_t result;\n\n        atomic\n        {\n            result = _count;\n            if (clear_before_inc)\n            {\n                new_value = inc_amount;\n            }\n            else\n            {\n                new_value = min(_count + inc_amount, limits<uint<Width>>::max);\n            }\n\n            _count = cast<count_t>(new_value);\n        }\n\n        return result;\n    }"}
{"file": "data\\counter\\saturating.pd", "nl": "Get the current value of the counter.", "code": "inline count_t get()\n    {\n        return _count;\n    }"}
{"file": "hardware\\dram.pd", "nl": "A wrapper over the external Verilog interface to FPGA on-board DRAM.", "code": "inline void AssertAlignment(uint64 addr, transaction_size_t size)\n    {\n        sim_assert(0 == (addr % 64));\n        sim_assert(0 == (size % 64));\n    }    // Check that is_last is set for last flit and not set for other flits.inline void AssertIsLast(transaction_size_t size, bool is_last) {\n    // A single atomic is used to reduce impact on pipeline stages\n    atomic {\n        // Get whether this is the first flit in a transaction\n        static bool _is_first = true;\n        bool is_first = _is_first; \n        _is_first = is_last;\n        // Get size after this flit\n        static transaction_size_t _remaining_size;\n        if (is_first) {\n            _remaining_size = size;\n        }\n        _remaining_size -= 64;\n        // is_last should only be set on last flit\n        if (_remaining_size == 0) {\n            sim_assert(is_last);\n        }\n       else {\n            sim_assert(!is_last);\n        }\n    }\n}"}
{"file": "hardware\\dram.pd", "nl": "Read one or more 512b words from DRAM. The first call to this function establishes the base address and size of the read transaction. You should call it N times, where N is the number of 64B words necessary to fulfill the byte-length specified by `size`.", "code": "inline uint512 Read\n( uint64 addr             //< Byte address of the DRAM word to read.\n                          // This address must be 64B aligned (lower 6 bits zero).\n, transaction_size_t size //< Size of the read, in bytes.\n, bool is_last            //< Set to true on the last read of the transaction, false otherwise.\n                          // This parameter guarantees that data read from two different DRAM\n                          // transactions are not inadvertently interleaved.\n) { AssertAlignment(addr, size);\n        AssertIsLast(size, is_last);\n\n        return _dram.read(addr, size, is_last);\n    }"}
{"file": "hardware\\dram.pd", "nl": "Write one or more 512b words from DRAM. The first call to this function establishes the base address and size of the write transaction. You should call it N times, where N is the number of 64B words necessary to fulfill the byte-length specified by `size`.", "code": "inline void Write\n    ( uint64 addr             //< Byte address of the DRAM word to write.\n                              // This address must be 64B aligned (lower 6 bits zero).\n    , transaction_size_t size //< Size of the write, in bytes.\n    , uint512 data\n    , bool is_last            //< Set to true on the last write of the transaction, false otherwise.\n                              // This parameter guarantees that data written from two different DRAM\n                              // transactions are not inadvertently interleaved.\n    )\n{AssertAlignment(addr, size);\n        AssertIsLast(size, is_last);\n\n        bool[64] byte_enable = replicate<64>(true);\n\n        _dram.write(addr, size, data, cast<uint64>(byte_enable), is_last);\n    }"}
{"file": "hardware\\dram.pd", "nl": "Selectively write bytes to DRAM. Note that calls to this function with any bytes disabled can result in significantly reduced throughput on some platforms.", "code": "inline void WriteBytes( uint64 addr               //< Transaction base address (must be 64-byte aligned).\n, transaction_size_t size   //< Transaction size in bytes (must be 64-byte aligned).\n, uint512 data              //< Data to write.\n, bool[64] byte_enable      //< byte_enable[i] is set to true if byte \"i\" should be written to DRAM.\n, bool is_last              //< True if this is the last write in a transaction.\n) {AssertAlignment(addr, size);\n        AssertIsLast(size, is_last);\n\n        _dram.write(addr, size, data, cast<uint64>(byte_enable), is_last);\n    }"}
{"file": "hardware\\dram.pd", "nl": "// Reads a 64B value, interleaving a global address space among channels", "code": "uint512 ReadUnified64(uint64 addr){\n    DecomposedAddress decomposedAddr = cast<DecomposedAddress>(addr);\n    uint512 result;\n    static for(const auto i : NUM_DRAM_CHANNELS) {\n        if (i == decomposedAddr._channelIndex)\n        {\n            result = DramChannels[i].Read(decomposedAddr._addressWithinChannel * 64, 64, true);\n        }\n    }\n    return result;}"}
{"file": "data\\random\\toeplitz.pd", "nl": "Get the next random number in the sequence, optionally seeding", "code": "toeplitz<PipelineCycles, Width, Width, KeyWidth, Key> _hash;\nuint<Width> _counter = 1;\nuint<Width> next\n        ( bool set_seed    //< If true, the random number will be seeded with the specified seed.\n        , uint<Width> seed //< The number to seed the random number generator. Ignored if `set_seed` is false.\n        )\n    {\n        uint<Width> counter;\n\n        atomic\n        {\n            counter = set_seed ? seed : _counter;\n\n            _counter = modular::increment(counter);\n        }\n\n        return _hash.calc_hash(counter);\n    }"}
{"file": "data\\random\\toeplitz.pd", "nl": "Calculate the Toeplitz hash of the supplied data.", "code": "Hash_t calc_hash(Data_t data)\n    {\n        // Call a \"pipelined\" function to calculate the hash of an portion of the input data.\n        // This lowers the issue rate (to 1:PipelineCycles), but should help with the size\n        // of the implementation.\n        Hash_t[PipelineCycles] hashChunks;\n        hashChunks = calc_hash_chunk(PipelineCycles, data);\n\n        const auto PartialHashesLength = 1 << clog2(PipelineCycles);\n        Hash_t[PartialHashesLength] partialHashes;\n\n        static for(const auto i : PipelineCycles)\n        {\n            partialHashes[i] = hashChunks[i];\n        }\n\n        const auto ReductionTreeDepth = clog2(PipelineCycles);\n        static for(const auto i : ReductionTreeDepth)\n        {\n            static for(const auto j : PartialHashesLength / 2)\n            {\n                partialHashes[j] = partialHashes[2*j] ^ partialHashes[2*j+1];\n            }\n        }\n\n        return partialHashes[0];\n    }"}
{"file": "data\\random\\toeplitz.pd", "nl": "Implementation of the Toeplitz hash algorithm as described // [here](https://en.wikipedia.org/wiki/Toeplitz_Hash_Algorithm). Input data is passed into `calc_hash` as one parallel data structure. If you need a key, a secure rng is a reasonable method of producing one. Here is a 256 byte key produced with the default Windows RNGCryptoServiceProvider. You can truncate it to whatever length you need.", "code": "static assert(KeyWidth >= HashWidth);\n    static assert(PipelineCycles > 0);\n\nprivate:\n    const auto DataChunkWidth = (DataWidth + PipelineCycles-1) / PipelineCycles; // Width of input data handled per \"thread\" in [[pipelined]] function _CalcHash\n    const auto TidWidth = (PipelineCycles < 2) ? 1 : clog2(PipelineCycles);\n\n    using Tid_t=uint<TidWidth>;\n    using DataChunk_t=uint<DataChunkWidth>;\n\n    inline Key_t rotate_key_left(Key_t key)\n    {\n        uint1 msb = key >> (KeyWidth-1);\n        uint<KeyWidth-1> lsbs = cast<uint<KeyWidth-1>>(key);\n\n        return concat(lsbs, msb);\n    }"}
{"file": "data\\random\\toeplitz.pd", "nl": "Extracts chunk of input data to process for the specified pipeline thread\n// Data is extracted MSB first, per Toeplitz algorithm description.//// Example calculation:\n//      DataWidth = 25\n//      PipelineCycles = 3\n//      DataChunkWidth = 9\n//\n//             ------- Input Data ------\n//             1111111110000000000000000xx\n//             876543210FEDCBA9876543210xx\n//       tid   ---Aligned Input Data----    <rshift><lshift>\n//        0    xxxxxxxxx                      16        0\n//        1             xxxxxxxxx              7        0\n//        2                      xxxxxxx00     0        2\n//\n//      rshift = DataWidth - (tid+1)*DataChunkWidth\n//      lshift = (tid == PipelineCycles-1) ? (DataChunkWidth - DataWidth/PipelineCycles) : 0", "code": "inline DataChunk_t extract_data_chunk(Data_t data, Tid_t tid){\n    // Toeplitz processes high order bits first, so chunk\n    // number 0 is left-most. If DataWidth is not an even multiple of PipelineCycles\n    // we left shift the input data to add LSB zero padding.\n    const auto PadBits = PipelineCycles * DataChunkWidth - DataWidth;\n    const auto rShiftBits = DataWidth + PadBits - (tid+1)*DataChunkWidth;\n    const uint<DataWidth+PadBits> paddedData = data << PadBits;\n    return cast<DataChunk_t>(paddedData >> rShiftBits); }"}
{"file": "data\\random\\toeplitz.pd", "nl": "Calculates a key rotated to account for the chunk offset within the input data.\n// Rotation is accomplished by shifting a doubly large key\n// Example calculation:\n//    DataChunkWidth = 9\n//    KeyWidth = 16\n//    HashWidth = 12\n//\n//----------Doubled Key-----------\n//          FEDCBA9876543210FEDCBA9876543210\n//\n//    tid   -----Aligned Key for Hash------- <shift>\n//     0                    xxxxxxxxxxxxxxxx    0\n//     1             xxxxxxxxxxxxxxxx           7\n//     2      xxxxxxxxxxxxxxxx                 14\n//     3               xxxxxxxxxxxxxxxx         5\n//\n//    shift = (2*KeyWidth - ((DataChunkWidth*tid)%KeyWidth))%KeyWidth\n", "code": "inline Key_t offset_key(Tid_t tid) {\n    const uint<KeyWidth*2> DoubledKey = concat(cast<uint<KeyWidth>>(Key),cast<uint<KeyWidth>>(Key));\n    return cast<Key_t>( DoubledKey >> ((2*KeyWidth - ((DataChunkWidth*tid)%KeyWidth))%KeyWidth) );inline bool bit_at(DataChunk_t data, index_t<DataChunkWidth> pos){\n    return ((data >> pos) & 0x1) != 0; }\n[[pipelined]] Hash_t calc_hash_chunk(Tid_t tid, Data_t data) {\n    // Figure out the starting offset within the key for all threads,\n    // and then select the offset for this thread using the thread id\n    // as an index. We do it this way so that the key is actually\n    // \"baked into the LUTs\" rather than being implemented as a\n    // separate large register and associated logic.\n    Key_t[PipelineCycles] offsetKeys;\n    static for(const auto i : PipelineCycles) {\n        offsetKeys[i] = offset_key(i);\n    }\n    Key_t offsetKey = offsetKeys[tid];\n    // Extract the portion of the input data we process in this thread\n    // Toeplitz processes high order bits first, so we start with\n    // leftmost bits of data word in tid=0, and move rightwards\n    DataChunk_t dataChunk = extract_data_chunk(data, tid);\n    // Array is rounded up to power of two because of the reduction loop below\n    const auto PartialHashesLength = (1 << clog2(DataChunkWidth));\n    Hash_t[PartialHashesLength] partialHashes;\n    // Use the input data to calculate intermediate values. A one bit in the\n    // input data means we XOR the result (which starts out as zero) with the\n    // left-most bits of the key, a zero value means we do nothing.\n    static for(const auto i : DataChunkWidth)  {\n        if (bit_at(dataChunk, DataChunkWidth-i-1))  {\n            partialHashes[i] = hash_align_and_truncate_key(offsetKey);  }\n        offsetKey = rotate_key_left(offsetKey);\n    }\n    // Now combine the intermediate hash results by XOR-ing them together\n    const auto ReductionTreeDepth = clog2(DataChunkWidth);\n    static for(const auto i : ReductionTreeDepth) {\n        static for(const auto j : PartialHashesLength / 2) {\n            // Binary reduction tree. The hope is the compiler should\n            // convert this to quatenary for us since the FPGA LUTs\n            // support that.\n            partialHashes[j] = partialHashes[2*j] ^ partialHashes[2*j+1];\n        }\n    }\n    return partialHashes[0];\n}"}
{"file": "debug\\assert.pd", "nl": "Hardware runtime assertion. If `assert(false, ...)` is called then an inspectable boolean is set to true. This sticky bit can be read through the standard inspection mechanisms. This version does not generate a `sim_assert` and is primarily used for testing the hardware assertion.", "code": "inline void hw_assert\n( bool shouldBeTrue        //< A boolean expression which should always evaluate\n                           // to true otherwise the assertion fires.\n, const string description //< String associated with the inspectable.)\n{\nstatic bool assertionHit = false;\ninspectable(assertionHit, description);\n\n    if (!shouldBeTrue)\n    {\n        println(\"Assertion failure: \", description);\n\n        assertionHit = true;\n    } \n}"}
{"file": "debug\\assert.pd", "nl": "Runtime assertion. If `assert(false, ...)` is called then an inspectable boolean is set to true. // This sticky bit can be read through the standard inspection mechanisms. A `sim_assert` is also executed.", "code": "inline void assert\n( bool shouldBeTrue        //< A boolean expression which should always evaluate\n                           // to true otherwise the assertion fires.\n , const string description //< String associated with the inspectable.\n)\nhw_assert(shouldBeTrue, description);\n    sim_assert(shouldBeTrue);\n}"}
{"file": "debug\\trace_buffer.pd", "nl": "Write one event to the circular buffer.", "code": "void write(entry_type event)\n    {\n        pointer_type write_pointer;\n\n        atomic\n        {\n            write_pointer = _write_pointer;\n            _write_pointer++;\n        }\n\n        // write_pointer arithmetic should wrap\n        sim_assert(write_pointer < depth);\n\n        // if write_pointer is -1, _write_pointer has wrapped to 0\n        if (write_pointer == cast<pointer_type>(-1))\n        {\n            _write_wrapped = true;\n        }\n\n        _log[write_pointer] = event;\n    }"}
{"file": "debug\\trace_buffer.pd", "nl": "Circular buffer of events. The buffer contents, the value of the next index to be written, and whether the buffer has wrapped around are inspectable. This can be used to determine which entries have valid data and their order.", "code": "template\n< typename entry_type //< The type of an event record in the buffer.\n, auto depth          //< The number of entries, must be a power of 2.\n, string description  //< A string description of the buffer.\n>\nclass trace_buffer\n{\nprivate:\n[[memory]] entry_type[depth] _log;\ninspectable(_log, description);\nusing pointer_type=index_t<depth>;\n// Verify pointer_type has correct width\nstatic assert(depth == (1 << bitsizeof(pointer_type)));\npointer_type _write_pointer = 0;\nbool _write_wrapped = false;\ninspectable(_write_pointer, description);\ninspectable(_write_wrapped, description);"}
{"file": "data\\cache\\internal.pd", "nl": "Function: ReduceEntryForInsertion  Given two cache_entry_with_index structs, return the one that would be a better candidate for inserting a new entry in the cache.  First choice is to find an unused (invalid) entry, but if both candidates are valid, then the least recently used is chosen.", "code": "template <typename LUtime, typename entry_index_t>\ninline cache_entry_with_index<LUtime, entry_index_t> ReduceEntryForInsertion(cache_entry_with_index<LUtime, entry_index_t> x, cache_entry_with_index<LUtime, entry_index_t> y)\n{\ncache_entry_with_index<LUtime, entry_index_t> result;\n\nif (!x._valid)\n{\n// If x is invalid, we can store a new entry here without evicting any cached data.\nresult = x;\nelse if (!y._valid) {\n    result = y;\n}\nelse if (x._lastUsed < y._lastUsed) {\n    // Both x and y are valid, but y was used more recently.  Evict x.\n    result = x;\n}\nelse { \n    result = y;\n}\nreturn result;}"}
{"file": "data\\cache\\internal.pd", "nl": "Handles metadata related to entries in the cache, but does not store data.", "code": "template\n< typename Key       //< The type of key for looking up a value in the cache.\n, typename LUtime    //< The type to use for storing the time a cache entry was\n// most recently used. Using a wider type makes LRU eviction\n// more accurate for a set associative cache, but for a direct\n// cache where LRU does not apply, using `uint1` saves space.\n, auto Associativity //< The number of entries to store for a given hash value,\n// keeping the most recently used values. Pass 1 to create\n// a directly mapped cache.\n, auto Depth         //< The total number of entries to cache. Must be a multiple\n// of `Associativity`.\n>\nclass cache_tags\n{\nprivate:\nconst auto _setCount = Depth / Associativity;\nconst auto _entryIndexBits = (clog2(Associativity) > 0) ? clog2(Associativity) : 1;\n\npublic:\nusing set_index_t = index_t<_setCount> ;\nusing entry_index_t = uint<_entryIndexBits> ;\n\nprivate:\nmemory_norep<cache_tag<Key, LUtime, Associativity>, _setCount> m_tags;\n"}
{"file": "data\\cache\\internal.pd", "nl": "Function: IsValidMatch  Maps from a cache_entry and a Key to a boolean indicating whether the given entry is a valid match for the key.", "code": "inline bool IsValidMatch(cache_entry<Key, LUtime> entry, Key key)\n{\nreturn (entry._valid && entry._key == key);\n}"}
{"file": "data\\cache\\internal.pd", "nl": "Function: FindKey  Given a key, find its index within the given tag. If the key is not found, the is_valid field of the result is false.", "code": "inline optional<entry_index_t> FindKey(cache_tag<Key, LUtime, Associativity> tag, Key key)\n{\nbool[Associativity] matchBitmap;\n\n// Conceptually this is a map operation, but map doesn't pass another parameter,\n// the key in this case, to the map function.\nstatic for(const auto i : Associativity)\n{\nmatchBitmap[i] = IsValidMatch(tag._entries[i], key);\n// There should never be more than 1 valid matching key, but this code affects\n// HW performance.  Uncomment this line if necessary when debugging the Cache.\n// sim_assert(pop_count<entry_index_t>(cast<uint<Associativity>>(matchBitmap)) < 2);\n// highest_one does not support being called for a single bit array, which causes the\n// following line to not compile in the direct map case (Associativity == 1) without\n// the + 1 term seen below.\nauto highestOne = highest_one<uint<Associativity + 1>>(cast<uint<Associativity>>(matchBitmap));\nreturn make_optional<entry_index_t>(highestOne.is_valid, highestOne.value);}"}
{"file": "data\\cache\\internal.pd", "nl": "Function: MapToEntryWithIndex  Maps a entry to a cache_entry_with_index.  The latter structure doesn't have the Key field, but adds an index field indicating where it lies in the tag._entries array.", "code": "inline cache_entry_with_index<LUtime, entry_index_t> MapToEntryWithIndex(cache_entry<Key, LUtime> entry, entry_index_t idx)\n{\ncache_entry_with_index<LUtime, entry_index_t> result;\n\nresult._valid = entry._valid;\nresult._unwritten = entry._unwritten;\nresult._lastUsed = entry._lastUsed;\nresult._index = idx;\n\nreturn result;\n}"}
{"file": "data\\cache\\internal.pd", "nl": "Function: GetIndexForNewEntry  Find the index of the best slot to store a new cache line entry. This will either be an entry that is not valid or else the valid entry that has been least recently used.", "code": "inline optional<entry_index_t> GetIndexForNewEntry(cache_tag<Key, LUtime, Associativity> tag)\n{\ncache_entry_with_index<LUtime, entry_index_t>[Associativity] indexed_entries;\n\n// Conceptually this is a map operation, but map doesn't pass another parameter,\n// the index in this case, to the map function.\nstatic for(const auto i : Associativity)\n{\nindexed_entries[i] = MapToEntryWithIndex(tag._entries[i], i);\nauto destination = reduce(ReduceEntryForInsertion<LUtime, entry_index_t>, indexed_entries);\nreturn make_optional(true, destination._index); }}"}
{"file": "data\\cache\\internal.pd", "nl": "Function: initializeCacheTag  Initializes a single cache_tag.", "code": "[[pipelined]] void InitializeCacheTag(set_index_t threadId)\n{\ncache_tag<Key, LUtime, Associativity> tag;\nstatic for (const auto j : Associativity)\n{\ncache_entry<Key, LUtime> entry;\nentry._valid = false;\nentry._unwritten = false;\nentry._lastUsed = 0; // not strictly necessary, but makes for cleaner debug output\ntag._entries[j] = entry;\n} }\n    m_tags[threadId] = tag;\n}"}
{"file": "data\\cache\\internal.pd", "nl": "Initialize or re-initialize a cache object. Re-initializing the cache invalidates all entries. The caller must ensure that intialize is not called concurrently with `get`.", "code": "void initialize()\n{\n// If this assert fires, Depth is not a multiple of Associativity.\nsim_assert(Depth == _setCount * Associativity);\n\nInitializeCacheTag(_setCount);\n}"}
{"file": "data\\cache\\internal.pd", "nl": "Get the index of a value from the `cache_tags`, if present.", "code": "cache_tags_get_result<entry_index_t, Key> get\n( Key key                //< The key to lookup.\n, set_index_t set_index  //< The hashed value of the key.\n, bool mark_as_unwritten //< Mark the cache entry as unwritten, meaning it hasn't\n// been written to the backing store yet.\n)\n{\nbool hit = false;\noptional<entry_index_t> idx;\ncache_entry<Key, LUtime> entry;\ncache_tags_get_result<entry_index_t, Key> result;\nauto cycleCount = cycles();\nKey key_to_write;\nbool valid_key_to_write = false;\natomic\n{\ncache_tag<Key, LUtime, Associativity> tag = m_tags[set_index];\nidx = FindKey(tag, key);\nif (idx.is_valid)\n{\nhit = true;\nentry = tag._entries[idx.value];\nelse {\nhit = false;\nidx = GetIndexForNewEntry(tag);\nsim_assert(idx.is_valid);\nif (tag._entries[idx.value]._unwritten) {\n    sim_assert(tag._entries[idx.value]._valid);\n    // Before we overwrite an unwritten value in the cache, capture the key\n    // that's about to be evicted.\n    key_to_write = tag._entries[idx.value]._key;\n    valid_key_to_write = true;\n}\n// In the cache miss case, we overwrite every field of the cache_tag, so\n// there is no need to copy the existing value from the tag._entries array.\nentry._valid = true;\nentry._key = key; }\n// Update the last used time for this cache entry\nsim_assert(idx.is_valid);\nentry._lastUsed = cast<LUtime>(cycleCount); // dropping high bits is expected\nentry._unwritten = mark_as_unwritten;\ntag._entries[idx.value] = entry;\nm_tags[set_index] = tag;\n}\nresult.idx = idx.value;\nresult.hit = hit;\nresult.key_to_write = make_optional<Key>(valid_key_to_write, key_to_write);\nreturn result;}"}
{"file": "data\\cache\\internal.pd", "nl": "Returns the key at the given (set_index, entry_index) tuple as well as whether the value is unwritten.  Marks the key as written. Must not be called concurrently with `get`.", "code": "optional<Key> get_and_clear_unwritten_key\n( set_index_t set_index     //< Set index of the key to lookup.\n, entry_index_t entry_index //< Way index of the key to lookup.\n)\n{\noptional<Key> result = {};\n\natomic\n{\nauto set = m_tags[set_index];\n\nauto entry = set._entries[entry_index];\n\nresult = make_optional<Key>(entry._unwritten, entry._key);\n\nentry._unwritten = false;\n\nset._entries[entry_index] = entry;\n\nm_tags[set_index] = set;\n}\nreturn result;}"}
{"file": "data\\cache\\write_through.pd", "nl": "Puts a value into the cache.", "code": "void put\n( Key key               //< The key to write.\n, set_index_t set_index //< The hashed value of the key.\n, Value value           //< The new value to put.\n)\n{\nget_or_put(false, key, set_index, value);\n}"}
{"file": "data\\cache\\write_through.pd", "nl": "Gets a value from the cache.", "code": "Value get\n( Key key               //< The key to lookup.\n, set_index_t set_index //< The hashed value of the key.\n)\n{\nValue null_value;\n\nreturn get_or_put(true, key, set_index, null_value);\n}"}
{"file": "data\\cache\\write_through.pd", "nl": "Gets or puts a value from/to the cache.", "code": "Value get_or_put\n( bool is_get               //< Whether this is a get operation.  If false, this is a put operation.\n, Key key               //< The key to read or write.\n, set_index_t set_index //< The hashed value of the key.\n, Value value           //< The new value to put.  Ignored if `is_get` is true.\n)\n{\nbool read_from_cache;\n\nauto getResult = _tags.get(key, set_index, false);\n\nif (is_get)\n{\nif (!getResult.hit)\n{\nvalue = load(key);\n}read_from_cache = getResult.hit;}\nelse {\n    store(key, value);\n    read_from_cache = false;\n}\nreturn store_value_in_cache(set_index, getResult.idx, value, read_from_cache);\n}"}
{"file": "data\\cache\\write_through.pd", "nl": "Stores a value in the cache, or reads the existing value if `readFromCache` is true. Called by both `get` and `put`, and serves as a single place with a single atomic block for manipulating the contents of the cached data. Returns the value now in the cache, which may have just been written there.", "code": "inline Value store_value_in_cache\n( set_index_t set_index       //< The hashed value of the key.\n, entry_index_t entry_index   //< The index within the cache line for the given entry.\n, Value newValue              //< The value to store into the cache.\n, bool readFromCache          //< Set to true if this function should return the existing value from the cache.\n)\n{\nValue result;\n\nauto dataIndex = set_index * Associativity + entry_index;\natomic\n{\nValue dataInCache = m_data[dataIndex];\nif (readFromCache)\n{\n// Snap the data from the cache.\nresult = dataInCache;\n} else {\n    // Update the cache.\n    dataInCache = newValue;\n    result = newValue;\n}\nm_data[dataIndex] = dataInCache;\n}\nreturn result;"}
{"file": "data\\cache\\write_through.pd", "nl": "A cache that immediately writes data to the backing store.", "code": "template\n< typename Key          //< The type of key for looking up a value in the cache.\n, typename Value        //< The type of value stored in the cache.\n, typename LUtime       //< The type to use for storing the time a cache entry was most recently used.\n// Using a wider type makes LRU eviction more accurate for a set associative\n// cache, but for a direct cache where LRU does not apply, using uint1 saves space.\n, auto Associativity    //< The number of entries to store for a given hash value.  Use 1 to create a directly mapped cache.\n, auto Depth            //< The total number of entries to cache.  Must be a multiple of `Associativity`.\n>"}
{"file": "data\\buffer\\accumulating.pd", "nl": "Write up to `InputSize` values to the buffer.  Once `FlitCount` flits are accumulated then `output_callback` is called once per accumulated flit.", "code": "inline void enqueue_with_callback\n( input_vec_t values                            //< Values to enqueue.\n, bool flush                                    //< If true, then call the callback for all buffer values associated with the buffer identified by `buffer_index`.\n, (index_t<FlitCount>,\ncount_t<FlitCount>,\nvec::vector<T, Size>)->void output_callback //< Function which is called once per output flit.\n)\n{\nreturn _buffer.enqueue_with_callback(0, values, flush, output_callback);\n}"}
{"file": "data\\buffer\\accumulating.pd", "nl": "write up to `InputSize` values to the buffer.  If there are now full flit of buffered data then the return structure will contain that flit.  A caller can also explicitly retrieve a partial flit by setting the `flush` parameter to true. Returns an `output` in which up to Size values are valid (at most a single flit).", "code": "output enqueue\n( T[InputSize] values            //< An array of values to enqueue.\n, count_t<InputSize> value_count //< The number of entries in the values array that are valid.\n// Must be between 0 and `InputSize`, inclusive.\n, bool flush                     //< If true, return up to Size elements, even if the buffer is not yet full.\n)\n{\nreturn _buffer.enqueue(0, values, value_count, flush);\n}"}
{"file": "data\\buffer\\accumulating.pd", "nl": "A buffer that accumulates elements into flits (fixed-sized arrays of elements).", "code": "template\n< typename T            //< Type of values stored in the accumulating buffer.\n, auto Size             //< Maximum number of elements that can be stored in a flit.\n, auto InputSize = Size //< Maximum number of elements that can be appended to the buffer in one call.\n, auto FlitCount = 1    //< Maximum number of flits that can be stored.  The output callback is called once for each `Size` elements.\n>\nclass accumulating_buffer\n{\nprivate:\nusing buffer_t = multi_accumulating_buffer<T, Size, 1, InputSize, array, true, FlitCount>;\n\nbuffer_t _buffer;\n\n"}
{"file": "data\\random\\xoshiro.pd", "nl": "[Xoshiro-128](http://xoshiro.di.unimi.it/xoshiro128starstar.c) random number generator. The \"128\" here refers to the internal state; the RNG actually returns 32-bit values.", "code": "inline void jump()\n   {\n        const uint32[4] JUMP = cast<uint32[4]>(cast<uint128>(0x77f2db5b6fa035c3f542d2d38764000b));\n\n        uint32 s0 = 0;\n        uint32 s1 = 0;\n        uint32 s2 = 0;\n        uint32 s3 = 0;\n\n        for (const uint3 i : 4)\n        {\n            const uint1[32] jump = cast<uint1[32]>(JUMP[i]);\n\n            for (const uint6 b : 32)\n            {\n                if (jump[b] == 1)\n                {\n                    s0 ^= _s[0];\n                    s1 ^= _s[1];\n                    s2 ^= _s[2];\n                    s3 ^= _s[3];\n                }\n                next();\n            }\n        }\n\n        _s[0] = s0;\n        _s[1] = s1;\n        _s[2] = s2;\n        _s[3] = s3;\n    }"}
{"file": "data\\random\\xoshiro.pd", "nl": "Set the RNG seed. Do not call this concurrently with `next`.", "code": "[[max_threads(1)]] void set_seed(uint32 seed) {\n    _s[0] = 0;\n    _s[1] = 0;\n    _s[2] = 0;\n    _s[3] = seed;\n    jump();\n}"}
{"file": "data\\random\\xoshiro.pd", "nl": "Get the next random number in the sequence.", "code": "uint32 next()\n    {\n        uint32 s0;\n\n        atomic\n        {\n            s0 = _s[0];\n            uint32 t = _s[1] << 9;\n            uint32 s2 = _s[2];\n            uint32 s3 = _s[3];\n\n            s2 ^= _s[0];\n            s3 ^= _s[1];\n\n            _s[0] ^= s3;\n            _s[1] ^= s2;\n            _s[2] = s2 ^ t;\n            _s[3] = cast<uint32>((s3 << 11) | (s3 >> 21));\n        }\n\n        return ((cast<uint32>(s0 * 5) << 7) | (cast<uint32>(s0 * 5) >> 25)) * 9;\n    }"}
{"file": "data\\random\\mt19937.pd", "nl": "Function: get_MT  Reads a value from one of the 3 memories.", "code": "inline uint<w> get_MT(const memory_index_t memory_index, uint1 mt_set_index, MT_t i)\n{\nreturn MT[memory_index][n * mt_set_index + i];\n}"}
{"file": "data\\random\\mt19937.pd", "nl": "Function: set_MT  Sets a value in all 3 memories.", "code": "inline void set_MT(uint1 mt_set_index, MT_t i, uint<w> value)\n{\nconst auto index_within_memory = n * mt_set_index + i;\nstatic for(const auto i : memory_count)\n{\nMT[i][index_within_memory] = value;\n}"}
{"file": "data\\random\\mt19937.pd", "nl": "Function: compute_one_mt_entry  Each call computes a single new value in the next MT array.  Mersenne Twister literature calls this a \"twist\" operation.  Twist is an expensive operation that is done once at initialization time, and again after every n calls to get_next.  After initialization, this implementation never does a full twist, but instead does a small amount of work after each call to get_next.  This produces the same results, but with more consistent latency.", "code": "inline void compute_one_mt_entry(MT_t i)\n{\n// Effectively this code is doing:\n// uint<w> x = (MT[i] & upper_mask) + (MT[(i + 1) % n] & lower_mask);\n// However n is not always a power of 2, so the % operator doesn't work here.\n// We know i + 1 is never more than n, so we don't need to call divide_unsigned.\nMT_t next_element_index = checked_cast<MT_t>(i + 1);\nuint1 next_element_set_index;\nif (next_element_index == n)\n{\nnext_element_set_index = next_mt;\nnext_element_index = 0;\n}       else {\nnext_element_set_index = current_mt;\n    }\n    uint<w> x = (get_MT(0, current_mt, i) & upper_mask) | (get_MT(1, next_element_set_index, next_element_index) & lower_mask);\n    uint<w> xA = x >> 1;\n    if (cast<uint1>(x) != 0)  // lowest bit of x is 1 {\n        xA = xA ^ a;\n    }\n    // Effectively:\n    // MT[i] = MT[(i + m) % n] ^ xA;\n    // m < n and i < n, therefore (i + m) < 2 * n\n    // therefore a general modulo isn't necessary, but we do need to account\n    // for the case where (i + m) > n\n    auto i_plus_m = i + m;\n    MT_t source_index = checked_cast<MT_t>(i_plus_m < n ? i_plus_m : i_plus_m - n);\n    // Low indices, which we set early in the twist operation, are computed entirely\n    // based on values in the current MT.  For higher indices, the value is based on\n    // a value that was \"overwritten\" earlier in the twist.  Therefore we must decide\n    // here whether to fetch MT[(i + m) % n] from either the current set of MT values\n    // or the \"next\" set being computed now.\n    uint1 mt_set_index;\n    if (i < (n - m)) {\n        mt_set_index = current_mt;\n    }\n    else {\n        mt_set_index = next_mt;\n    }\n    set_MT(next_mt, i, (get_MT(2, mt_set_index, source_index) ^ xA));\n}"}
{"file": "data\\random\\mt19937.pd", "nl": "Function: switch_MT_sets  Switches the MT sets.  Current becomes next and vice versa.  The caller must ensure it is safe to call this function.  Specifically: * no other thread is calling switch_MT_sets concurrently and * no thread is reading/writing the contents of either the current or next MT array while this function is running.  The next() function relies on the _retwist_semaphore to ensure that its call to switch_MT_sets is safe.", "code": "inline void switch_MT_sets()\n{\n// Invert these 1-bit integers\ncurrent_mt = ~current_mt;\nnext_mt = ~next_mt;\n}"}
{"file": "data\\random\\mt19937.pd", "nl": "Function: next  Gets the next random number in the sequence.", "code": "uint<w> next()\n{\n_retwist_semaphore.wait();\n\nMT_t snapped_index;\nbool call_switch = false;\natomic\n{\nif (index >= n)\n{\ncall_switch = true;\nindex = 0;\n}\n}\n        snapped_index = index;\n        index++;\n    }\n    if (call_switch)\n    {\n        switch_MT_sets();\n    }\n    uint<w> y = get_MT(3, current_mt, snapped_index);\n    // We just consumed MT[snapped_index], so the retwist thread is now free to calculate\n    // the next value at MT[snapped_index].\n    compute_one_mt_entry(snapped_index);\n    _retwist_semaphore.post();\n    y = y ^ ((y >> u) & d);\n    y = y ^ ((y << s) & b);\n    y = y ^ ((y << t) & c);\n    y = y ^ (y >> l);\n    return cast<uint<w>>(y);\n}"}
{"file": "data\\random\\mt19937.pd", "nl": "Set the RNG seed. Do not call this concurrently with `next`.", "code": "void set_seed(uint32 seed)\n    {\n        _mt.set_seed(seed);\n    }"}
{"file": "data\\random\\mt19937.pd", "nl": "Get the next random number in the sequence.", "code": "uint32 next()\n    {\n        return _mt.next();\n    }"}
{"file": "data\\buffer\\gearbox.pd", "nl": "A mechanism for converting values among differing types.", "code": "template\n< typename From                                        //< Type of the value to be\n// converted.\n, typename To                                          //< Type of the result of the\n// conversion.\n, (To, bool, count_t<bytesizeof(To)>) -> void Callback //< The callback function to be\n// invoked when the conversion is\n// complete.\n>\nclass gearbox\n{\nprivate:\nconst auto output_array_length = bitsizeof(To) > bitsizeof(From) ? 1 : bitsizeof(From) / bitsizeof(To);\ngearbox_context<From, To> context;\n\n[[pipelined]] void flush_output(count_t<output_array_length> tid, gearbox_context<From, To> ctx)\n{\nbool last = false;\nauto bytes = bytesizeof(To);\n\nif (tid == ctx.num_output_elements - 1)\n{\nbytes -= (bytesizeof(To)) - ctx.num_bytes;\nlast = true;\n} Callback(ctx.u.output_buff[tid], last, bytes);}"}
{"file": "data\\buffer\\gearbox.pd", "nl": "Perform a step of the translation. If the size of the `From` type is smaller than the size of the `To` type this function will be called multiple times, once for each portion of the input.", "code": "void push\n( From input //< The value to be converted. May be a partial value if\n// the `From` type is smaller than the `To` type.\n, bool start //< When `true`, indicates that this call is the start of\n// the translation.\n, bool last  //< When `true`, indicates that this call marks the end of\n// the translation. Make sure to set this to true when\n// passing the last of partial input.\n)\n{\ngearbox_context<From, To> local_context;\natomic\n{\nlocal_context = context;\n\nlocal_context = gearbox_with_context<From, To>(local_context, input, start, last);\n\ncontext = local_context;\n}if (local_context.valid)\n{\n    flush_output(output_array_length, local_context);\n}\n}"}
{"file": "data\\buffer\\gearbox.pd", "nl": "Convert between values of differing bit sizes. Return a `gearbox_context` containing the current state of the conversion.", "code": "template <typename From, typename To>\ninline gearbox_context<From, To> gearbox_with_context\n    ( gearbox_context<From, To> context //< Current state of the conversion.\n    , From input                        //< The value to be converted.\n    , bool start                        //< When `true` indicates that this call\n                                        // is the first of possibly several\n                                        // calls performing the conversion.\n    , bool last                         //< When `true` indicates that this call\n                                        // is processing the last portion of\n                                        // the input.\n    )\n{\n    static assert((bitsizeof To % 8 == 0) && (bitsizeof From % 8 == 0));\n\n    // Ensure a new context on first call\n    gearbox_context<From, To> empty_context = {};\n    context = start ? empty_context : context;\n\n    // Ensure we're not being called too many times.\n    const auto input_buffer_width = bitsizeof(context.u.input_buff) / bitsizeof(From);\n    sim_assert(context.num_input_elements < input_buffer_width);\n\n    if (bitsizeof From > bitsizeof To)\n    {\n        // gearbox_with_context is called a single time,\n        context.u.input_buff[0] = input;\n        context.num_input_elements = 1;\n        context.num_output_elements = bitsizeof(From) / bitsizeof(To);\n        context.num_bytes = bytesizeof(To);\n        context.valid = true;\n    }\n    else if (bitsizeof To > bitsizeof From)\n    {\n        // gearbox_with_context is called multiple times,\n        // once for each of the smaller values\n        context.u.input_buff[context.num_input_elements] = input;\n        ++context.num_input_elements;\n        context.num_bytes += bytesizeof(From);\n        if (context.num_input_elements == input_buffer_width || last == true)\n        {\n            context.num_output_elements = 1;\n            context.valid = true;\n        }\n    }\n    else\n    {\n        // Pass-through\n        // gearbox_with_context is called a single time\n        context.u.output_buff[0] = input;\n        context.num_input_elements = 1;\n        context.num_output_elements = 1;\n        context.num_bytes = bytesizeof(To);\n        context.valid = true;\n    }\n\n    return context;\n}"}
{"file": "data\\buffer\\burst_write.pd", "nl": "Write one entry to the buffer.  May invoke the `write_callback` function.", "code": "inline void write\n(T value                   //< The value to write.\n, bool flush_now           //< If true, the callback will be invoked\n// for any buffered values, even if there\n// are fewer than `BurstSize` values buffered.\n, ( T value                //< The value to write in the callback.\n, burst_count_t index    //< The index of this callback within the burst.\n// Between 0 and `BurstSize` - 1 inclusive.\n, bool is_last           //< True if this is the last value within this\n// burst, false otherwise.\n) -> void write_callback //< The function to call when `BurstSize`\n// entires have been written.\n)\n{\n// Block until the buffer is no longer full.\n_write_semaphore.wait();\n\npointer_t snapped_producer_index;\npointer_t snapped_consumer_index;\ncount_t<BurstSize> callback_count = 0;\n\n// Get the values of the read and write pointers, increment the write pointer.\natomic\n{\nsnapped_consumer_index = _consumer_index;\nsnapped_producer_index = _producer_index;\n_producer_index = modular::increment(_producer_index);\n\n// Note that entries_before_this is deliberately too small to hold a count.  When\n// the producer index wraps around 0 before the consumer index, we rely on this\n// calculation overflowing to produce the correct result.\npointer_t entries_before_this = snapped_producer_index - snapped_consumer_index;\n\nif (flush_now || (entries_before_this == (BurstSize - 1)))\n{\n// Adding 1 to reflect what the count will be after writing the current value.\ncallback_count = entries_before_this + 1;\n\n// By setting the consumer index to the producer index, this thread is\n// \"reserving\" these values to pass to the callback.  Note that the space\n// is not available in the buffer yet, because the code below has not yet\n// passed the value(s) to the callback.  The _write_semaphore tracks how\n// much room is available in the buffer, and it will be updated after the\n// callback is invoked.\n_consumer_index = _producer_index;\n}\n}\n // Store the value into the memory.\n _data[snapped_producer_index] = value;\n // Invoke the callback if necessary.\n invoke_callback(callback_count, snapped_consumer_index, callback_count, write_callback);}"}
{"file": "data\\buffer\\burst_write.pd", "nl": "Return the number of elements that have been written and not yet sent to the callback. Note that this can be out of date the instant it is read due to other threads writing to the buffer.", "code": "inline buffer_count_t count()\n{\nbuffer_count_t result;\natomic\n{\nresult = _producer_index - _consumer_index;\n}"}
{"file": "data\\buffer\\burst_write.pd", "nl": "Function: invoke_callback  Invokes the write callback once and posts to the write semaphore. thread_index   - Which thread this is, in the range 1 through (callback_count - 1). data_offset    - The offset within the _data memory for the first value being passed to the callback in this burst. callback_count - How many callbacks will be invoked in this burst.  Used to determine whether pass is_last to the callback. write_callback - The function to call when BurstSize entries have been written. See write function for parameter descriptions and usage.", "code": "inline void invoke_callback(burst_count_t thread_index, pointer_t data_offset, burst_count_t callback_count, (T, burst_count_t, bool) -> void write_callback)\n{\npipelined_for(callback_count, [data_offset, callback_count, write_callback](index_t<BurstSize> thread_index)\n{\npointer_t data_index = data_offset + thread_index;\n\nwrite_callback(_data[data_index], thread_index, thread_index == (callback_count - 1));\n_write_semaphore.post();\n});\n}"}
{"file": "data\\buffer\\burst_write.pd", "nl": "Buffer that accumulates a given number of entries, and then invokes a callback one or more times to write those values to e.g. DRAM in a burst.", "code": "template\n< typename T                  //< Type of each entry of the buffer\n, auto BufferSize             //< Number of elements to buffer.  Must be a\n// power of 2.\n, auto BurstSize = BufferSize //< Number of elements to store before\n// invoking the `write_callbck`.  Must be a\n// power of 2 and `BurstSize` <= `BufferSize`.\n>\nclass burst_write_buffer\n{\npublic:\nstatic assert(0 == (BufferSize & (BufferSize - 1))); //< `BufferSize` must be a power of 2.\nstatic assert(0 == (BurstSize & (BurstSize - 1)));   //< `BurstSize` must be a power of 2.\nstatic assert(BurstSize <= BufferSize);\n\nusing buffer_count_t = count_t<BufferSize>;\nusing burst_count_t = count_t<BurstSize>;\n\nprivate:\nusing pointer_t = index_t<BufferSize>;\npointer_t _producer_index = 0;\npointer_t _consumer_index = 0;\n\n// Memory that holds the values waiting to be written back\nmemory<T, BufferSize> _data;\n\n// Used to block writes while the buffer is full\nsemaphore<BufferSize, BufferSize, true> _write_semaphore;\n"}
{"file": "codec\\parquet.pd", "nl": "| Inflate bit-packed values into uint64's. Reference: <https://github.com/apache/parquet-format/blob/master/Encodings.md#bit-packed-deprecated-bit_packed--4>", "code": "template\n< auto BatchSize      //< Number of values to decompress at a time.\n// `BatchSize` must be less than or equal to\n// `DataLoadSize` divided by the largest column's\n// `input_bit_size`.\n, auto DataLoadSize   //< Number of bits to laod at a time when requesting\n// more data, e.g. 512.\n, auto NumColumns     //< Number of columns in source data, e.g. 5.\n, typename OutputSize //< The kind of value you want the bits unpacked into\n// e.g. uint16.\n>\nclass bit_reader{\nprivate:\nconst auto _cacheSize = DataLoadSize;\n\n//need to be able to store values 0 to DataLoadSize, and signed, so add 2.\n//e.g. if we are loading 512 bits at a time, we need to store values\n//0 to 512 (513 total values), but signed, so -512 to 512\nconst auto _tailBitSize = clog2(DataLoadSize+1)+1;\n\n[[pipelined]] void _reset(uint<clog2(NumColumns)> tid)\n{\n_numTailBits[tid] = 0;\n}"}
{"file": "codec\\compression\\gunzip.pd", "nl": "Decompress a stream of `DEFLATE` (RFC1951) blocks that are used by GZIP. The GZIP header and footer are expected to be processed outside of this class.", "code": "template\n< auto DecodeBytesPerCycle      //< Number of bytes to decode at a time in\n// the `decode` function.\n, auto MaxInputFileSizeBytes    //< Maximum supported input file size. Used\n// for sizing indices.\n, auto MemoryWidthBytes         //< Number of bytes for the store or load\n// of input data. Should match target BRAM.\n, auto MemorySizeBytes          //< The size of the input buffer memory.\n, auto LzBankCount              //< Number of banks to divide the\n// back-reference memory into. Higher\n// values increase throughput by avoiding\n// bank conflicts but increase area.\n, auto LzNumPorts               //< Number of read ports on the window\n// memory. Higher values increase throughput\n// by tolerating more bank conflicts but\n// increase memory consumption.\n, auto LzLookbackSize           //< Size of an internal buffer used to\n// resolve references to nearby words.\n// Increasing this size increases area, but\n// reduces stall cycles.\n, auto DecodeLengthsPerCycle    //< Max number of code lengths that can be\n// decoded in one cycle.\n, auto DecodeSymbolsPerCycle    //< Max number of symbols that can be\n// decoded in one cycle.\n, auto LitLenExtraBitsTableBits //< Max bit width of codes that are stored\n// in the Literal/Length extra bits table.\n// 7 is a reasonable value.\n, auto DistExtraBitsTableBits   //< Max bit width of codes that are stored\n// in the distance extra bits table.\n// 5 is a reasonable value.\n, auto MaxDecompThreads         //< Max number of decompression threads.\n, auto WriteCallbackWidth\n, ( uint8[WriteCallbackWidth]\n, count_t<WriteCallbackWidth>\n, bool                        //< Indicate whether this will be the last call.\n// Allows the consumer to flush if desired.\n) -> void WriteCallback       //< Callback function for supplying the\n// next `count_t<WriteCallbackWidth>`\n// compressed bytes.\n>\nclass decompressor\n{\nstatic assert(MemorySizeBytes % MemoryWidthBytes == 0);\n\n"}
{"file": "codec\\compression\\gunzip.pd", "nl": "Reset the decompressor. Must be called prior to decoding a new GZIP member, and must only be called again after `wait_for_done` returns.", "code": "template<auto N>\nvoid reset(uint<N> input_size)\n{\n// Compile-time check that input_size cannot contain more than MaxInputFileSizeBytes\nstatic assert((1 << N) - 1 <= MaxInputFileSizeBytes);\n\nsim_assert(_unzip_done);\n\n// Start at a \"negative\" offset accounting for the data produced by NumSeekThreads\n_read_bit_offset = 0 - (NumSeekThreads * MemoryWidthBits);\n_free_bit_offset = -1;\n_input_size = input_size;\n_output_count = 0;\n_last_read_addr = {};\n\n// Reset flags\n_unzip_done = false;\n_error_code = 0;\n\n_input_buffer.reset();\n\n// Start unzipping\nunzip();\n}"}
{"file": "codec\\compression\\gunzip.pd", "nl": "Wait for unzipping to complete. Return error code, where 0 indicates success, and CRC-32 checksum.", "code": "result_t wait_for_done()\n{\nwait_for(_unzip_done);\nreturn {_error_code, _crc32, _output_count};\n}"}
{"file": "codec\\compression\\gunzip.pd", "nl": "Sized so that `MaxCompressedDecodeThreads` will be ~2048", "code": "const auto MemorySizeBytes = DecodeBytesPerCycle * 2048;\nconst auto LzBankCount = DecodeBytesPerCycle * 2;\nconst auto LzNumPorts = 2;\nconst auto LzLookbackSize = 2;\nconst auto DecodeLengthsPerCycle = DecodeBytesPerCycle;\nconst auto DecodeSymbolsPerCycle = DecodeBytesPerCycle * 2;\nconst auto LitLenExtraBitsTableBits = 6;\nconst auto DistExtraBitsTableBits = 6;\nconst auto MaxDecompThreads = 512;\n\n\nprivate:\nusing decompressor_t = decompressor<DecodeBytesPerCycle, MaxInputFileSizeBytes, MemoryWidthBytes, MemorySizeBytes,\nLzBankCount, LzNumPorts, LzLookbackSize,\nDecodeLengthsPerCycle, DecodeSymbolsPerCycle,\nLitLenExtraBitsTableBits, DistExtraBitsTableBits,\nMaxDecompThreads,\nWriteCallbackWidth, WriteCallback>;\ndecompressor_t _decomp;\n\npublic:\nusing memory_word_t = decompressor_t::memory_word_t;\n\ninline void push(memory_word_t data)\n{\n_decomp.push(data);\n}"}
{"file": "codec\\compression\\gunzip.pd", "nl": "Push this piece of data into the input buffer", "code": "inline void push(memory_word_t data)\n    {\n        _input_buffer.write(data);\n    }"}
{"file": "codec\\compression\\gunzip.pd", "nl": "Free entries from the cyclic buffer up to but not including the entry that includes the specified bit index.", "code": "[[async]] void free(input_bit_index_t bit_index) {\n    // Convert from bit index to byte index\n    auto byte_index = bit_index >> clog2(BitsPerByte);\n    auto free_addr = byte_index / MemoryWidthBytes;\n    // Avoid underflow\n    if (free_addr != 0)\n    {\n        // Free up to the entry before this bit index\n        free_addr--;\n        _input_buffer.free(free_addr);\n    }}"}
{"file": "codec\\compression\\gunzip.pd", "nl": "Return ReadWidthBits of data starting at the given argument. In the sequential read case, this would read the newest word into the cache and shift the cached values. This function is capable of tracking what the last read address is, and will not update the cache if a new word does not need to be read. In the non-sequential case, it is the responsibility of the caller to refill the cache with valid data.", "code": "read_word_t read(input_bit_index_t offset){\n    auto addr = offset / (MemoryWidthBytes * BitsPerByte);\n    index_t<MemoryWidthBits> shift = offset % MemoryWidthBits;\n    optional<index_t<MaxInputFileSizeWords>> snapped_last_read_addr;\n    atomic {\n       snapped_last_read_addr = _last_read_addr;\n        _last_read_addr = {true, addr};\n    }\n    bool read = (!snapped_last_read_addr.is_valid || addr != snapped_last_read_addr.value);\n    auto max_addr = (_input_size + MemoryWidthBytes - 1) / MemoryWidthBytes - 1;\n    memory_word_t data;\n    if (read) {\n        data = _input_buffer.read(template min<index_t<MaxInputFileSizeWords>>(addr + (CacheWords - 1), max_addr));\n    }\n    memory_word_t[CacheWords] snapped_cache;\n    atomic {\n        static memory_word_t[CacheWords] _cache;\n        if (read) {\n            static for(const auto i : CacheWords) {\n                memory_word_t rhs;\n                if (i + 1 < CacheWords)\n                    rhs = _cache[i + 1];\n                else\n                    rhs = data;\n                _cache[i] = rhs;\n            }\n        }\n        snapped_cache = _cache;\n    }\n    return cast<uint<CacheWords * MemoryWidthBits>>(snapped_cache) >> shift;\n}"}
{"file": "codec\\compression\\gunzip.pd", "nl": "Get the extra bit information for a header length symbol.", "code": "inline extra_bits get_extra_bits_header_length(index_t<MaxHCLEN> symbol) {\n    sim_assert(symbol <= 18);\n    auto value = extra_bits_header_length_table[symbol];\n    extra_bits result;\n    result.addend = value.first;\n    result.count = value.second;\n    return result;\n}"}
{"file": "codec\\compression\\gunzip.pd", "nl": "Get the special bit information for a length symbol, including whether this length value is followed by a distance - possibly with special bits of its own.", "code": "inline extra_bits get_extra_bits_length(index_t<MaxHLIT> symbol){\n    extra_bits result;\n    if (symbol < EndOfBlockSymbol) {\n        result.addend = 0;\n        result.count = 0;\n    }\n    else {\n        sim_assert(symbol < MaxHLIT);\n        auto value = extra_bits_length_table[symbol % 256];\n        result.addend = value.first;\n        result.count = value.second;\n        result.distance_follows = (symbol != EndOfBlockSymbol);  // A distance will follow this length.\n    }\n    return result;\n}"}
{"file": "codec\\compression\\gunzip.pd", "nl": "Given raw compressed bits, return the length of the symbol it contains.", "code": "inline code_and_length_t get_code_length(code_t code, huffman_code huff){\n    code_length_t len = decode_length<MinCodeBits>(code,\n        [huff](code_length_t length)\n        {\n            return _huffman_tables.get_last_code<MaxCodeBits>(huff, length);\n        },\n        [huff]() {\n            return _huffman_tables.get_max_length<clog2(MaxCodeBits)>(huff);\n        }\n    ); \n    code_and_length_t ret;\n    ret.length = len;\n    sim_assert(ret.length != 0);\n    ret.code = code >> (MaxCodeBits - ret.length);\n    return ret;\n}"}
{"file": "codec\\compression\\gzcomp.pd", "nl": "Public due to codeLengthCount_dot_run()  Given a code length, the number of times it is repeated, and the next length, compute the code(s) (that supports run length encoding) required to encode it. Call enqueue() to store these codes into the _journal memory for re-use later; that function also increments the code frequency count used to compute the optimal Huffman coding.", "code": "inline void flush(lenHuffman_t::symbol_t lastSym, lenHuffman_t::symFreq_t repeats,\noptional<lenHuffman_t::symbol_t> nextSym)\n{\ncodeRepeat_t[3] journalEntries;\ncount_t<3> numJournalEntries;\n\n            if (repeats != 0) {\n        sim_assert(lastSym <= 15);\n        if (repeats <= 2) {\n            // Run-length symbols only supports repeats >= 3,\n            // so output this code literally\n            if (nextSym.is_valid)\n               sim_assert(lastSym != nextSym.value);\n           static for(const auto i : 2) if (i < repeats) journalEntries[i] = {lastSym, 0};\n            numJournalEntries = repeats;}\n        else {\n            // Maximum run-length depends on if the code length is zero\n            if (lastSym != 0) {\n                if (nextSym.is_valid && nextSym.value == lastSym)\n                    sim_assert(repeats == 6);\n                // Nonzero lengths require that the length is output literally,\n                // (already done below by the last flush() call) after which a\n                // \"repeat last length X times\" code can be used\n                sim_assert(repeats >= 3 && repeats <= 6);\n                journalEntries[0] = {16, repeats - 3};\n            }\n            else {\n                if (nextSym.is_valid && nextSym.value == lastSym)\n                    sim_assert(repeats == 138);\n                // Zero lengths do not require that the length is output\n                // literally, and a \"repeat zero X times\" code can be used\n                sim_assert(repeats >= 3 && repeats <= 138);\n                if (repeats <= 10)\n                    journalEntries[0] = {17, repeats - 3};\n                else\n                    journalEntries[0] = {18, repeats - 11};\n            }\n            numJournalEntries = 1; }}\n    // If the next length is nonzero, output that length literally here\n    if (nextSym.is_valid && nextSym.value != 0 && nextSym.value != lastSym) {\n        sim_assert(nextSym.value <= 15);\n        journalEntries[numJournalEntries] = {nextSym.value, 0};\n        numJournalEntries++;\n    }\n    // Use a pipelined function to prevent out-of-order entries when >1 thread enqueues into the memory\n    journal_enqueue(numJournalEntries,\n                    journalEntries); // ContextSaver: 11x512 saving a 2-bit tid and a 9-bit tid (bug 19392)\n}"}
{"file": "codec\\compression\\gzcomp.pd", "nl": "Entry point for encoding threads, determining the number of threads (and thus the functionality) of encode_pipeline(), for example, depending on if and how big of an update is pending. size == 0 implies the current data block should be ended.", "code": "void encode(token_t[Width] word, count_t<Width> size, bool flush)\n{\nif (_state == state_t::RESET)\n_state = state_t::UNDERWAY;\n\nbool snappedUpdatePending;\natomic\n{\nsnappedUpdatePending = _updatePending && !flush;\nif (snappedUpdatePending)\n_updatePending = false;\n} // Compute the tid on which data (if any) should be output (after header but before EOB) index_t<MaxEncodePipelineThreads> dataTid = 0;\nif (snappedUpdatePending)\n{\n    sim_assert(!flush);\n    dataTid = _preparedBufferCount;\n    sim_assert(dataTid != 0);\n}\ncount_t<MaxEncodePipelineThreads> numThreads = dataTid + 1 + (flush ? 1 /* BFINAL/pad */ + 1 /* CRC32 */ + 1 /* ISIZE */ : 0);\nencode_pipeline(numThreads, word, size, dataTid, flush); // ContextSaver: 4x512bit saving 4-bit tid (bug 19392)}"}
{"file": "codec\\compression\\gzcomp.pd", "nl": "Intended to be called by countFreq.count() once enough symbols have been counted; this function is responsible for computing and preloading a new Huffman code based on the sampled values and preparing the end-of-block (if performing live updates) and new GZIP member and/or DEFLATE block header -- all in parallel without affecting the main encoding thread.", "code": "[[async, max_threads(1)]] void start_new_block_async()[[async, max_threads(1)]] void start_new_block_async()\n//       ^^^^^^^^^^^^^^ No functional reason for this, but causes the ContextSaver for compute_huffman()\n//                      and writer_dot_prepare() to go into LUTRAM not BRAM {\n    sim_assert(_updateState == updateState_t::IDLE);\n   _updateState = updateState_t::UNDERWAY;\n    auto train = (countFreq.get_update_interval() == 0);\n    compute_huffman(3, train);\n    bool gzipHeader = (_state == state_t::RESET);\n    index_t<writer_t::MaxPrepareThreads> deflateTid = (gzipHeader ? writer.GzipHeaderThreads : 0);\n    index_t<writer_t::MaxPrepareThreads> flushTid = deflateTid + 1 /* EOB/NOP */ + 1 /* BFINAL+BTYPE(+HLIT+HDIST)*/;\n    if (!writer.get_fixed_huffman())\n        flushTid +=\n            (gz::MaxHCLEN + 1 + gz::MaxHCLEN) /* HCLEN */ + codeLengthCount.journal_count() /* Code Lengths */;\n    count_t<writer_t::MaxPrepareThreads> numThreads = flushTid + 1;\n    writer_dot_prepare(numThreads, deflateTid, flushTid, !train /* EOB */);\n    // The user-defined updateInterval determines how much input data must be seen before switching over to\n    // the new Huffman code (and then starting a new update) to ensure deterministic file sizes.\n    // Use this async thread to wait until updateInterval has been reached (which also restarts sampling) or\n    // until the compressor is flushed.\n    wait_for(countFreq.update_interval_reached() || _state == state_t::NEED_RESET);\n    writer.set_update_pending();\n    _updateState = updateState_t::IDLE;\n}"}
{"file": "codec\\compression\\gzcomp.pd", "nl": "Moving this function back into writer_t causes \"Internal compiler error\" since it is calling a method inside a fellow nested class (codeLengthCount) inline pair<uint<gz::MaxLengthCodeBits + 7>, count_t<gz::MaxLengthCodeBits + 7>>", "code": "writer_dot_write_code_lengths(index_t<HLIT> tid){\n    sim_assert(codeLengthCount.journal_count() != 0);\n    auto entry = codeLengthCount.journal_get(tid);\n    sim_assert(entry.sym <= 18);\n    auto sym = entry.sym;\n    auto c = writer.len_code(sym);\n    uint<gz::MaxLengthCodeBits + 7> data = c.code;\n    count_t<gz::MaxLengthCodeBits + 7> size = c.length;\n    sim_assert(size > 0);\n    data |= entry.repeatFor << size;\n    if (sym == 16) {\n        sim_assert(entry.repeatFor < 4);\n        size += 2;\n    }\n    else if (sym == 17) {\n        sim_assert(entry.repeatFor < 8);\n        size += 3;\n    }\n    else if (sym == 18) {\n        size += 7;\n    }\n    else{\n        sim_assert(entry.repeatFor == 0);\n    }\n    return {data, size};\n}"}
{"file": "codec\\compression\\gzcomp.pd", "nl": "Performs the encoding for input tokens into Huffman codes. Also responsible for maintaining the number of uncompressed bytes processed and draining the contents of _preparedBuffer containing the GZIP header and/or starting or transitioning onto a new DEFLATE block, as well as to output the GZIP footer.", "code": "[[pipelined]] void encode_pipeline(index_t<MaxEncodePipelineThreads> tid, token_t[Width] word,\ncount_t<Width> wordSize, index_t<MaxEncodePipelineThreads> dataTid,\nbool flush)\n{\nuint<MaxWriteBits * MaxWriteThreads> data;\ncount_t<MaxWriteBits * MaxWriteThreads> size;\noptional<token_t>[Width] optionalWord;\nauto mask = mask_less_than<Width>(wordSize);\nstatic for(const auto i : Width)\noptionalWord[i] = make_optional(mask[i], word[i]);\n//Find the original/dereferenced size by accounting for reference lengths\nauto origSize = map_reduce(token_length<token_t, count_t<MaxReferenceDistance*Width>>\n, add<count_t<MaxReferenceDistance*Width>, count_t<MaxReferenceDistance*Width>>\n, optionalWord);\nbool endBlock = (wordSize == 0);\nbool padToNextByte = false;\nuint64 snappedBytesEncoded;\nbool snappedPrevEndBlock;\natomic\n{\nif (tid == dataTid)\n_bytesUncompressed += origSize;\nsnappedBytesEncoded = _bytesUncompressed;\nstatic bool prevEndBlock = false;\nsnappedPrevEndBlock = prevEndBlock;\nprevEndBlock = endBlock;\n}\nif (tid < dataTid)\n{\n// Write contents of _preparedBuffer, containing end-of-last-block (if appropriate) and\n// header-of-next-block\natomic\n{\nsim_assert(tid < _preparedBufferCount);\ndata = _preparedBuffer[tid];\nstatic assert(MaxPreparedBufferSize <= bitsizeof(data));\n}\nsize = (tid == dataTid - 1) ? _lastPreparedBufferEntrySize : MaxPreparedBufferSize;\n}\nelse if (tid == dataTid){\nuint1 snappedCodesFront;\natomic {\n// If this is not the first thread, then it must mean a new header was written so switch over\n// to those new data codes\nif (tid != 0)\n_codebookFront = ~_codebookFront;\nsnappedCodesFront = _codebookFront; }\n// Lack of any data implies an end-of-block operation\nif (endBlock) {\n// Write DEFLATE end-of-block (if one was not written previously and no header was just emitted)\nauto c = code_EOB(snappedCodesFront);\ndata = c.code;\nsize = (!snappedPrevEndBlock && tid == 0) ? c.length : 0;\n}\nelse {\n// Write data\ntokenCode_t<MaxEncodedBits>[Width] compressed;\nstatic for(const auto i : Width)\n{\nif (optionalWord[i].is_valid) {\nlengthSymbolWithExtraBits_t sb;\nif (word[i].kind == input_kind::reference)\nsb = length_to_symbol_and_extra_bits<lengthSymbolWithExtraBits_t,MaxReferenceLength>(\nword[i].payload.reference.length);\nauto s = (word[i].kind == input_kind::data ? word[i].payload.data : sb.sym);\nauto c = _litLenCodebook[snappedCodesFront * HLITPow2 | s];\nsim_assert(c.length != 0);\ncompressed[i] = {c.code, c.length};\nif (word[i].kind == input_kind::reference) {\ncompressed[i].code |= sb.bits << compressed[i].length;\ncompressed[i].length += sb.extraBits;\nauto db = distance_to_symbol_and_extra_bits<distanceSymbolWithExtraBits_t,MaxReferenceDistance>(\nword[i].payload.reference.offset);\nauto c = _distCodebook[snappedCodesFront * HDISTPow2 | db.sym];\nsim_assert(c.length != 0);\ncompressed[i].code |= ((db.bits << c.length) | c.code) << compressed[i].length;\ncompressed[i].length += db.extraBits + c.length;}}\nelse\nsim_assert(compressed[i].length == 0);\n}// Reduce\nauto result = reduce(reduce_token_code<MaxEncodedBits>, compressed);\ndata = result.code;\nsize = result.length;\nsim_assert(size != 0);\n}\n}\nelse if (tid == dataTid + 1) {\n// Write BFINAL block (using fixed Huffman)\nsim_assert(dataTid == 0);\nsim_assert(endBlock);\ndata = (1 << 0) |                   // BFINAL\n(gz::btype::fixed << 1) |    // BTYPE == 0b01\n(0 << 3);                    // EndOfBlockSymbol\nsize = 1 + 2 + 7;\n// Pad to next byte boundary\npadToNextByte = true; } else if (tid == dataTid + 2) {\n// Write GZIP footer: CRC32\nstatic assert(MaxEncodedBits >= 32);\ndata = cast<uint32>(_crc32);\nsize = 32;\n}\nelse {\nsim_assert(flush);\n// Write GZIP footer: ISIZE\nsim_assert(tid == dataTid + 3);\nstatic assert(MaxEncodedBits >= 32);\ndata = snappedBytesEncoded;\nsize = 32;\nstatic assert(32 / MaxWriteBits + 1 /* flush */ <= MaxWriteThreads);\n}\nflush &&= (tid == dataTid + 3);\natomic {\nstatic index_t<8> accumulatedBits = 0;\naccumulatedBits += size;\nif (padToNextByte && accumulatedBits != 0) {\nsize += 8 - accumulatedBits;\naccumulatedBits = 0;\n}\nif (flush) {\n// By flush time should already be byte aligned\nsim_assert(accumulatedBits == 0);\n} }\n// Note that the input FIFO to write_async could fill up and apply back-pressure upstream and limit\n// compressor throughput.\n// On one hand, this can occur when a sequence of input words (e.g. containing long literal/length &\n// distance codes, accompanied by extra bits) each consistently generates more than MaxWriteBits of data,\n// thus queueing up more than one thread into write_async() per cycle.\n// On the other hand, outside of synthetic testing, the use of lzcomp alongside this compressor would not\n// be expected to generate the full Width tokens per cycle (for example, since any back-references must\n// cover a minimum of three literals) for back-pressure to be a problem.\nauto numThreads = (size + MaxWriteBits - 1) / MaxWriteBits + (flush ? 1 : 0);\nwrite_async(numThreads, cast<uint<MaxWriteBits>[MaxWriteThreads]>(data), size, flush);\n}"}
{"file": "codec\\compression\\gzcomp.pd", "nl": "Push the given number of tokens into the compressor. It is illegal to call `push` with `size < Width` except in the cycle prior to ending the current data block by setting `size == 0`.", "code": "void push( compressor_mode mode          //< Compression mode.\n                                //\n                                // `DEFLATE`\n                                // : `DEFLATE` the given number of\n                                //   tokens using the current Huffman\n                                //   code. If `updateInterval > 0`,\n                                //   also accumulate `SampleSize`\n                                //   tokens for computing a new\n                                //   Huffman code.\n                                //\n                                // `TRAIN`\n                                // : Accumulate the given data and\n                                //   use it to compute the optimal\n                                //   Huffman code. Typically, a\n                                //   sequence of `TRAIN` (supplying no\n                                //   more than `SampleSize` tokens)\n                                //   will be called prior to another\n                                //   sequence of `DEFLATE` on the same\n                                //   block of data for optimal compression.\n, token_t[Width] word           //< Input data. When `size` is zero and\n                                // `last` is set, the first four tokens\n                                // must contain the CRC32 value.\n, count_t<Width> size           //< Number of valid tokens. In `DEFLATE`\n                                // mode, a zero value indicates that the\n                                // current `DEFLATE` block should be\n                                // closed (by emitting the End-Of-Block\n                                // symbol). Optionally, when the `last`\n                                // argument is also set the first four\n                                // tokens of `word` will be used to\n                                // store the CRC32 value. In `TRAIN`\n                                // mode, a zero value triggers a new\n                                // Huffman code to be computed based on\n                                // the data sampled so far, blocking\n                                // until this code is ready. Immediately\n                                // prior to flushing, `push` must be\n                                // called with the last argument set.\n, [[last]] bool last            //< Indicates that the current GZIP\n                                // member should be terminated, using the\n                                // CRC32 value specified in word (in\n                                // conjunction with `size == 0`) and all\n                                // buffered data should be flushed\n                               // through `WriteCallback`. Only\n                                // applicable for `DEFLATE` mode.) {\nassert(_state != state_t::NEED_RESET, \\\"compressor_t::push() requires compressor_t::reset() be called first\\\");\nbool endBlock = (size == 0);\nbool deflate = (mode == compressor_mode::DEFLATE);\nassert(!last || deflate,\n       \\\"compressor_t::push() with last set is only applicable with compressor_mode::DEFLATE\\\");\n// Only count if DEFLATE mode with non-zero updateInterval, or if in TRAIN mode\nbool train = (mode == compressor_mode::TRAIN);\nif ((deflate && countFreq.get_update_interval() != 0 && !last) || train) {\n    bool snappedResetPending;\n    atomic\n    {\n        snappedResetPending = countFreq.get_reset_pending();\n        countFreq.set_reset_pending(train && endBlock);\n    }\n    countFreq_dot_count((snappedResetPending ? HLIT : 0) + (train || !endBlock ? 1 : 0), snappedResetPending,\n                        word, size); // ContextSaver: 80x512 including saving 9-bit tid (bug 19392)\n}\n// Only write if in DEFLATE mode\nif (deflate) {\n    if (last) {\n        assert(size == 0, \\\"compressor_t::push() with last argument set must also have size == 0\\\");\n        static for(const auto i : 4) {\n            sim_assert(word[i].kind == input_kind::data);\n            _crc32[i] = word[i].payload.data;\n        }\n    }\n    writer.encode(word, size, last);\n    // Since writer is asynchronous, block until all writing is complete\n    if (last)\n        wait_for(_state == state_t::NEED_RESET);\n}\n}"}
{"file": "codec\\compression\\gzcomp.pd", "nl": "Reset compressor states, set the `updateInterval`, and optionally prepare the initial GZIP/DEFLATE header using either a fixed Huffman code table or re-using the code table from the previous `DEFLATE` block.", "code": "[[max_threads(1)]] void reset( uint32 updateInterval //< The number of bytes that must pass through\n// the compressor before switching over onto\n// the newly computed dynamic Huffman code as\n// well as starting computation for the next\n// Huffman code.\n//\n// * `0` value indicates no dynamic updates (thus\n//   using either the initial Huffman code, or\n//   a to-be-computed code from a future call\n//   to `push` in `TRAIN` mode).\n//\n// * `>0` value indicates that a new Huffman\n//   table should be computed immediately, and\n//   once complete, wait until this number of\n//   bytes to have passed through the compressor\n//   before switching to the new code. The\n//   significance of this parameter is that,\n//   since new Huffman codes are computed in\n//   parallel with the main encoding thread, it\n//   will continue to progress even if the main\n//   thread becomes stalled. A small value\n//   would mean that the new Huffman code will\n//   be used as soon as possible, possibly\n//   leading to a non-deterministic (but still\n//   correct) number of output bytes depending\n//   on when the switch-over occurs with respect\n//   to the incoming data. A large value could\n    //   mean that holding back the switch-over for\n    //   so long that the new code may become stale\n    //   with respect to any new data. This value is\n    //   counted from the beginning of sampling,\n    //   and with `start_new_block_async`\n                        //   experimentally observed to require < 21,000 cycles\n                        //   (longer if stalled due to Huffman encoding\n                        //   failures) a rule of thumb would be that\n                        //   `updateInterval` be set to\n                        //   `SampleSize + 21,000 * Width` bytes for\n                        //   broadly deterministic behaviour.\n, bool reuseLastCode    //< Reuse the dynamic Huffman code table from\n                        // the last GZIP member instead of preloading\n                        // the fixed code. Undefined behaviour will\n                        // occur if an input symbol is not present in\n                        // the previous code table.\n) sim_assert(_state == state_t::NEED_RESET || _state == state_t::RESET);\n        // Wait for any outstanding start_new_block_async() to complete before advancing\n        wait_for(_updateState == updateState_t::IDLE);\n\n        writer.reset(reuseLastCode);\n\n        // updateInterval cannot be smaller than SampleSize since countFreq._wordsSinceStartedCounting -- used for\n        // determining how many samples to count as well as how long to wait until the next is triggered -- will\n        // saturate at updateInterval. If it were to be smaller than SampleSize, then counting would never\n        // terminate.\n        if (updateInterval != 0 && updateInterval < SampleSize)\n            updateInterval = SampleSize;\n        countFreq.set_update_interval(updateInterval);\n        countFreq.set_reset_pending(true);\n\n        if (updateInterval != 0)\n        {\n            index_t<writer_t::MaxPrepareThreads> deflateTid = writer.GzipHeaderThreads;\n            index_t<writer_t::MaxPrepareThreads> flushTid =\n                deflateTid + 1 /* EOB/NOP */ + 1 /* BFINAL+BTYPE(+HLIT+HDIST)*/;\n\n            if (reuseLastCode)\n            {\n                if (!writer.get_fixed_huffman())\n                    flushTid += (gz::MaxHCLEN + 1 + gz::MaxHCLEN) /* HCLEN */ +\n                                codeLengthCount.journal_count() /* code Lengths */;\n            }\n            else\n                writer.preload_codebook(HLIT + HDIST, preloadType_t::LITERAL_AND_DISTANCE, true /* fixed */);\n\n            count_t<writer_t::MaxPrepareThreads> numThreads = flushTid + 1;\n            writer_dot_prepare(numThreads, deflateTid, flushTid, false /* EOB */);\n            writer.set_update_pending();\n        }\n_state = state_t::RESET;\n}"}
{"file": "control\\async\\rendezvous\\strict.pd", "nl": "Join exactly `N` threads into a group. Each thread contributes one request to an array of requests before that thread blocks. A single function processes the combined array of requests to generate an array of responses. One response is sent to each thread and each thread in the group is unblocked.", "code": "template\n< typename Request                              //< Request type.\n, typename Response                             //< Response type.\n, auto N                                        //< Number of requests processed in parallel.\n, auto FifoDepth = 32                           //< Depth of internal FIFOs.\n                                                //  Larger values are needed to achieve full throughput if `Process` is a high latency.\n>\nclass rendezvous {\nprivate:\ninit_once _once;\ncounter<FifoDepth>[N] _request_count;\n\n    // DequeueBlocking is false because _request_count is checked before calling dequeue\n    template<typename T, auto Depth>\n    using request_fifo_t = FIFO<T, Depth, true, false>;\n\n    fifo_array<Request, FifoDepth, N, request_fifo_t> _requests;\n\n    counter<FifoDepth>[N] _response_count;\n\n    // EnqueueBlocking is false because _response_count is checked before calling enqueue\n    template<typename T, auto Depth>\n    using response_fifo_t = FIFO<T, Depth, false, true>;\n\n    fifo_array<Response, FifoDepth, N, response_fifo_t> _responses;\n\npublic:"}
{"file": "control\\async\\rendezvous\\strict.pd", "nl": "Must be called before any requests will be processed. All calls to `start` after the first are ignored.", "code": "inline void start\n ( (Request[N])->Response[N] process_fn   //< Function that processes requests to generate responses.\n )\n{\n    if (!_once.check())\n    {\n        async_exec([process_fn](){process(process_fn);});\n    }\n}"}
{"file": "control\\async\\rendezvous\\strict.pd", "nl": "Submits a requests, blocks until the corresponding response is generated, and returns the response.", "code": "template\n< auto Index //< Index of the request in the request array passed to `Process`.\n>\nResponse join(Request req)\n    {\n        static assert(Index < N);\n\n        // Save request into request FIFO\n        _requests.enqueue_one<Index>(req);\n\n        // Notify processing thread that another request is ready\n        _request_count[Index].increment();\n\n        // Wait for response\n        Response result = _responses.dequeue_one<Index>();\n\n        // Notify processing thread that response has been dequeued\n        _response_count[Index].decrement();\n\n        return result;\n    }"}
{"file": "control\\async\\rendezvous\\lenient.pd", "nl": "Join up to up to `N` distinct threads into a group. Each thread contributes one request to an array of requests before that thread blocks. A single function processes the combined array of requests to generate an array of responses. One response is sent to each thread and each thread in the group is unblocked.", "code": "template\n< typename Request                              //< Request type.\n, typename Response                             //< Response type.\n, auto N                                        //< Maximum number of requests processed in parallel.\n, auto FifoDepth = 32                           //< Depth of internal FIFOs.\n                                                //  Larger values are needed to achieve full throughput if `Process` is a high latency.\n>\nclass rendezvous {\nprivate:\ninit_once _once;\ncounter<FifoDepth>[N] _request_count;\n\n    // DequeueBlocking is false because _request_count is checked before calling dequeue\n    template<typename T, auto Depth>\n    using request_fifo_t = FIFO<T, Depth, true, false>;\n\n    fifo_array<Request, FifoDepth, N, request_fifo_t> _requests;\n\n    counter<FifoDepth>[N] _response_count;\n\n    // EnqueueBlocking is false because _response_count is checked before calling enqueue\n    template<typename T, auto Depth>\n    using response_fifo_t = FIFO<T, Depth, false, true>;\n\n    fifo_array<Response, FifoDepth, N, response_fifo_t> _responses;\n}"}
{"file": "control\\async\\rendezvous\\lenient.pd", "nl": "Must be called before any requests will be processed.  All calls to `start` after the first are ignored.", "code": "inline void start\n    ( (optional<Request>[N])->Response[N] process_fn   //< Function that processes requests to generate responses.\n    ) {\n    if (!_once.check())\n    {\n        async_exec([process_fn](){process(process_fn);});\n    }\n}"}
{"file": "control\\async\\rendezvous\\lenient.pd", "nl": "Submits a requests, blocks until the corresponding response is generated, and returns the response.", "code": "template\n< auto Index //< Index of the request in the request array passed to `Process`.\n>Response join(Request req)\n    {\n        static assert(Index < N);\n\n        // Save request into request FIFO\n        _requests.enqueue_one<Index>(req);\n\n        // Notify processing thread that another request is ready\n        _request_count[Index].increment();\n\n        // Wait for response\n        Response result = _responses.dequeue_one<Index>();\n\n        // Notify processing thread that response has been dequeued\n        _response_count[Index].decrement();\n\n        return result;\n    }"}
{"file": "tutorials\\complete\\parameterization.pd", "nl": "Parameterized helper classes/functions begin_strip", "code": "template<typename T, auto Count>\nclass fold_helper\n{\nprivate:\n    memory<T, Count> _input_data;\n    using element_index_t = index_t<Count>;\npublic:\n void write_input(element_index_t index, T data)\n {\n     _input_data[index] = data;\n}\ninline T fold((T, T)->T operator_fn) { return pipelined_last(){ bool is_first = (index == 0);\n\n            T val = _input_data[index];\n\n            T new_result;\n\n            atomic\n            {\n                static T _curr_result;\n\n                new_result = is_first ? val : operator_fn(val, _curr_result);\n\n                _curr_result = new_result;\n            }\n\n            return new_result; }"}
{"file": "tutorials\\complete\\parameterization.pd", "nl": "Stores 256 elements internally, each are 6-bit unsigned integers find() returns the largest element of those stored This class does not have any parameterization. The goal of this tutorial is to make a class like this one that is flexible enough to support the requirements listed in tutorial::run", "code": "class largest_uint6_out_of_256 {\nprivate:\n    memory<uint6, 256> _input_data;\npublic:\n    void write_input(uint8 index, uint6 data) {\n        _input_data[index] = data;\n    }\n    uint6 find() {\n        return pipelined_last(256, [](uint8 index) {\n            bool is_first = (index == 0);\n            uint6 val = _input_data[index];\n            uint6 new_max;\n            atomic {\n                static uint6 _curr_max;\n                new_max = is_first ? 0 : _curr_max;\n                new_max = val > new_max ? val : new_max;\n                _curr_max = new_max;\n            }\n            return new_max;\n        });\n    }\n}"}
{"file": "tutorials\\complete\\parameterization.pd", "nl": "Test for an object that stores 32 elements internally, each are 12-bit unsigned integers. Computes the largest element of those stored", "code": "pipelined_for(32, [](uint5 index) {\n    uint12 input_value = index * 7;\n    // Pass input value to a helper object\n    // begin_strip\n    _largest_uint12_out_of_32.write_input(index, input_value);\n    // end_strip\n});\nrun_scalar_test<uint12>([]() { \n     uint12 result = 0;\n     // Call helper object to compute maximum of all input values\n     // begin_strip\n     const auto max = [](uint12 a, uint12 b) -> uint12 {\n         return a > b ? a : b;\n     };\n     result = _largest_uint12_out_of_32.fold(max); \n     // end_strip\n     return result;\n }, \n 217, \"largest_uint12_out_of_32\");"}
{"file": "tutorials\\complete\\parameterization.pd", "nl": "Test for an object that stores 8 elements internally, each are 5-bit unsigned integers. Computes the smallest element of those stored", "code": "pipelined_for(8, [](uint3 index) {\n    uint5 input_value = (index + 13) * 7;\n    // Pass input value to a helper object\n    // begin_strip\n    _smallest_uint5_out_of_8.write_input(index, input_value);\n    // end_strip\n});\nrun_scalar_test<uint5>([]() {\n    uint5 result = 0;\n    // Call helper object to compute minimum of all input values\n    // begin_strip\n    const auto min = [](uint5 a, uint5 b) -> uint5 {\n        return a < b ? a : b;\n    };\n    result = _smallest_uint5_out_of_8.fold(min); \n    // end_strip\n    return result;}, \n2, \"smallest_uint5_out_of_8\");"}
{"file": "codec\\compression\\lzdecomp.pd", "nl": "Produce an array of outputs corresponding to a subset of the outputs that a set of tokens will produce. Each call can produce information corresponding to `WindowSize` output bytes.", "code": "optional<output_t> get_lz_input\n        ( length_t thread_id             //< Identify which set of output bytes\n                                         // this call refers to. A given set of\n                                         // tokens may produce many outputs\n                                         // bytes, and thus require many calls\n                                         // to this function.\n        , token_t[InputWidth] tokens     //< Array of input tokens to process.\n        , count_t<InputWidth> num_tokens //< Number of valid elements in the token array.\n        , bool is_last                   //< Indicate if this is the last set of\n                                         // tokens for 1 input stream.\n        )\n    {\n        // Compute cumulative length of each token (in bytes)\n        length_t[InputWidth] token_end_byte = get_cumulative_token_size(tokens, num_tokens);\n        length_t sum_token_lengths = token_end_byte[InputWidth - 1];\n\n        length_t[InputWidth] token_start_byte;\n        token_start_byte[0] = 0;\n        static for (const auto i : (InputWidth - 1))\n        {\n            token_start_byte[i+1] = token_end_byte[i];\n        }\n\n        length_t start_byte = OutputWidth * thread_id;\n        length_t end_byte = start_byte + OutputWidth;\n\n        if (end_byte > sum_token_lengths)\n        {\n            end_byte = sum_token_lengths;\n        }\n\n        // The last thread through is just to flush any remaining bytes out\n        length_t byte_count = is_last ? 0 : end_byte - start_byte;\n\n        output_t this_thread_data;\n\n        static for (const auto i : OutputWidth)\n        {\n            // Find the token that corresponds to this output byte\n            index_t<InputWidth> matching_token_index;\n\n            length_t byte_index = (i + start_byte);\n\n            static for (const auto token_index : InputWidth)\n            {\n                if ((byte_index >= token_start_byte[token_index]) && (byte_index < token_end_byte[token_index]))\n                {\n                    matching_token_index = token_index;\n                }\n            }\n\n            token_t matching_token = tokens[matching_token_index];\n\n            output_element_t input_record;\n            input_record.kind = matching_token.kind;\n\n            if (matching_token.kind == input_kind::data)\n            {\n                input_record.payload.data = matching_token.payload.data;\n            }\n            else\n            {\n                input_record.payload.offset = matching_token.payload.reference.offset;\n            }\n\n            this_thread_data[i] = input_record;\n        }\n\n        // Buffer results into outputs of size = OutputWidth\n        auto result = _accumulating_buffer.enqueue(this_thread_data, byte_count, is_last);\n\n        return make_optional<output_t>(result.value_count != 0, result.values);\n    }"}
{"file": "codec\\compression\\lzdecomp.pd", "nl": "Return running byte size + number of threads required to process a given set of input tokens.", "code": "metadata get_metadata\nmetadata get_metadata\n    ( token_t[InputWidth] tokens     //< Array of input tokens to process.\n    , count_t<InputWidth> num_tokens //< Number of valid elements in the\n                                     // token array.\n    , bool is_last                   //< Indicate if this is the last set of\n                                     // tokens for 1 input stream.\n    ) {\n    // Compute cumulative length of each token (in bytes)\n    length_t[InputWidth] partial_sums = get_cumulative_token_size(tokens, num_tokens);\n    length_t total_bytes = partial_sums[InputWidth - 1];\n    length_t num_threads = (total_bytes + OutputWidth - 1) / OutputWidth;\n    metadata result;\n    result.thread_count = num_threads;\n    if (is_last) {\n        // One final thread to flush out any remaining data\n        result.thread_count++;\n    }\n    // Update running total byte count\n    atomic {\n        static uint64 _running_byte_count = 0;\n        result.byte_count = _running_byte_count + total_bytes;\n        _running_byte_count = is_last ? 0 : result.byte_count;\n     }\n     return result;\n"}
{"file": "codec\\compression\\lzdecomp.pd", "nl": "Returns true if the current thread is safe to read from window memories", "code": "inline bool test(reference_t minimum_word_index, bool do_test) {\n    bool result = !do_test;\n    if (do_test) {\n        if (_num_in_flight_words.count() <= minimum_word_index) {\n            // Record that a new thread is in-flight (has memory writes pending)\n            _num_in_flight_words.add(1);\n            result = true;\n        }\n    }\n    return result;\n}"}
{"file": "codec\\compression\\lzdecomp.pd", "nl": "Returns byte offset from the start of the current word to the nearest referenced by", "code": "inline reference_t get_minimum_reference(input_t input) {\n    reference_t sentinal_value = cast<reference_t>(-1);\n    reference_t[Width] references;\n    // \"-i\" term ensures the result is the offset from the start of the current word\n    static for (const auto i : Width)\n    {\n        references[i] = (input_kind::reference == input[i].kind) ? (input[i].payload.offset - i) : sentinal_value;\n    }\n    return minimum<reference_t, Width>(references);\n}"}
{"file": "codec\\compression\\lzdecomp.pd", "nl": "Computes the set of memory acceses redquired for a given input", "code": "inline optional<decomposed_address>[Width] get_memory_access_info(input_t input, window_addr_t base_offset) {\n    optional<decomposed_address>[Width] result = {};\n    static for (const auto i : Width) {\n        if (input_kind::reference == input[i].kind) {\n            // Determine the absolute byte address of the source of this reference\n            reference_t relative_offset = input[i].payload.offset;\n            window_addr_t position = (base_offset + i) - relative_offset;\n            decomposed_address address = decompose_address(position);\n            result[i] = make_optional<decomposed_address>(true, address);\n        }\n    }\n    return result;\n}"}
{"file": "codec\\compression\\lzdecomp.pd", "nl": "finds elements in the input that reference other elements in the input, replaces these references with either raw bytes or references to previous inputs", "code": "inline input_t resolve_self_references(input_t input) {\n   input_t result = input;\n    // The outer loop runs log2(Width) iterations - which is enough to remove all self-references in the worst case input\n    // The inner loop runs Width iterations.  There are no loop-carried depedencies in the inner loop\n    static for (const auto iteration : clog2(Width)) {\n        input_t new_result = result;\n        static for (const auto i : Width) {\n            if (input_kind::reference == result[i].kind) {\n                auto i_minus_offset = i - result[i].payload.offset;\n               if (i_minus_offset >= 0)  {\n                    // Element i is a reference to an element in this same input\n                    // Look at the referenced element\n                    reference_t other_index = i_minus_offset;\n                    if (input_kind::reference == result[other_index].kind)  {\n                        // The referenced element is a reference - dereference\n                        new_result[i].payload.offset = result[other_index].payload.offset + result[i].payload.offset;\n                    }\n                    else {\n                        // The referenced element is raw data, replace the reference at i with raw data\n                        new_result[i].kind = input_kind::data;\n                        new_result[i].payload.data = result[other_index].payload.data;\n                    }\n                }\n            }\n        }\n        result = new_result;\n    }\n    // Assert that all self-references have been removed\n    static for (const auto i : Width) {\n        if (input_kind::reference == result[i].kind) {\n            sim_assert(result[i].payload.offset > i);\n            sim_assert(result[i].payload.offset <= WindowSize + i);\n        }\n    }\n    return result;\n}"}
{"file": "docs", "nl": "In the following example the accumulate function computes the sum of a series of integers and returns the current sum. Each call to accumulate adds one more integer to the running total. accumulate uses an static local variable to hold the current sum. This variable is reset when the is_last parameter is true. If accumulate is called from 2 call sites in parallel, then it will not operate as desired. The problem is that calls from the 2 call sites will interleave and thus the running total will not have the expected value.", "code": "uint32 accumulate(uint32 value, bool is_last) {\n    uint32 result;\n    atomic {\n        static uint32 _sum = 0;\n        result = _sum + value;\n        _sum = is_last ? 0 : result;\n    }\n    return result;\n}\n// assume function1 and function2 run in parallel\nvoid function1() {\n    pipelined_for(1000, [](uint32 i) {\n        bool is_last = (i == 999);\n        uint32 result = accumulate(i, is_last);\n        if (is_last) {\n            println('result from function1: ', result);\n        }\n    });}\nvoid function2() {\n    pipelined_for(500, [](uint32 i) {\n        bool is_last = (i == 499);\n        uint32 result = accumulate(i, is_last);\n        if (is_last) {\n            println('result from function2: ', result);\n        }\n    });\n}"}
{"file": "docs", "nl": "[[schedule(1)]] is used to ensure that a shared variable is updated atomically.", "code": "// This variable is shared among threads\nstatic uint32 res = 0;\n// Only 1 thread allowed in this block at a time\n[[schedule(1)]] {\n    // Read-modify-write the shared variable\n    uint32 sum = res + 2;s\n    res = sum * 6;\n}"}
{"file": "docs", "nl": "The following code snippet will execute in approximately numIter clock cycles. The operators corresponding to the x = x - tid statement can service at most one thread per cycle. Therefore, there is no end-to-end time saved by skipping the body of the if statement for half of the threads. The generated circuit may choose to skip the body of the if statement to save power, but this will not affect throughput.", "code": "uint32 numIter;\npipelined_for(numIter, [](uint32 tid) {\n    uint32 x = tid;\n    if ((tid & 1) == 1) {\n        x++;\n        x = x * 5;\n        // many more operators on x\n    }\n    x = x - tid;\n    println(x);\n});"}
{"file": "docs", "nl": "The following code snippet will execute in approximately numIter * 4 clock cycles. The key insight is that any particular thread must execute the operators corresponding to x += tid four times.", "code": "uint32 numIter;\npipelined_for(numIter, [](uint32 tid) {\n    uint32 x = tid & 5;\n    for (const auto i : 4) {\n        x += tid;\n    }\n    println(x);\n});"}
{"file": "docs", "nl": "The following code snippet has nested concurrency. It will execute in approximately numIter * 4 clock cycles. Any particular outer thread will create 4 inner threads, each of which executes the operators corresponding to inner_tid + 4 one time.", "code": "uint32 numIter;\npipelined_for(numIter, [](uint32 outer_tid) {\n    pipelined_for(4, [](uint32 inner_tid)\n    {\n        uint32 j = inner_tid + 4;\n        println(j);\n    });\n});"}
{"file": "docs", "nl": "This example will execute in approximately numIter * 2 clock cycles. Half of the outer threads will create four inner threads, the other half will create zero threads. Thus the average outer thread will create two inner threads.", "code": "uint32 numIter;pipelined_for(numIter, [](uint32 outer_tid) {\n    if (1 == (outer_tid & 1)) {\n        pipelined_for(4, [](uint32 inner_tid) {\n            uint32 j = inner_tid + 4;\n            println(j);\n        });\n    }\n});"}
{"file": "docs", "nl": "Functions annotated with [[reset]] attribute are called automatically after the design is reset (typically used to initialize state). Reset functions must have void return type and an empty parameter list.", "code": "class Foo{\nprivate:\n    [[reset]] void init()  {\n        pipelined_for(32, [](index_t<32> i) {\n            mem[i] = 0;\n        });\n    }\n    memory<uint32, 32> mem;\n}"}
{"file": "docs", "nl": "recursive algorithms can be expressed statically if the recursion \u201csize\u201d is known at compile time. The trick is to use static if syntax to terminate the recursive calls of a template function", "code": "template <typename T, auto N>\ninline auto reduce(T[N] a, (T, T) -> T fn) {\n    static assert((N & (N-1)) == 0);\n    static if (N == 1) {\n        return a[0];\n    }\n    else {\n        const auto b = split(a);\n        return fn(reduce(b.first, fn), reduce(b.second, fn));\n    }\n}\ntemplate <typename T, auto N>\ninline auto maximum(T[N] a)\n{\nreturn reduce(a, [](uint32 x, uint32 y){\n    return x > y ? x : y;\n});\n}"}
{"file": "docs", "nl": "pipelined_for creates N threads, each of which executes the provided function one time. A thread identifier is passed to each one.", "code": "auto numIter = 4;\n// prints: 0, 1, 2, 3\npipelined_for(numIter, [](uint2 thread_id) {\n    println(thread_id);\n});"}
{"file": "docs", "nl": "Thread ordering is a useful synchronization construct. A typical example is to identify the first and/or last thread within a group", "code": "const auto numIter = 256;pipelined_for(numIter, [numIter](uint32 thread_id) {\n    bool is_first = (thread_id == 0);\n    bool is_last = (thread_id == (numIter - 1));\n    // a bunch of code\n    // is_first and is_last are still valid\n    if (is_last) {\n        println(\"last thread done\");\n    }\n});"}
{"file": "docs", "nl": "The trace_buffer class implements a ring buffer of events. This enables the N most recent events to be inspectable.", "code": "import debug.trace_buffer\nvoid F(uint32 x, uint32 y) {\n    struct Event {\n        uint32 x;\n        uint32 y;\n        uint64 timestamp;\n    }\n    Event evt = { x, y, cycles() };\n    static trace_buffer<Event, 512, 'Recent calls to F'> _tb;\n    _tb.write(evt);\n}"}
{"file": "docs", "nl": "concat returns an unsigned integer that is the concatenation of multiple expressions. Note that the arguments are specified in big-endian order (the most significant bit of first argument is placed in the most significant bit of the result).", "code": "uint8 x = 0x45;\nuint16 y = 0x1267;\nuint48 z = concat(y, x); // 0x126745"}
{"file": "docs", "nl": "mux uses the first argument (an unsigned integer) to select one of the remaining input arguments. The number of arguments required by mux is determined by the width of the first argument. If the first argument is N bits wide, then there must be 2^N additional arguments. The arguments are passed from least significant to most significant (if the index argument is 0, then argument 1 is selected)", "code": "uint2 idx = 2;\nuint32 x = 54;\nuint32 y = 98;\nuint32[4] choices = { x, 3, 4, y };\nuint32 result = choices[idx];\n// result = 4"}
{"file": "docs", "nl": "Throughput: one addition per clock cycle. Execution Time: numIter*4 clock cycles", "code": "uint32 AddOne(uint32 x){\n    return x + 1; }\npipelined_for(numIter, [](uint32 tid) {\n    uint32[4] src;\n    uint32[4] dst;\n    static for (const auto i : 4) {\n        dst[i] = AddOne(src[i]);\n    }\n});"}
{"file": "docs", "nl": "Throughput: four additions per clock cycle. Execution Time: numIter clock cycles", "code": "inline uint32 AddOneInline(uint32 x) {\n    return x + 1; }\npipelined_for(numIter, [](uint32 tid) {\n    uint32[4] src;\n    uint32[4] dst;\n    static for (const auto i : 4) {\n        dst[i] = AddOneInline(src[i]);\n    }\n});"}
{"file": "docs", "nl": "Throughput: one multiplication per clock cycle. Execution Time: numIter*4 clock cycles", "code": "uint32 mul(uint32 x) {\n    return x * 3;}void ExecuteOneReplica(uint32 numIter) {\n    pipelined_for(numIter, [](uint32 tid) {\n        static multiply_by_three _multiplier;\n        uint32[4] src;\n        uint32[4] dst;\n        static for (const auto i : 4) {\n            dst[i] = _multiplier.mul(src[i]);\n        }\n    });\n}"}
{"file": "docs", "nl": "Throughput: Four multiplication per clock cycle. Execution Time: numIter clock cycles", "code": "void ExecuteFourReplicas(uint32 numIter) {\n    pipelined_for(numIter, [](uint32 tid) {\n        static multiply_by_three[4] _multipliers;\n        uint32[4] src;\n        uint32[4] dst;\n        static for (const auto i : 4) {\n            dst[i] = _multipliers[i].mul(src[i]);\n        }\n    });\n}"}